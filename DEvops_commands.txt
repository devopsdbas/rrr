devopsdbas -Krithigattu@123 ->github
root -Krithigattu@123
 user -devdb
nainiramu24@gmail.com
==============================
Access:

In kubernetes, only role based access cab be controlled fot teh users

In Aes: , IAM->SSO-> user access

raamu@raamu-VirtualBox:~$ kubectl get nodes
NAME       STATUS   ROLES           AGE    VERSION
minikube   Ready    control-plane   106d   v1.30.0

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
mydeploy-64c98c499f-x8gp6   1/1     Running   0          146m

To check the kubernetes resources:

raamu@raamu-VirtualBox:~$ kubectl api-resources |less
NAME                                SHORTNAMES   APIVERSION                        NAMESPACED   KIND
bindings                                         v1                                true         Binding
componentstatuses                   cs           v1                                false        ComponentStatus
configmaps                          cm           v1                                true         ConfigMap
endpoints                           ep           v1                                true         Endpoints

 $kubectl scale deploy myweb --replicas=4 (ensure if we increase the replicas we need that much amount of resources CPU/RAM)
                                   ******It creates replicas along wiht pods, but if we create POD , replicas will not create 

Deployment work is to run replicasets 
replicaset work is to ensure that pods are up and running		

* selector is used to select specific application if muleiple applications running in container
 Deployment checks on based on label
 like while we give a app name app=nginx  , this will assign to the LABEL	
 ANNOTATIONS : we can give metadata information: 

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$DOCKER_MINIKUBE$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

-> we can configure AWS related k8, if we install AWS CLI in minikube
     eg: we can use eksctl from minkube, for which we need to configure aws related keys using 
	     $AWS configure


	TO check the status of minikube:
	 $minikube status
raamu@raamu-VirtualBox:~$ minikube status
minikube
type: Control Plane
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured

raamu@raamu-VirtualBox:~$ kubectl get nodes
NAME       STATUS   ROLES           AGE    VERSION
minikube   Ready    control-plane   106d   v1.30.0
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ docker ps
CONTAINER ID   IMAGE                                 COMMAND                  CREATED        STATUS         PORTS                                                                                                                                  NAMES
0261026b6120   gcr.io/k8s-minikube/kicbase:v0.0.43   "/usr/local/bin/entr…"   3 months ago   Up 3 minutes   127.0.0.1:32772->22/tcp, 127.0.0.1:32771->2376/tcp, 127.0.0.1:32770->5000/tcp, 127.0.0.1:32769->8443/tcp, 127.0.0.1:32768->32443/tcp   minikube

raamu@raamu-VirtualBox:~$ minikube ssh
docker@minikube:~$ exit
logout

**One of the advantage of using minikube is we can launch K8's Dashboard
 
 raamu@raamu-VirtualBox:~$ minikube dashboard
* Verifying dashboard health ...

raamu@raamu-VirtualBox:~$ minikube addons list
|-----------------------------|----------|--------------|--------------------------------|
|         ADDON NAME          | PROFILE  |    STATUS    |           MAINTAINER           |
|-----------------------------|----------|--------------|--------------------------------|
| ambassador                  | minikube | disabled     | 3rd party (Ambassador)         |
| auto-pause                  | minikube | disabled     | minikube                       |
| cloud-spanner               | minikube | disabled     | Google                         |
| csi-hostpath-driver         | minikube | disabled     | Kubernetes                     |
| dashboard                   | minikube | enabled ✅   | Kubernetes                     |
| default-storageclass        | minikube | enabled ✅   | Kubernetes                     |
| efk                         | minikube | disabled     | 3rd party (Elastic)            |
| freshpod                    | minikube | disabled     | Google                         |
| gcp-auth                    | minikube | disabled     | Google                         |
| gvisor                      | minikube | disabled     | minikube                       |
| headlamp                    | minikube | disabled     | 3rd party (kinvolk.io)         |
| helm-tiller                 | minikube | disabled     | 3rd party (Helm)               |
| inaccel                     | minikube | disabled     | 3rd party (InAccel             |
|                             |          |              | [info@inaccel.com])            |
| ingress                     | minikube | disabled     | Kubernetes                     |
| ingress-dns                 | minikube | disabled     | minikube                       |
| inspektor-gadget            | minikube | disabled     | 3rd party                      |
|                             |          |              | (inspektor-gadget.io)          |
| istio                       | minikube | disabled     | 3rd party (Istio)              |
| istio-provisioner           | minikube | disabled     | 3rd party (Istio)              |
| kong                        | minikube | disabled     | 3rd party (Kong HQ)            |
| kubeflow                    | minikube | disabled     | 3rd party                      |
| kubevirt                    | minikube | disabled     | 3rd party (KubeVirt)           |
| logviewer                   | minikube | disabled     | 3rd party (unknown)            |
| metallb                     | minikube | disabled     | 3rd party (MetalLB)            |
| metrics-server              | minikube | disabled     | Kubernetes                     |
| nvidia-device-plugin        | minikube | disabled     | 3rd party (NVIDIA)             |
| nvidia-driver-installer     | minikube | disabled     | 3rd party (Nvidia)             |
| nvidia-gpu-device-plugin    | minikube | disabled     | 3rd party (Nvidia)             |
| olm                         | minikube | disabled     | 3rd party (Operator Framework) |
| pod-security-policy         | minikube | disabled     | 3rd party (unknown)            |
| portainer                   | minikube | disabled     | 3rd party (Portainer.io)       |
| registry                    | minikube | disabled     | minikube                       |
| registry-aliases            | minikube | disabled     | 3rd party (unknown)            |
| registry-creds              | minikube | disabled     | 3rd party (UPMC Enterprises)   |
| storage-provisioner         | minikube | enabled ✅   | minikube                       |
| storage-provisioner-gluster | minikube | disabled     | 3rd party (Gluster)            |
| storage-provisioner-rancher | minikube | disabled     | 3rd party (Rancher)            |
| volumesnapshots             | minikube | disabled     | Kubernetes                     |
| yakd                        | minikube | disabled     | 3rd party (marcnuri.com)       |
|-----------------------------|----------|--------------|--------------------------------|
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ minikube addons enable metrics-server
* metrics-server is an addon maintained by Kubernetes. For any concerns contact minikube on GitHub.
You can view the list of minikube maintainers at: https://github.com/kubernetes/minikube/blob/master/OWNERS
  - Using image registry.k8s.io/metrics-server/metrics-server:v0.7.1
* The 'metrics-server' addon is enabled

raamu@raamu-VirtualBox:~$  minikube addons list
|-----------------------------|----------|--------------|--------------------------------|
|         ADDON NAME          | PROFILE  |    STATUS    |           MAINTAINER           |
|-----------------------------|----------|--------------|--------------------------------|
| ambassador                  | minikube | disabled     | 3rd party (Ambassador)         |
| auto-pause                  | minikube | disabled     | minikube                       |
| cloud-spanner               | minikube | disabled     | Google                         |
| csi-hostpath-driver         | minikube | disabled     | Kubernetes                     |
| dashboard                   | minikube | enabled ✅   | Kubernetes                     |
| default-storageclass        | minikube | enabled ✅   | Kubernetes                     |
| efk                         | minikube | disabled     | 3rd party (Elastic)            |
| freshpod                    | minikube | disabled     | Google                         |
| gcp-auth                    | minikube | disabled     | Google                         |
| gvisor                      | minikube | disabled     | minikube                       |
| headlamp                    | minikube | disabled     | 3rd party (kinvolk.io)         |
| helm-tiller                 | minikube | disabled     | 3rd party (Helm)               |
| inaccel                     | minikube | disabled     | 3rd party (InAccel             |
|                             |          |              | [info@inaccel.com])            |
| ingress                     | minikube | disabled     | Kubernetes                     |
| ingress-dns                 | minikube | disabled     | minikube                       |
| inspektor-gadget            | minikube | disabled     | 3rd party                      |
|                             |          |              | (inspektor-gadget.io)          |
| istio                       | minikube | disabled     | 3rd party (Istio)              |
| istio-provisioner           | minikube | disabled     | 3rd party (Istio)              |
| kong                        | minikube | disabled     | 3rd party (Kong HQ)            |
| kubeflow                    | minikube | disabled     | 3rd party                      |
| kubevirt                    | minikube | disabled     | 3rd party (KubeVirt)           |
| logviewer                   | minikube | disabled     | 3rd party (unknown)            |
| metallb                     | minikube | disabled     | 3rd party (MetalLB)            |
| metrics-server              | minikube | enabled ✅   | Kubernetes                     |
| nvidia-device-plugin        | minikube | disabled     | 3rd party (NVIDIA)             |
| nvidia-driver-installer     | minikube | disabled     | 3rd party (Nvidia)             |
| nvidia-gpu-device-plugin    | minikube | disabled     | 3rd party (Nvidia)             |
| olm                         | minikube | disabled     | 3rd party (Operator Framework) |
| pod-security-policy         | minikube | disabled     | 3rd party (unknown)            |
| portainer                   | minikube | disabled     | 3rd party (Portainer.io)       |
| registry                    | minikube | disabled     | minikube                       |
| registry-aliases            | minikube | disabled     | 3rd party (unknown)            |
| registry-creds              | minikube | disabled     | 3rd party (UPMC Enterprises)   |
| storage-provisioner         | minikube | enabled ✅   | minikube                       |
| storage-provisioner-gluster | minikube | disabled     | 3rd party (Gluster)            |
| storage-provisioner-rancher | minikube | disabled     | 3rd party (Rancher)            |
| volumesnapshots             | minikube | disabled     | Kubernetes                     |
| yakd                        | minikube | disabled     | 3rd party (marcnuri.com)       |
|-----------------------------|----------|--------------|--------------------------------|
raamu@raamu-VirtualBox:~$


raamu@raamu-VirtualBox:~$ minikube addons disable metrics-server
* "The 'metrics-server' addon is disabled
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl top nodes
error: Metrics API not available
raamu@raamu-VirtualBox:~$ kubectl top pods
error: Metrics API not available
raamu@raamu-VirtualBox:~$

Gives the utilization report when we enable the metrics-server addons on minikube


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$KUBERNETES$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

raamu@raamu-VirtualBox:~$ kubectl get pods -A
NAMESPACE              NAME                                        READY   STATUS    RESTARTS       AGE
default                mydeploy-64c98c499f-864vz                   1/1     Running   2 (56m ago)    25d
default                mynginx                                     1/1     Running   2 (56m ago)    25d
kube-system            calico-kube-controllers-ddf655445-gn9gz     1/1     Running   7 (56m ago)    106d
kube-system            calico-node-szc9l                           1/1     Running   7 (56m ago)    106d
kube-system            coredns-7db6d8ff4d-tw4cj                    1/1     Running   9 (56m ago)    106d
kube-system            etcd-minikube                               1/1     Running   7 (56m ago)    106d
kube-system            kube-apiserver-minikube                     1/1     Running   7 (56m ago)    106d
kube-system            kube-controller-manager-minikube            1/1     Running   7 (56m ago)    106d
kube-system            kube-proxy-ztt7n                            1/1     Running   7 (56m ago)    106d
kube-system            kube-scheduler-minikube                     1/1     Running   7 (56m ago)    106d
kube-system            storage-provisioner                         1/1     Running   14 (55m ago)   106d
kubernetes-dashboard   dashboard-metrics-scraper-b5fc48f67-6r4j9   1/1     Running   5 (56m ago)    106d
kubernetes-dashboard   kubernetes-dashboard-779776cb65-znsbf       1/1     Running   5 (56m ago)    106d
raamu@raamu-VirtualBox:~$


Nodegroups::

we can use multiple group nodes
used to scale up/down the number of nodes in cluster-config.yaml file
                                             -------------------
		Eg: nodegroups:
		      -name:eks-node-grop
			  instanceType:t2.medium
			  desiredCapacity:3

================================================================
Kube config file:

It tells how to connect the different clusters , which stores the TLS certificates and acts as the mediator

Location : .kube in config directory

===============================================================
What is a namespace?

It is where we can restrict the resources.

===================================================
raamu@raamu-VirtualBox:~$ kubectl api-resources
NAME                                SHORTNAMES   APIVERSION                        NAMESPACED   KIND
bindings                                         v1                                true         Binding
componentstatuses                   cs           v1                                false        ComponentStatus
configmaps                          cm           v1                                true         ConfigMap
endpoints                           ep           v1                                true         Endpoints
events                              ev           v1                                true         Event
limitranges                         limits       v1                                true         LimitRange

=======================================================
TO make a shorcut to kubectl while we use TAB:

raamu@raamu-VirtualBox:~$ kubectl completion -h
Output shell completion code for the specified shell (bash, zsh, fish, or powershell). The shell code must be evaluated
to provide interactive completion of kubectl commands.  This can be done by sourcing it from the .bash_profile.

 Detailed instructions on how to do this are available here:

        for macOS:
        https://kubernetes.io/docs/tasks/tools/install-kubectl-macos/#enable-shell-autocompletion

        for linux:
        https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#enable-shell-autocompletion

        for windows:
        https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/#enable-shell-autocompletion

 Note for zsh users: [1] zsh completions are only supported in versions of zsh >= 5.2.

Examples:
  # Installing bash completion on macOS using homebrew
  ## If running Bash 3.2 included with macOS
  brew install bash-completion
  ## or, if running Bash 4.1+
  brew install bash-completion@2
  ## If kubectl is installed via homebrew, this should start working immediately
  ## If you've installed via other means, you may need add the completion to your completion directory
  kubectl completion bash > $(brew --prefix)/etc/bash_completion.d/kubectl


  # Installing bash completion on Linux
  ## If bash-completion is not installed on Linux, install the 'bash-completion' package
  ## via your distribution's package manager.
  ## Load the kubectl completion code for bash into the current shell
  source <(kubectl completion bash)
  ## Write bash completion code to a file and source it from .bash_profile
  kubectl completion bash > ~/.kube/completion.bash.inc
  printf "
  # kubectl shell completion
  source '$HOME/.kube/completion.bash.inc'

===============================================

raamu@raamu-VirtualBox:~$ kubectl top nodes
error: Metrics API not available
raamu@raamu-VirtualBox:~$ kubectl top pods
error: Metrics API not available
raamu@raamu-VirtualBox:~$

Gives the utilization report when we enable the metrics-server addons on minikube

==================================================

Kubernetes API Access and Resources:


 ***RBAC need to be installed to access the below commands.
 
 
=>How to control API access & Regulate:
  By using RBAC(Role based acces control)	, we can restrict/provide the access to the users.
  we get  information in .kube/config file
                         -----------------
                         like who have access and what access

To check the acces in Kubernetes:

In real time how to /where to check the access we got.

raamu@raamu-VirtualBox:~$ kubectl auth can-i create pods
yes
raamu@raamu-VirtualBox:~$ kubectl auth can-i create deployments
yes
raamu@raamu-VirtualBox:~$ kubectl auth can-i create --as ramu
error: you must specify two arguments: verb resource or verb resource/resourceName.
See 'kubectl auth can-i -h' for help and examples.
raamu@raamu-VirtualBox:~$ kubectl auth can-i -h
Check whether an action is allowed.

 VERB is a logical Kubernetes API verb like 'get', 'list', 'watch', 'delete', etc. TYPE is a Kubernetes resource.
Shortcuts and groups will be resolved. NONRESOURCEURL is a partial URL that starts with "/". NAME is the name of a
particular Kubernetes resource. This command pairs nicely with impersonation. See --as global flag.

Examples:
  # Check to see if I can create pods in any namespace
  kubectl auth can-i create pods --all-namespaces

  # Check to see if I can list deployments in my current namespace
  kubectl auth can-i list deployments.apps
  

=> Core Kubernetes Objects:

same Ip address for all containers in pods, ie. 1 IP address is assigned for pod.

 -----Deployment(Application)-----  
 |                               |
 |   192.168.0.1                 |
 |   -----POD(P1)----- __        |
 |   | container     | p2|       |
 |   | (has own      |   |__     |                 
 |   |  volumes)--------------------> PVC -------> PV --------> Storage
 |   |      C1  TLS  |   |p3|    |    persistent   persistent
 |   -----------------   |  |    |    volume       volume
 |     |________c2_______|  |    |    claims
 |        |________c3_______| ---------------------------->Replicasets
 |                      |_______________Config maps(whaterver the configuration /env variables in containers
 |                               |      Secret-> password/critical information and these will be outside of the pod 
---------------------------------                that means if we delete the pods also secrets will be available

===========================================

API' through CURL: 
Mostly it be used in Jenkins 
=>It runs the kubeproxy:
raamu@raamu-VirtualBox:~$ kubectl proxy --port=8001 &
[1] 38652
raamu@raamu-VirtualBox:~$ Starting to serve on 127.0.0.1:8001
^C
=>Shows the versions of the kubernetes
raamu@raamu-VirtualBox:~$ curl http://localhost:8001/version
{
  "major": "1",
  "minor": "30",
  "gitVersion": "v1.30.0",
  "gitCommit": "7c48c2bd72b9bf5c44d21d7338cc7bea77d0ad2a",
  "gitTreeState": "clean",
  "buildDate": "2024-04-17T17:27:03Z",
  "goVersion": "go1.22.2",
  "compiler": "gc",
  "platform": "linux/amd64"
}raamu@raamu-VirtualBox:~$

=>shows the information of the namespaces in Jason format

}raamu@raamu-VirtualBox:~$ curl http://localhost:8001/api/v1/namespaces
{
  "kind": "NamespaceList",
  "apiVersion": "v1",
  "metadata": {
    "resourceVersion": "23208"
  },
  "items": [
    {
      "metadata": {
        "name": "default",
        "uid": "447b1e69-2716-48e4-91b9-5ceb58d6b465",
        "resourceVersion": "40",
        "creationTimestamp": "2024-05-05T12:02:00Z",
        "labels": {
          "kubernetes.io/metadata.name": "default"
        },
        "managedFields": [
          {
            "manager": "kube-apiserver",
            "operation": "Update",
            "apiVersion": "v1",
            "time": "2024-05-05T12:02:00Z",
            "fieldsType": "FieldsV1",
            "fieldsV1": {
              "f:metadata": {
                "f:labels": {
                  ".": {},
                  "f:kubernetes.io/metadata.name": {}
                }
              }
            }
          }
        ]
      },

=>shows the information of the namespaces

raamu@raamu-VirtualBox:~$ kubectl get ns
NAME                   STATUS   AGE
default                Active   106d
kube-node-lease        Active   106d
kube-public            Active   106d
kube-system            Active   106d
kubernetes-dashboard   Active   106d
raamu@raamu-VirtualBox:~$ kubectl get namespace
NAME                   STATUS   AGE
default                Active   106d
kube-node-lease        Active   106d
kube-public            Active   106d
kube-system            Active   106d
kubernetes-dashboard   Active   106d
raamu@raamu-VirtualBox:~$

=>shows the information of the pods in jason format

raamu@raamu-VirtualBox:~$ curl http://localhost:8001/api/v1/namespaces/default/pods
{
  "kind": "PodList",
  "apiVersion": "v1",
  "metadata": {
    "resourceVersion": "23362"
  },
  "items": [
    {
      "metadata": {
        "name": "mydeploy-64c98c499f-864vz",
        "generateName": "mydeploy-64c98c499f-",
        "namespace": "default",
        "uid": "41164f28-e79e-4a04-b4d3-33278f0ab497",
        "resourceVersion": "20994",
        "creationTimestamp": "2024-07-25T07:16:09Z",
        "labels": {
          "app": "mydeploy",
          "pod-template-hash": "64c98c499f"
        },
        "annotations": {
          "cni.projectcalico.org/containerID": "71c2ac6e44009288e3ef7fbd6ce501647cfa8ba0482e6dcc4e3de11772d6ada0",
          "cni.projectcalico.org/podIP": "10.244.120.106/32",
          "cni.projectcalico.org/podIPs": "10.244.120.106/32"
        },
        "ownerReferences": [
          {
            "apiVersion": "apps/v1",

=>shows the information of the pods

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS    RESTARTS        AGE
mydeploy-64c98c499f-864vz   1/1     Running   3 (4h18m ago)   25d
mynginx                     1/1     Running   3 (4h18m ago)   25d

=> To delete the pod through curl

raamu@raamu-VirtualBox:~$ curl -XDELETE http://localhost:8001/api/v1/namespaces/default/pods/mynginx

To know in whihc namespace we are in :

raamu@raamu-VirtualBox:~$ kubens
Command 'kubens' not found, but can be installed with:
sudo snap install kubectx  # version 0.9.5, or
sudo apt  install kubectx  # version 0.9.5-1ubuntu0.1
See 'snap info kubectx' for additional versions.
raamu@raamu-VirtualBox:~$ sudo apt  install kubectx

Once installed, it shows 

raamu@raamu-VirtualBox:~$ kubens
default
kube-node-lease
kube-public
kube-system
kubernetes-dashboard
rnamespace
raamu@raamu-VirtualBox:~$



================================================================================================================

How to manage pod?

1. To create Naked pod:or any pod

raamu@raamu-VirtualBox:~$ kubectl run nakednginx --image=nginx
pod/nakednginx created
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS    RESTARTS        AGE
mydeploy-64c98c499f-864vz   1/1     Running   3 (4h44m ago)   25d
mynginx                     1/1     Running   3 (4h44m ago)   25d
nakednginx                  1/1     Running   0               23s
raamu@raamu-VirtualBox:~$

=>to check what pod has created.
raamu@raamu-VirtualBox:~$ kubectl get pods -o yaml
apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 71c2ac6e44009288e3ef7fbd6ce501647cfa8ba0482e6dcc4e3de11772d6ada0
      cni.projectcalico.org/podIP: 10.244.120.106/32
      cni.projectcalico.org/podIPs: 10.244.120.106/32
    creationTimestamp: "2024-07-25T07:16:09Z"
    generateName: mydeploy-64c98c499f-
    labels:
      app: mydeploy
      pod-template-hash: 64c98c499f
    name: mydeploy-64c98c499f-864vz
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: mydeploy-64c98c499f
      uid: 8e9ee74f-451d-43d8-ac43-f81902b3f558
    resourceVersion: "20994"
    uid: 41164f28-e79e-4a04-b4d3-33278f0ab497
  spec:
    containers:
    - image: nginx
   

=> To check above fiel in readble format.

raamu@raamu-VirtualBox:~$ kubectl get pods -o yaml > nakednginx.yaml
raamu@raamu-VirtualBox:~$ ls -ltr
total 39868
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Videos
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Templates
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Public
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Pictures
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Music
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Downloads
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Documents
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Desktop
-rw-rw-r-- 1 raamu raamu 40775680 May  5 17:28 minikube-linux-amd64
drwx------ 5 raamu raamu     4096 Jul 25 12:00 snap
-rw-rw-r-- 1 raamu raamu    10339 Aug 20 01:54 nakednginx.yaml
raamu@raamu-VirtualBox:~$ date
Tue Aug 20 01:55:01 AM IST 2024
raamu@raamu-VirtualBox:~$ more nakednginx.yaml
apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 71c2ac6e44009288e3ef7fbd6ce501647cfa8ba0482e6dcc4e3de11772d6ada0
      cni.projectcalico.org/podIP: 10.244.120.106/32
      cni.projectcalico.org/podIPs: 10.244.120.106/32
    creationTimestamp: "2024-07-25T07:16:09Z"
    generateName: mydeploy-64c98c499f-
    labels:
      app: mydeploy
      pod-template-hash: 64c98c499f
    name: mydeploy-64c98c499f-864vz
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: mydeploy-64c98c499f
      uid: 8e9ee74f-451d-43d8-ac43-f81902b3f558
    resourceVersion: "20994"
    uid: 41164f28-e79e-4a04-b4d3-33278f0ab497



=> how to check details about pod (like container info and what is running in container)
 
raamu@raamu-VirtualBox:~$ kubectl get pods -o wide
NAME                        READY   STATUS    RESTARTS        AGE     IP               NODE       NOMINATED NODE   READINESS GATES
mydeploy-64c98c499f-864vz   1/1     Running   3 (4h52m ago)   25d     10.244.120.106   minikube   <none>           <none>
mynginx                     1/1     Running   3 (4h52m ago)   25d     10.244.120.101   minikube   <none>           <none>
nakednginx                  1/1     Running   0               7m39s   10.244.120.107   minikube   <none>           <none>
raamu@raamu-VirtualBox:~$ kubect get pods
kubect: command not found
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS    RESTARTS        AGE
mydeploy-64c98c499f-864vz   1/1     Running   3 (4h52m ago)   25d
mynginx                     1/1     Running   3 (4h52m ago)   25d
nakednginx                  1/1     Running   0               7m59s
raamu@raamu-VirtualBox:~$ kubectl describe pod nakednginx
Name:             nakednginx
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Tue, 20 Aug 2024 01:49:46 +0530
Labels:           run=nakednginx
Annotations:      cni.projectcalico.org/containerID: 434907fc6e9d75682d76940bd7e376bbc91d5e6c2b233fdb5425c1918f894bf3
                  cni.projectcalico.org/podIP: 10.244.120.107/32
                  cni.projectcalico.org/podIPs: 10.244.120.107/32
Status:           Running
IP:               10.244.120.107
IPs:
  IP:  10.244.120.107
Containers:
  nakednginx:
    Container ID:   docker://216ac03a15763ac5fd9d0c3f760798a17e3eeba79651f6542b51236a318626f5
    Image:          nginx
    Image ID:       docker-pullable://nginx@sha256:447a8665cc1dab95b1ca778e162215839ccbb9189104c79d7ec3a81e14577add
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Tue, 20 Aug 2024 01:50:00 +0530
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-vmc7z (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       True
  ContainersReady             True
  PodScheduled                True
Volumes:
  kube-api-access-vmc7z:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  8m15s  default-scheduler  Successfully assigned default/nakednginx to minikube
  Normal  Pulling    8m7s   kubelet            Pulling image "nginx"
  Normal  Pulled     8m3s   kubelet            Successfully pulled image "nginx" in 4.052s (4.052s including waiting). Image size: 187694648 bytes.
  Normal  Created    8m3s   kubelet            Created container nakednginx
  Normal  Started    8m1s   kubelet            Started container nakednginx
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl delete -f nakednginx.yaml
pod "mydeploy-64c98c499f-864vz" deleted
pod "mynginx" deleted
pod "nakednginx" deleted
raamu@raamu-VirtualBox:~$


===================================================================================================

How YAML looks like?

->whenever we create yaml manifest, it has Apiversion which specifies the version of API
   eg: apiVersion:
            Kind:
		metadata:
      Spec:		
=> If we do not have any idea what pod /deployment doing, check below command,
   ******************whihc shows what are teh components need to be added in yaml file.	
	raamu@raamu-VirtualBox:~$ kubectl explain pod
KIND:       Pod
VERSION:    v1

DESCRIPTION:
    Pod is a collection of containers that can run on a host. This resource is
    created by clients and scheduled onto hosts.

FIELDS:
  apiVersion    <string>
    APIVersion defines the versioned schema of this representation of an object.
    Servers should convert recognized schemas to the latest internal value, and
    may reject unrecognized values. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources


raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl explain pod.spec |less
KIND:       Pod
VERSION:    v1

FIELD: spec <PodSpec>


DESCRIPTION:
    Specification of the desired behavior of the pod. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
    PodSpec is a description of a pod.

FIELDS:
  activeDeadlineSeconds <integer>
    Optional duration in seconds the pod may be active on the node relative to
    StartTime before the system will actively try to mark it failed and kill
    associated containers. Value must be a positive integer.

  affinity      <Affinity>
    If specified, the pod's scheduling constraints


===============================================================================================================

To create pod/deployemt/image with yaml file:

Imparative: create any pod from the simple template or we can get from kubernetes.io
Declarative: using command line
 eg: kubectl create -f busybox.yaml.


create: whenever we doing for the first time , we use it
apply: if we doing any changes 

raamu@raamu-VirtualBox:~$ ls -ltr
total 39872
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Videos
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Templates
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Public
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Pictures
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Music
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Downloads
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Documents
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Desktop
-rw-rw-r-- 1 raamu raamu 40775680 May  5 17:28 minikube-linux-amd64
drwx------ 5 raamu raamu     4096 Jul 25 12:00 snap
-rw-rw-r-- 1 raamu raamu    10339 Aug 20 01:54 nakednginx.yaml
-rw-rw-r-- 1 raamu raamu      197 Aug 20 13:45 busybox.yaml

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
mydeploy-64c98c499f-x8gp6   1/1     Running   0          30m

raamu@raamu-VirtualBox:~$ kubectl create -f busybox.yaml
pod/busybox1 created

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
busybox1                    1/1     Running   0          5s
mydeploy-64c98c499f-x8gp6   1/1     Running   0          30m
raamu@raamu-VirtualBox:~$

to describe:

raamu@raamu-VirtualBox:~$ kubectl describe pod busybox1
Name:             busybox1
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Tue, 20 Aug 2024 13:46:22 +0530
Labels:           app=busybox
Annotations:      cni.projectcalico.org/containerID: 00cf7350ba558533c5cbd49629b67bc6daf5de3b2dac9190c068abd9e510361d
                  cni.projectcalico.org/podIP: 10.244.120.119/32
                  cni.projectcalico.org/podIPs: 10.244.120.119/32
Status:           Running
IP:               10.244.120.119
IPs:
  IP:  10.244.120.119
Containers:
  busy:
    Container ID:  docker://874caca8e2b9639d81f255aab1000883c4223331e63ecd85f19b78f22f2a1a53
    Image:         busybox
    Image ID:      docker-pullable://busybox@sha256:9ae97d36d26566ff84e8893c64a6dc4fe8ca6d1144bf5b87b2b85a32def253c7
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      3600
    State:          Running
      Started:      Tue, 20 Aug 2024 13:46:26 +0530
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-8r9fb (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       True
  ContainersReady             True
  PodScheduled                True
Volumes:
  kube-api-access-8r9fb:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  9m43s  default-scheduler  Successfully assigned default/busybox1 to minikube
  Normal  Pulling    9m42s  kubelet            Pulling image "busybox"
  Normal  Pulled     9m39s  kubelet            Successfully pulled image "busybox" in 2.703s (2.703s including waiting). Image size: 4261574 bytes.
  Normal  Created    9m39s  kubelet            Created container busy
  Normal  Started    9m39s  kubelet            Started container busy
raamu@raamu-VirtualBox:~$

TO edit  the pod:

actual yaml file and once we edit it shows what are the k8 components restricted and active
once we execute the yaml file , it will creates all annotations.status from the below yaml file(template)
======================
Basic yaml file :

apiVersion: v1
kind: Pod
metadata:
  labels:
    app: busybox
  name: busybox1
  namespace: default
spec:
  containers:
  - name: busy
    image: busybox
    command:
      - sleep
      - "3600"
====================	  


raamu@raamu-VirtualBox:~$ kubectl edit pod busybox1
Edit cancelled, no changes made.

# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: v1
kind: Pod
metadata:
  annotations:
    cni.projectcalico.org/containerID: 00cf7350ba558533c5cbd49629b67bc6daf5de3b2dac9190c068abd9e510361d
    cni.projectcalico.org/podIP: 10.244.120.119/32
    cni.projectcalico.org/podIPs: 10.244.120.119/32
  creationTimestamp: "2024-08-20T08:16:22Z"
  labels:
    app: busybox
  name: busybox1
  namespace: default
  resourceVersion: "31530"
  uid: 8a831ff4-f770-4e79-9bcc-9f848bdd480e
spec:
  containers:
  - command:
    - sleep
    - "3600"
    image: busybox
    imagePullPolicy: Always
    name: busy
    resources: {}
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-8r9fb
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  nodeName: minikube
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  
 ===============================================

TO apply any changes to the yaml file:

 raamu@raamu-VirtualBox:~$ kubectl apply -f busybox.yaml
Warning: resource pods/busybox1 is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is 
required by kubectl apply. kubectl apply should only be used on resources created declaratively by either
kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
pod/busybox1 configured
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl apply -f busybox.yaml
pod/busybox1 unchanged
raamu@raamu-VirtualBox:~$

=================================================

Yaml dryrun:

It will not execute, used for testing 

raamu@raamu-VirtualBox:~$ kubectl run mynginx --image=nginx --dry-run=client -o yaml > myniginx.yml
raamu@raamu-VirtualBox:~$ ls -ltr
total 39876
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Videos
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Templates
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Public
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Pictures
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Music
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Downloads
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Documents
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Desktop
-rw-rw-r-- 1 raamu raamu 40775680 May  5 17:28 minikube-linux-amd64
drwx------ 5 raamu raamu     4096 Jul 25 12:00 snap
-rw-rw-r-- 1 raamu raamu    10339 Aug 20 01:54 nakednginx.yaml
-rw-rw-r-- 1 raamu raamu      197 Aug 20 13:45 busybox.yaml
-rw-rw-r-- 1 raamu raamu      238 Aug 20 14:11 myniginx.yml
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ cat myniginx.yml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: mynginx
  name: mynginx
spec:
  containers:
  - image: nginx
    name: mynginx
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
raamu@raamu-VirtualBox:~$

To update/apend the  yaml file through command line:

raamu@raamu-VirtualBox:~$ kubectl run mynginx1 --image=nginx --dry-run=client -- sleep 3600 > mynginx.yml

==========================================================================================
To delete pod:

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
busybox1                    1/1     Running   0          58m
mydeploy-64c98c499f-x8gp6   1/1     Running   0          88m

raamu@raamu-VirtualBox:~$ kubectl delete pod busybox1
pod "busybox1" deleted

kubectl delete all --all

TO check the Ip address of the pods:

raamu@raamu-VirtualBox:~$ kubectl get pods -o wide
NAME                        READY   STATUS    RESTARTS   AGE    IP               NODE       NOMINATED NODE   READINESS GATES
mydeploy-64c98c499f-x8gp6   1/1     Running   0          148m   10.244.120.115   minikube   <none>           <none>
raamu@raamu-VirtualBox:~$


Multi container pod:

 1.Sidecar
 2.Ambasdor
 3.Adaptor
 
i. side car:

create side car yml
 
raamu@raamu-VirtualBox:~$ kubectl create -f sidecar.yml
deployment.apps/myapp created
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
myapp-6f97c6d9d6-wcfbm      2/2     Running   0          13s
mydeploy-64c98c499f-x8gp6   1/1     Running   0          3h36m

=========================================================================
Namespaces:

To check the available namespace:

raamu@raamu-VirtualBox:~$ kubectl get namespace
NAME                   STATUS   AGE
default                Active   107d
kube-node-lease        Active   107d
kube-public            Active   107d
kube-system            Active   107d
kubernetes-dashboard   Active   107d
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl config view
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /home/raamu/.minikube/ca.crt
    extensions:
    - extension:
        last-update: Wed, 21 Aug 2024 14:18:46 IST
        provider: minikube.sigs.k8s.io
        version: v1.33.0
      name: cluster_info
    server: https://192.168.49.2:8443
  name: minikube
contexts:
- context:
    cluster: minikube
    extensions:
    - extension:
        last-update: Wed, 21 Aug 2024 14:18:46 IST
        provider: minikube.sigs.k8s.io
        version: v1.33.0
      name: context_info
    namespace: default
    user: minikube
  name: minikube
current-context: minikube
kind: Config
preferences: {}
users:
- name: minikube
  user:
    client-certificate: /home/raamu/.minikube/profiles/minikube/client.crt
    client-key: /home/raamu/.minikube/profiles/minikube/client.key
raamu@raamu-VirtualBox:~$


To create namespace:

 raamu@raamu-VirtualBox:~$ kubectl create namespace rnamespace
namespace/rnamespace created
raamu@raamu-VirtualBox:~$ kubectl get ns
NAME                   STATUS   AGE
default                Active   107d
kube-node-lease        Active   107d
kube-public            Active   107d
kube-system            Active   107d
kubernetes-dashboard   Active   107d
rnamespace             Active   12s
raamu@raamu-VirtualBox:~$

To check the resources in namespace:

since no resoucres created in ns , it shows empty:

raamu@raamu-VirtualBox:~$ kubectl get pods -n rnamespace
No resources found in rnamespace namespace.

resoucrces available in the ns:

raamu@raamu-VirtualBox:~$ kubectl get pods -n kubernetes-dashboard
NAME                                        READY   STATUS    RESTARTS      AGE
dashboard-metrics-scraper-b5fc48f67-6r4j9   1/1     Running   8 (12m ago)   107d
kubernetes-dashboard-779776cb65-znsbf       1/1     Running   8             107d
raamu@raamu-VirtualBox:~$

To switch the nampspace:

raamu@raamu-VirtualBox:~$ kubectl get ns
NAME                   STATUS   AGE
default                Active   107d
kube-node-lease        Active   107d
kube-public            Active   107d
kube-system            Active   107d
kubernetes-dashboard   Active   107d
rnamespace             Active   11m
raamu@raamu-VirtualBox:~$ kubectl config set-context --current --namespace=rnamespace
Context "minikube" modified.

raamu@raamu-VirtualBox:~$ kubectl config set-context --current --namespace=default
Context "minikube" modified.
raamu@raamu-VirtualBox:~$

To check in which namespace does the pod created:

NAMESPACE              NAME                                        READY   STATUS    RESTARTS         AGE
kube-system            calico-kube-controllers-ddf655445-gn9gz     1/1     Running   11 (6m26s ago)   107d
kube-system            calico-node-szc9l                           1/1     Running   11 (6m26s ago)   107d
kube-system            coredns-7db6d8ff4d-tw4cj                    1/1     Running   13 (6m26s ago)   107d
kube-system            etcd-minikube                               1/1     Running   11 (6m26s ago)   107d
kube-system            kube-apiserver-minikube                     1/1     Running   11 (6m26s ago)   107d
kube-system            kube-controller-manager-minikube            1/1     Running   12 (6m26s ago)   107d
kube-system            kube-proxy-ztt7n                            1/1     Running   11 (6m26s ago)   107d
kube-system            kube-scheduler-minikube                     1/1     Running   11 (6m26s ago)   107d
kube-system            storage-provisioner                         1/1     Running   22 (5m34s ago)   107d
kubernetes-dashboard   dashboard-metrics-scraper-b5fc48f67-6r4j9   1/1     Running   9 (6m26s ago)    107d
kubernetes-dashboard   kubernetes-dashboard-779776cb65-znsbf       1/1     Running   9 (6m26s ago)    107d
rnamespace             busybox1                                    1/1     Running   0                107s
raamu@raamu-VirtualBox:~$
====================================================================
raamu@raamu-VirtualBox:~$ cat namespace.yml
apiVersion: v1
kind: Pod
metadata:
  labels:
    app: busybox
  name: busybox1
  namespace: rnamespace
spec:
  containers:
  - name: busy
    image: busybox
    command:
      - sleep
      - "3600"
raamu@raamu-VirtualBox:~$
====================================================================

To check the namespace description:

raamu@raamu-VirtualBox:~$ kubectl describe ns rnamespace
Name:         rnamespace
Labels:       kubernetes.io/metadata.name=rnamespace
Annotations:  <none>
Status:       Active

No resource quota.

No LimitRange resource.
raamu@raamu-VirtualBox:~$

------------------------------------------------------------------------
Quotas:

To create quotas take the help:

raamu@raamu-VirtualBox:~$ kubectl create quota -h
Create a resource quota with the specified name, hard limits, and optional scopes.

Aliases:
quota, resourcequota

Examples:
  # Create a new resource quota named my-quota
  kubectl create quota my-quota
--hard=cpu=1,memory=1G,pods=2,services=3,replicationcontrollers=2,resourcequotas=1,secrets=5,persistentvolumeclaims=10

  # Create a new resource quota named best-effort
  kubectl create quota best-effort --hard=pods=100 --scopes=BestEffort

Options:
    --allow-missing-template-keys=true:
        If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to
        golang and jsonpath output formats.

TO create quota:

$kubectl create ns limits
$kubectl create quota --hard pos=3,cpu=100,memory=500Mi -n limits
$kubectl create deploy nginx --image=nginx -n limits
                ------                            --------
				it creates deployments		       nampspace name is limits
                and pods inside deployment
				

To set the resoucrces:

$kubectl set resources deploy nginx --requests cpu=100m,memory=5Mi --limits cpu=200m, memory -n limites
                                    ----------                      -------
									it fixes when resources         restricts teh limits fro resources			
									creates

===========================================================================================================================						
Day11: Kubernetes Security Context|jobs|Crontab:

Port Forwarding services:
 by utilizing this service we can access the pods.

$kubectl port-forward <podname> <portno> 

checking the pods to get the ipaddress and port where we need to expose with port number

raamu@raamu-VirtualBox:~$ kubectl run fwnginx --image=nginx
pod/fwnginx created
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME       READY   STATUS    RESTARTS      AGE
busybox1   1/1     Running   1 (42m ago)   102m
fwnginx    1/1     Running   0             5s
raamu@raamu-VirtualBox:~$ kubectl get pods -o wide
NAME       READY   STATUS    RESTARTS      AGE    IP              NODE       NOMINATED NODE   READINESS GATES
busybox1   1/1     Running   1 (42m ago)   102m   10.244.120.70   minikube   <none>           <none>
fwnginx    1/1     Running   0             17s    10.244.120.73   minikube   <none>           <none>
raamu@raamu-VirtualBox:~$ kubectl port-forward fwnginx 8080:80 &-->runs in background
raamu@raamu-VirtualBox:~$ kubectl port-forward fwnginx 8080:80 &
[1] 99997
raamu@raamu-VirtualBox:~$ Forwarding from 127.0.0.1:8080 -> 80
Forwarding from [::1]:8080 -> 80

raamu@raamu-VirtualBox:~$ curl localhost:8080
Handling connection for 8080
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$

to end the porr-forwarding:

raamu@raamu-VirtualBox:~$ fg
kubectl port-forward fwnginx 8080:80

TO test the application or webpage:

raamu@raamu-VirtualBox:~$ kubectl port-forward fwnginx 8080:80 &
[1] 95828
raamu@raamu-VirtualBox:~$ Forwarding from 127.0.0.1:8080 -> 80
Forwarding from [::1]:8080 -> 80

raamu@raamu-VirtualBox:~$ Handling connection for 8080
 
 now type localhost:8080 in web browser.
 
---------------------------------------------------------------------------------
 Security Context:

In K8's standard user id: 1000
In docker we use only user no user id(UID) 

pod level:

raamu@raamu-VirtualBox:~$ kubectl explain pod.spec.securityContext |less

COntainer level:
raamu@raamu-VirtualBox:~$ kubectl explain pod.spec.containers.securityContext |less 

To check the pod in interactive mode:

$kubectl exec -it <pod name> -- bash  ->>gives 126 exit code error, so use sh
$kubectl exec -it <pod name> -- sh
/ $ps
 showa the user id's

TO create job:
raamu@raamu-VirtualBox:~$ kubectl create -h |less
Create a resource from a file or from stdin.

 JSON and YAML formats are accepted.

raamu@raamu-VirtualBox:~$ kubectl create job onejob --image=busybox1 -- date
job.batch/onejob created
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME           READY   STATUS              RESTARTS   AGE
onejob-xpj7s   0/1     ContainerCreating   0          5s
raamu@raamu-VirtualBox:~$ kubectl get jobs,pods
NAME               STATUS    COMPLETIONS   DURATION   AGE
job.batch/onejob   Running   0/1           35s        35s

NAME               READY   STATUS         RESTARTS   AGE
pod/onejob-xpj7s   0/1     ErrImagePull   0          35s
raamu@raamu-VirtualBox:~$

to delete job: (if we delete job -> pod also will delete)

raamu@raamu-VirtualBox:~$ kubectl delete job onejob
job.batch "onejob" deleted
raamu@raamu-VirtualBox:~$ kubectl get jobs,pods
No resources found in rnamespace namespace.
raamu@raamu-VirtualBox:~$


TO check the restartpolicy :

raamu@raamu-VirtualBox:~$ kubectl get jobs -o yaml |grep -i restartpolicy
        restartPolicy: Never
raamu@raamu-VirtualBox:~$
=============================================================================================================================
creating yaml job fie:

raamu@raamu-VirtualBox:~$ kubectl create job mynewjob --image=busybox --dry-run=client -o yaml -- sleep 5 >mynewjob.yml
raamu@raamu-VirtualBox:~$

creates the below file by appending busybox and after we added completions: 3
  ttlSecondsAfterFinished: 60

raamu@raamu-VirtualBox:~$ cat mynewjob.yml
apiVersion: batch/v1
kind: Job
metadata:
  creationTimestamp: null
  name: mynewjob
spec:
  completions: 3
  ttlSecondsAfterFinished: 60
  template:
    metadata:
      creationTimestamp: null
    spec:
      containers:
      - command:
        - sleep
        - "5"
        image: busybox
        name: mynewjob
        resources: {}
      restartPolicy: Never
status: {}
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl create -f mynewjob.yml
job.batch/mynewjob created
raamu@raamu-VirtualBox:~$ kubectl get jobs,pods
NAME                 STATUS    COMPLETIONS   DURATION   AGE
job.batch/mynewjob   Running   1/3           23s        23s

NAME                 READY   STATUS      RESTARTS   AGE
pod/mynewjob-74vtf   0/1     Completed   0          11s
pod/mynewjob-wjk8r   0/1     Completed   0          23s
raamu@raamu-VirtualBox:~$ kubectl get jobs,pods
NAME                 STATUS     COMPLETIONS   DURATION   AGE
job.batch/mynewjob   Complete   3/3           36s        43s

NAME                 READY   STATUS      RESTARTS   AGE
pod/mynewjob-74vtf   0/1     Completed   0          31s
pod/mynewjob-npk4d   0/1     Completed   0          19s
pod/mynewjob-wjk8r   0/1     Completed   0          43s
raamu@raamu-VirtualBox:~$

*************shows the 3 jobs completed , so this senario will delete after 60 secs

raamu@raamu-VirtualBox:~$ kubectl get jobs,pods
NAME                 STATUS     COMPLETIONS   DURATION   AGE
job.batch/mynewjob   Complete   3/3           36s        89s

NAME                 READY   STATUS      RESTARTS   AGE
pod/mynewjob-74vtf   0/1     Completed   0          77s
pod/mynewjob-npk4d   0/1     Completed   0          65s
pod/mynewjob-wjk8r   0/1     Completed   0          89s
raamu@raamu-VirtualBox:~$ kubectl get jobs,pods
No resources found in rnamespace namespace.

If we describe the job, by default it shows parallelism as 1

raamu@raamu-VirtualBox:~$ kubectl describe job mynewjob
Name:                        mynewjob
Namespace:                   rnamespace
Selector:                    batch.kubernetes.io/controller-uid=4c125c3e-6f3a-4f88-8716-54873094b7ab
Labels:                      batch.kubernetes.io/controller-uid=4c125c3e-6f3a-4f88-8716-54873094b7ab
                             batch.kubernetes.io/job-name=mynewjob
                             controller-uid=4c125c3e-6f3a-4f88-8716-54873094b7ab
                             job-name=mynewjob
Annotations:                 <none>
Parallelism:                 1
Completions:                 3
Completion Mode:             NonIndexed
Suspend:                     false
Backoff Limit:               6
TTL Seconds After Finished:  60
Start Time:                  Wed, 21 Aug 2024 17:55:48 +0530
Pods Statuses:               1 Active (0 Ready) / 2 Succeeded / 0 Failed
Pod Template:
  Labels:  batch.kubernetes.io/controller-uid=4c125c3e-6f3a-4f88-8716-54873094b7ab
           batch.kubernetes.io/job-name=mynewjob
           controller-uid=4c125c3e-6f3a-4f88-8716-54873094b7ab
           job-name=mynewjob
  Containers:
   mynewjob:
    Image:      busybox
    Port:       <none>
    Host Port:  <none>
    Command:
      sleep
      5
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Events:
  Type    Reason            Age   From            Message
  ----    ------            ----  ----            -------
  Normal  SuccessfulCreate  29s   job-controller  Created pod: mynewjob-tk9cp
  Normal  SuccessfulCreate  15s   job-controller  Created pod: mynewjob-76w8d
  Normal  SuccessfulCreate  3s    job-controller  Created pod: mynewjob-g28bc
raamu@raamu-VirtualBox:~$

If we want to run jobs parallelly add the parallelism

apiVersion: batch/v1
kind: Job
metadata:
  creationTimestamp: null
  name: mynewjob
spec:
  completions: 3
  parallelism: 3
  ttlSecondsAfterFinished: 60
  template:
    metadata:
      creationTimestamp: null
    spec:
      containers:
      - command:
        - sleep
        - "5"
        image: busybox
        name: mynewjob
        resources: {}
      restartPolicy: Never
status: {}

=============================================================================================================================
 
crontab:

raamu@raamu-VirtualBox:~$ kubectl create cronjab -h |less


kubectl create cronjob rume --image=busybox --schedule="+/1 * * * * *" --echo hello

-------------------------------------------------------------------------------------------------------

Day 12: Kubernetes Resource Limiations |Deployment:

***************The CPU/RAM limitations all managed by Kube-Scheduler in MAster node .
*************The resources we are able to convert only on deployments and containers not on PODS

             ========================================
			 ||                                    ||
			 ||			 Till this PODS has done   ||
	         ||                                    ||
             ||                                    ||
		     ========================================
			 


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$Deployment$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

=> 2 methods to deploy application:
  i. kubectl create deploy(short form of deployment)
  ii. By using YAML files
  
 raamu@raamu-VirtualBox:~$ kubectl create deployment myweb --image=nginx --replicas=3
deployment.apps/myweb created											 ------------
																		which creates 3 containers in a pod
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                     READY   STATUS              RESTARTS   AGE
myweb-59dbdfc554-2vwkc   0/1     ContainerCreating   0          7s
myweb-59dbdfc554-bklml   0/1     ContainerCreating   0          7s
myweb-59dbdfc554-gz64h   1/1     Running             0          7s
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl get deployments
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
myweb   3/3     3            3           65s
raamu@raamu-VirtualBox:~$

To get teh details of deployment:


raamu@raamu-VirtualBox:~$ kubectl describe deployment myweb
Name:                   myweb
Namespace:              rnamespace
CreationTimestamp:      Wed, 21 Aug 2024 19:41:51 +0530
Labels:                 app=myweb
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=myweb
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=myweb
  Containers:
   nginx:
    Image:         nginx
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   myweb-59dbdfc554 (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  3m4s  deployment-controller  Scaled up replica set myweb-59dbdfc554 to 3
raamu@raamu-VirtualBox:~$

****Application name is updated under Labels.
                                      ------
To get the details of pod, containers and deployment:

raamu@raamu-VirtualBox:~$ kubectl get all
NAME                         READY   STATUS    RESTARTS   AGE
pod/myweb-59dbdfc554-2vwkc   1/1     Running   0          4m43s
pod/myweb-59dbdfc554-bklml   1/1     Running   0          4m43s
pod/myweb-59dbdfc554-gz64h   1/1     Running   0          4m43s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/myweb   3/3     3            3           4m43s

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/myweb-59dbdfc554   3         3         3       4m43s
raamu@raamu-VirtualBox:~$


==>>Managing the Scalability:

-> In older versions, we do not have deployment in kubernetes. so earlier it has done through replication controllers.
                                                                                              -----------------------
																							  where we need to create replicasets
																							  seperately and manage them

raamu@raamu-VirtualBox:~$ kubectl api-resources |less
 
 So in deployment replicasets will be automatically created.*********************
 
 To Scale up Replicas :
 
 $kubectl scale deploy myweb --replicas=4 (ensure if we increase the replicas we need that much amount of resources CPU/RAM)
                                   ******It creates replicas along wiht pods, but if we create POD , replicas will not create 
 
 and we can do by edidting but not all resources will be added
 
raamu@raamu-VirtualBox:~$ kubectl edit deploy
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  creationTimestamp: "2024-08-21T14:11:51Z"
  generation: 1
  labels:
    app: myweb
  name: myweb
  namespace: rnamespace
  resourceVersion: "58929"
  uid: 792b0c17-e040-4cbf-b7b6-90945a959919
spec:


To get a specific pod information:

raamu@raamu-VirtualBox:~$ kubectl get pods --selector app=myweb
NAME                     READY   STATUS    RESTARTS   AGE
myweb-59dbdfc554-2vwkc   1/1     Running   0          28m
myweb-59dbdfc554-bklml   1/1     Running   0          28m
myweb-59dbdfc554-gz64h   1/1     Running   0          28m
raamu@raamu-VirtualBox:~$

*****If we delete the pod replicaset will mmonitor and creates the new pods


raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
myweb-59dbdfc554-2vwkc   1/1     Running   0          31m
myweb-59dbdfc554-bklml   1/1     Running   0          31m
myweb-59dbdfc554-gz64h   1/1     Running   0          31m
raamu@raamu-VirtualBox:~$ kubectl delete pod myweb-59dbdfc554-2vwkc
pod "myweb-59dbdfc554-2vwkc" deleted
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                     READY   STATUS              RESTARTS   AGE
myweb-59dbdfc554-5rgrh   0/1     ContainerCreating   0          5s
myweb-59dbdfc554-bklml   1/1     Running             0          31m
myweb-59dbdfc554-gz64h   1/1     Running             0          31m
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl get all
NAME                         READY   STATUS    RESTARTS   AGE
pod/myweb-59dbdfc554-5rgrh   1/1     Running   0          68s
pod/myweb-59dbdfc554-bklml   1/1     Running   0          32m
pod/myweb-59dbdfc554-gz64h   1/1     Running   0          32m

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/myweb   3/3     3            3           32m

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/myweb-59dbdfc554   3         3         3       32m
raamu@raamu-VirtualBox:~$ kubectl delete replicaset.apps/myweb-59dbdfc554
replicaset.apps "myweb-59dbdfc554" deleted
raamu@raamu-VirtualBox:~$ kubectl get all
NAME                         READY   STATUS              RESTARTS   AGE
pod/myweb-59dbdfc554-2mlkh   0/1     ContainerCreating   0          4s
pod/myweb-59dbdfc554-5rgrh   1/1     Terminating         0          4m13s
pod/myweb-59dbdfc554-bklml   1/1     Terminating         0          36m
pod/myweb-59dbdfc554-gz64h   0/1     Terminating         0          36m
pod/myweb-59dbdfc554-h4nv2   0/1     ContainerCreating   0          4s
pod/myweb-59dbdfc554-mrr5x   0/1     ContainerCreating   0          4s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/myweb   0/3     3            0           36m

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/myweb-59dbdfc554   3         3         0       5s
raamu@raamu-VirtualBox:~$  kubectl get all
NAME                         READY   STATUS    RESTARTS   AGE
pod/myweb-59dbdfc554-2mlkh   1/1     Running   0          3m12s
pod/myweb-59dbdfc554-h4nv2   1/1     Running   0          3m12s
pod/myweb-59dbdfc554-mrr5x   1/1     Running   0          3m12s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/myweb   3/3     3            3           39m

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/myweb-59dbdfc554   3         3         3       3m13s
raamu@raamu-VirtualBox:~$

To delete:

raamu@raamu-VirtualBox:~$ kubectl delete all --all
pod "myweb-59dbdfc554-2mlkh" deleted
pod "myweb-59dbdfc554-h4nv2" deleted
pod "myweb-59dbdfc554-mrr5x" deleted
deployment.apps "myweb" deleted
replicaset.apps "myweb-59dbdfc554" deleted
raamu@raamu-VirtualBox:~$ kubectl get all
No resources found in rnamespace namespace.
raamu@raamu-VirtualBox:~$

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$Deployment Strategy$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

Creating deployment:

$kubectl delete all --all -> to delete all pods/containers

*Ensure in which namespace we creating.

raamu@raamu-VirtualBox:~$ kubectl config set-context --current --namespace=rnamespace
Context "minikube" modified.
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubens
default
kube-node-lease
kube-public
kube-system
kubernetes-dashboard
rnamespace
raamu@raamu-VirtualBox:~$ kubectl get pds -A
error: the server doesn't have a resource type "pds"
raamu@raamu-VirtualBox:~$ kubectl get pods -a
error: unknown shorthand flag: 'a' in -a
See 'kubectl get --help' for usage.
raamu@raamu-VirtualBox:~$ kubectl get pods -A
NAMESPACE              NAME                                        READY   STATUS    RESTARTS       AGE
kube-system            calico-kube-controllers-ddf655445-gn9gz     1/1     Running   12 (18m ago)   108d
kube-system            calico-node-szc9l                           1/1     Running   12 (18m ago)   108d
kube-system            coredns-7db6d8ff4d-tw4cj                    1/1     Running   14 (18m ago)   108d
kube-system            etcd-minikube                               1/1     Running   12 (18m ago)   108d
kube-system            kube-apiserver-minikube                     1/1     Running   13 (17m ago)   108d
kube-system            kube-controller-manager-minikube            1/1     Running   14 (17m ago)   108d
kube-system            kube-proxy-ztt7n                            1/1     Running   12 (18m ago)   108d
kube-system            kube-scheduler-minikube                     1/1     Running   12 (18m ago)   108d
kube-system            storage-provisioner                         1/1     Running   24 (16m ago)   108d
kubernetes-dashboard   dashboard-metrics-scraper-b5fc48f67-6r4j9   1/1     Running   10 (18m ago)   108d
kubernetes-dashboard   kubernetes-dashboard-779776cb65-znsbf       1/1     Running   10 (18m ago)   108d

*Creating deployment:


raamu@raamu-VirtualBox:~$ kubectl create deploy nginx --image=nginx
deployment.apps/nginx created

*get teh pods:

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS              RESTARTS   AGE
nginx-bf5d5cf98-87xw7   0/1     ContainerCreating   0          6s

*get teh deployment details: 
like pod/container, deploymemnt,replicaset

raamu@raamu-VirtualBox:~$ kubectl get all
NAME                        READY   STATUS    RESTARTS   AGE
pod/nginx-bf5d5cf98-87xw7   1/1     Running   0          25s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx   1/1     1            1           25s

NAME                              DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-bf5d5cf98   1         1         1       25s

* get deployment name, status

raamu@raamu-VirtualBox:~$ kubectl get deploy
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   1/1     1            1           41s

*describe the deployment where in this details by defult we Label and selector and versions

raamu@raamu-VirtualBox:~$ kubectl describe deploy nginx
Name:                   nginx
Namespace:              rnamespace
CreationTimestamp:      Thu, 22 Aug 2024 14:02:34 +0530
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=nginx
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:         nginx
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   nginx-bf5d5cf98 (1/1 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  65s   deployment-controller  Scaled up replica set nginx-bf5d5cf98 to 1
raamu@raamu-VirtualBox:~$


* SELECTOR is used to select specific application if muleiple applications running in container
 Deployment checks on based on label
 like while we give a app name app=nginx  , this will assign to the LABEL
 
 ANNOTATIONS : we can give metadata information:
 
 

raamu@raamu-VirtualBox:~$ kubectl get all --selector app=nginx
NAME                        READY   STATUS    RESTARTS   AGE
pod/nginx-bf5d5cf98-87xw7   1/1     Running   0          6m27s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx   1/1     1            1           6m27s

NAME                              DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-bf5d5cf98   1         1         1       6m27s
raamu@raamu-VirtualBox:~$

*get the details of app related pod and deployment details 

raamu@raamu-VirtualBox:~$ kubectl  get deploy --selector app=nginx
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   1/1     1            1           11m
raamu@raamu-VirtualBox:~$ kubectl  get pod --selector app=nginx
NAME                    READY   STATUS    RESTARTS   AGE
nginx-bf5d5cf98-87xw7   1/1     Running   0          11m
raamu@raamu-VirtualBox:~$

To get the pod/container related details:

raamu@raamu-VirtualBox:~$ kubectl describe pod/nginx-bf5d5cf98-87xw7
Name:             nginx-bf5d5cf98-87xw7
Namespace:        rnamespace
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Thu, 22 Aug 2024 14:02:34 +0530
Labels:           app=nginx
                  pod-template-hash=bf5d5cf98
Annotations:      cni.projectcalico.org/containerID: 9cd4c2dd261fe9c16d2e104ac4cfc799a6cb4c7ca6aafe0f95f5f105e0d1f5db
                  cni.projectcalico.org/podIP: 10.244.120.86/32
                  cni.projectcalico.org/podIPs: 10.244.120.86/32
Status:           Running
IP:               10.244.120.86
IPs:
  IP:           10.244.120.86
Controlled By:  ReplicaSet/nginx-bf5d5cf98
Containers:
  nginx:
    Container ID:   docker://198df10de12a3369aed499c5083a2075f3c90560f79948dc01e0eb5cf28eec2a
    Image:          nginx
    Image ID:       docker-pullable://nginx@sha256:447a8665cc1dab95b1ca778e162215839ccbb9189104c79d7ec3a81e14577add
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Thu, 22 Aug 2024 14:02:40 +0530
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-msq88 (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       True
  ContainersReady             True
  PodScheduled                True
Volumes:
  kube-api-access-msq88:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  15m   default-scheduler  Successfully assigned rnamespace/nginx-bf5d5cf98-87xw7 to minikube
  Normal  Pulling    15m   kubelet            Pulling image "nginx"
  Normal  Pulled     15m   kubelet            Successfully pulled image "nginx" in 2.943s (2.943s including waiting). Image size: 187694648 bytes.
  Normal  Created    15m   kubelet            Created container nginx
  Normal  Started    15m   kubelet            Started container nginx
raamu@raamu-VirtualBox:~$

========================================================================================================

To upgrade teh Image version:

shows what components we can change/update/upgrade

raamu@raamu-VirtualBox:~$ kubectl set -h
Configure application resources.

 These commands help you make changes to existing application resources.

Available Commands:
  env              Update environment variables on a pod template
  image            Update the image of a pod template
  resources        Update resource requests/limits on objects with pod templates
  selector         Set the selector on a resource
  serviceaccount   Update the service account of a resource
  subject          Update the user, group, or service account in a role binding or cluster role binding

Usage:
  kubectl set SUBCOMMAND [options]

Use "kubectl set <command> --help" for more information about a given command.
Use "kubectl options" for a list of global command-line options (applies to all commands).
raamu@raamu-VirtualBox:~$


* by using this update/upgrade of version old version will deleted and new version will create.

Manual update:

step1:

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
nginx-bf5d5cf98-87xw7   1/1     Running   0          22m

step2:

raamu@raamu-VirtualBox:~$ kubectl describe deploy nginx
Name:                   nginx
Namespace:              rnamespace
CreationTimestamp:      Thu, 22 Aug 2024 14:02:34 +0530
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=nginx
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:         nginx ------------------------------> about to change to v1.7
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   nginx-bf5d5cf98 (1/1 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  22m   deployment-controller  Scaled up replica set nginx-bf5d5cf98 to 1
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$

step3:

raamu@raamu-VirtualBox:~$ kubectl set image deploy nginx nginx=nginx:1.17
deployment.apps/nginx image updated

step4:

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS              RESTARTS   AGE
nginx-559d86675-p7bnn   0/1     ContainerCreating   0          10s ---->new
nginx-bf5d5cf98-87xw7   1/1     Running             0          23m ---->old
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS              RESTARTS   AGE
nginx-559d86675-p7bnn   0/1     ContainerCreating   0          16s
nginx-bf5d5cf98-87xw7   1/1     Running             0          23m
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
nginx-559d86675-p7bnn   1/1     Running   0          26s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
nginx-559d86675-p7bnn   1/1     Running   0          32s---->new created old deleted
raamu@raamu-VirtualBox:~$

step5:

raamu@raamu-VirtualBox:~$ kubectl describe deploy
Name:                   nginx
Namespace:              rnamespace
CreationTimestamp:      Thu, 22 Aug 2024 14:02:34 +0530
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision: 2
Selector:               app=nginx
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:         nginx:1.17  --------------------------------->version change
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  nginx-bf5d5cf98 (0/0 replicas created)
NewReplicaSet:   nginx-559d86675 (1/1 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  26m    deployment-controller  Scaled up replica set nginx-bf5d5cf98 to 1
  Normal  ScalingReplicaSet  3m35s  deployment-controller  Scaled up replica set nginx-559d86675 to 1
  Normal  ScalingReplicaSet  3m15s  deployment-controller  Scaled down replica set nginx-bf5d5cf98 to 0 from 1
raamu@raamu-VirtualBox:~$


Update strategies: which is automate the version upgrade 





========================================================================================

TO add a label check the details:

raamu@raamu-VirtualBox:~$ kubectl label -h
Update the labels on a resource.

  *  A label key and value must begin with a letter or number, and may contain letters, numbers, hyphens, dots, and
underscores, up to 63 characters each.

step1:

raamu@raamu-VirtualBox:~$ kubectl create deploy bluelabel --image=nginx
deployment.apps/bluelabel created

step2:

add label to the deployment bluelabel

raamu@raamu-VirtualBox:~$ kubectl label deploy bluelabel state=demo
deployment.apps/bluelabel labeled

step3:

raamu@raamu-VirtualBox:~$ kubectl describe deploy
Name:                   bluelabel
Namespace:              rnamespace
CreationTimestamp:      Thu, 22 Aug 2024 15:20:42 +0530
Labels:                 app=bluelabel
                        state=demo
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=bluelabel
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=bluelabel
  Containers:
   nginx:
    Image:         nginx
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   bluelabel-64c5d9799b (1/1 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  15m   deployment-controller  Scaled up replica set bluelabel-64c5d9799b to 1
  

step4:

*To check what are the lables assigned to alll pods:

raamu@raamu-VirtualBox:~$ kubectl get deploy --show-labels
NAME        READY   UP-TO-DATE   AVAILABLE   AGE   LABELS
bluelabel   1/1     1            1           22m   app=bluelabel,state=demo
raamu@raamu-VirtualBox:~$

step5:

  
raamu@raamu-VirtualBox:~$ kubectl get all
NAME                             READY   STATUS    RESTARTS   AGE
pod/bluelabel-64c5d9799b-v4hwk   1/1     Running   0          16m

NAME                        READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/bluelabel   1/1     1            1           16m

NAME                                   DESIRED   CURRENT   READY   AGE
replicaset.apps/bluelabel-64c5d9799b   1         1         1       16m
raamu@raamu-VirtualBox:~$ 

step6:

shows the deployment :

raamu@raamu-VirtualBox:~$ kubectl get all --show-labels --selector state=demo ->>changes name for deploymemnt
NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   LABELS
deployment.apps/bluelabel   1/1     1            1           23m   app=bluelabel,state=demo
raamu@raamu-VirtualBox:~$

shows all deployed pods related label names

raamu@raamu-VirtualBox:~$ kubectl get all --show-labels
NAME                             READY   STATUS    RESTARTS   AGE   LABELS
pod/bluelabel-64c5d9799b-v4hwk   1/1     Running   0          54m   pod-template-hash=64c5d9799b

NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   LABELS
deployment.apps/bluelabel   1/1     1            1           54m   app=bluelabel,state=demo

NAME                                   DESIRED   CURRENT   READY   AGE   LABELS
replicaset.apps/bluelabel-64c5d9799b   1         1         1       54m   app=bluelabel,pod-template-hash=64c5d9799b


raamu@raamu-VirtualBox:~$ kubectl describe deploy bluelabel
Name:                   bluelabel
Namespace:              rnamespace
CreationTimestamp:      Thu, 22 Aug 2024 15:20:42 +0530
Labels:                 app=bluelabel
                        state=demo               --------------------------->assigned the label name
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=bluelabel
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=bluelabel
  Containers:
   nginx:
    Image:         nginx
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   bluelabel-64c5d9799b (1/1 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  25m   deployment-controller  Scaled up replica set bluelabel-64c5d9799b to 1
raamu@raamu-VirtualBox:~$


To change the default label for the pod:

**Deployment always monitors trough labels and selectors.****

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                         READY   STATUS    RESTARTS   AGE
bluelabel-64c5d9799b-v4hwk   1/1     Running   0          27m

when we remove the label , It creates a new pod, but old pod not deleting , because Lable always monitor the deployment label name

raamu@raamu-VirtualBox:~$ kubectl label pod bluelabel-64c5d9799b-v4hwk app-
pod/bluelabel-64c5d9799b-v4hwk unlabeled

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                         READY   STATUS    RESTARTS   AGE
bluelabel-64c5d9799b-9m56w   1/1     Running   0          18s ->new created
bluelabel-64c5d9799b-v4hwk   1/1     Running   0          28m -> old
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                         READY   STATUS    RESTARTS   AGE
bluelabel-64c5d9799b-9m56w   1/1     Running   0          24s
bluelabel-64c5d9799b-v4hwk   1/1     Running   0          28m
raamu@raamu-VirtualBox:~$


raamu@raamu-VirtualBox:~$ kubectl get all --show-labels
NAME                             READY   STATUS    RESTARTS   AGE   LABELS
pod/bluelabel-64c5d9799b-9m56w   1/1     Running   0          35m   app=bluelabel,pod-template-hash=64c5d9799b
pod/bluelabel-64c5d9799b-v4hwk   1/1     Running   0          63m   pod-template-hash=64c5d9799b

NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   LABELS
deployment.apps/bluelabel   1/1     1            1           63m   app=bluelabel,state=demo

NAME                                   DESIRED   CURRENT   READY   AGE   LABELS
replicaset.apps/bluelabel-64c5d9799b   1         1         1       63m   app=bluelabel,pod-template-hash=64c5d9799b
raamu@raamu-VirtualBox:~$


TO delete the label:

raamu@raamu-VirtualBox:~$ kubectl label pods foo bar-
Error from server (NotFound): pods "foo" not found

Suppose if we delete the pod which we re-named the updated label
It will not create again:

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                         READY   STATUS    RESTARTS   AGE
bluelabel-64c5d9799b-9m56w   1/1     Running   0          40m -->new
bluelabel-64c5d9799b-v4hwk   1/1     Running   0          68m -->old

raamu@raamu-VirtualBox:~$ kubectl delete pod bluelabel-64c5d9799b-9m56w
pod "bluelabel-64c5d9799b-9m56w" deleted

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                         READY   STATUS    RESTARTS   AGE
bluelabel-64c5d9799b-v4hwk   1/1     Running   0          68m -->old

If we delete the default pod , it will recreates again with  different pod name

raamu@raamu-VirtualBox:~$ kubectl delete pod bluelabel-64c5d9799b-v4hwk
pod "bluelabel-64c5d9799b-v4hwk" deleted
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                         READY   STATUS    RESTARTS   AGE
bluelabel-64c5d9799b-fzc62   1/1     Running   0          40s



====================================================================================================

Update strategies:

Recreate -> we never use
Rolling update:

to check the rollout history:

raamu@raamu-VirtualBox:~$ kubectl get deploy
NAME        READY   UP-TO-DATE   AVAILABLE   AGE
bluelabel   1/1     1            1           129m

raamu@raamu-VirtualBox:~$  kubectl rollout -h
Manage the rollout of one or many resources.

 Valid resource types include:

  *  deployments
  *  daemonsets
  *  statefulsets

step1

it done only 1 revision

raamu@raamu-VirtualBox:~$ kubectl rollout history deploy bluelabel
deployment.apps/bluelabel
REVISION  CHANGE-CAUSE
1         <none>

raamu@raamu-VirtualBox:~$


we can undo the rollout

 --------------------------------
 
 we can find the rolling update strategy in deployments:
 
 Options to rollout:

Max unavailable :

Max number of pods that should be updated at same time

eg: out of 4 pods, we mention max=1 or 25% , it will bringdown only 1 pod  and other should up and run

maxsurge  :

the number of max can run heyond the desired number of pods
eg: In pod if we mention 4 replicaset 
   then desired would be 4  and if we have max surge is 6
    During update  if we mention max=1 and in surge=6  out of 4 (1 will down and 3 available) 
	so based on surge 3 more new versions of pods will create that means now total we have 6 pods 3 old and 3 new
	next stage out of 3 old another goes down then we have 2 old and 3 new we have then surge creates 1 more new
	then we have toatal 4 new versions which matchs the desired replica 0f 4
	
	in next stage , since we have all 4 pods are updated with new versions the remaining 2 goes down
	
	SO in total, we have 4 new versions of pod available


 
 raamu@raamu-VirtualBox:~$ kubectl get deploy
NAME        READY   UP-TO-DATE   AVAILABLE   AGE
bluelabel   1/1     1            1           137m
raamu@raamu-VirtualBox:~$ kubectl describe deploy bluelabel
Name:                   bluelabel
Namespace:              rnamespace
CreationTimestamp:      Thu, 22 Aug 2024 15:20:42 +0530
Labels:                 app=bluelabel
                        state=demo
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=bluelabel
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable ---------->
StrategyType:           RollingUpdate ----------------------------------------------------------->
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge-------------------------------------->
Pod Template:
  Labels:  app=bluelabel
  Containers:
   nginx:
    Image:         nginx
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Progressing    True    NewReplicaSetAvailable
  Available      True    MinimumReplicasAvailable
OldReplicaSets:  <none>
NewReplicaSet:   bluelabel-64c5d9799b (1/1 replicas created)
Events:          <none>
raamu@raamu-VirtualBox:~$


sureg example:

raamu@raamu-VirtualBox:~$ kubectl scale deploy bluelabel --replicas=8
deployment.apps/bluelabel scaled
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl scale deploy bluelabel --replicas=8
deployment.apps/bluelabel scaled
raamu@raamu-VirtualBox:~$ kubectl describe deploy bluelabel
Name:                   bluelabel
Namespace:              rnamespace
CreationTimestamp:      Thu, 22 Aug 2024 15:20:42 +0530
Labels:                 app=bluelabel
                        state=demo
Annotations:            deployment.kubernetes.io/revision: 2
Selector:               app=bluelabel
Replicas:               4 desired | 4 updated | 4 total | 4 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=bluelabel
  Containers:
   nginx:
    Image:      nginx
    Port:       <none>
    Host Port:  <none>
    Environment:
      type:        dev
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  bluelabel-64c5d9799b (0/0 replicas created)
NewReplicaSet:   bluelabel-7dc6487b67 (4/4 replicas created)
Events:
  Type    Reason             Age                  From                   Message
  ----    ------             ----                 ----                   -------
  Normal  ScalingReplicaSet  7m40s                deployment-controller  Scaled up replica set bluelabel-64c5d9799b to 8 from 1
  Normal  ScalingReplicaSet  5m35s                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 2
  Normal  ScalingReplicaSet  5m34s                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 6 from 8
  Normal  ScalingReplicaSet  5m33s                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 4 from 2
  Normal  ScalingReplicaSet  5m6s                 deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 5 from 6
  Normal  ScalingReplicaSet  5m6s                 deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 5 from 4
  Normal  ScalingReplicaSet  4m55s                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 4 from 5
  Normal  ScalingReplicaSet  4m55s                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 6 from 5
  Normal  ScalingReplicaSet  4m52s                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 3 from 4
  Normal  ScalingReplicaSet  42s (x6 over 4m51s)  deployment-controller  (combined from similar events): Scaled down replica set bluelabel-7dc6487b67 to 4 from 8
raamu@raamu-VirtualBox:~$


raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                         READY   STATUS    RESTARTS   AGE
bluelabel-7dc6487b67-2mfg8   1/1     Running   0          5m7s
bluelabel-7dc6487b67-48rl6   1/1     Running   0          5m16s
bluelabel-7dc6487b67-nfzh6   1/1     Running   0          5m58s
bluelabel-7dc6487b67-nlhbd   1/1     Running   0          6m
raamu@raamu-VirtualBox:~$


setting env varibale for deployment

raamu@raamu-VirtualBox:~$ kubectl set env deploy bluelabel type=dev
deployment.apps/bluelabel env updated
raamu@raamu-VirtualBox:~$


if we want to cahnge teh surege

edit and udpate.

raamu@raamu-VirtualBox:~$ kubectl edit deploy bluelabel
deployment.apps/bluelabel edited
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl apply deploy bluelabel
error: Unexpected args: [deploy bluelabel]
See 'kubectl apply -h' for help and examples
raamu@raamu-VirtualBox:~$ kubectl describe deploy bluelabel
Name:                   bluelabel
Namespace:              rnamespace
CreationTimestamp:      Thu, 22 Aug 2024 15:20:42 +0530
Labels:                 app=bluelabel
                        state=demo
Annotations:            deployment.kubernetes.io/revision: 2
Selector:               app=bluelabel
Replicas:               4 desired | 4 updated | 4 total | 4 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 50% max surge
Pod Template:
  Labels:  app=bluelabel
  Containers:
   nginx:
    Image:      nginx
    Port:       <none>
    Host Port:  <none>
    Environment:
      type:        dev
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  bluelabel-64c5d9799b (0/0 replicas created)
NewReplicaSet:   bluelabel-7dc6487b67 (4/4 replicas created)
Events:
  Type    Reason             Age                From                   Message
  ----    ------             ----               ----                   -------
  Normal  ScalingReplicaSet  17m                deployment-controller  Scaled up replica set bluelabel-64c5d9799b to 8 from 1
  Normal  ScalingReplicaSet  14m                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 2
  Normal  ScalingReplicaSet  14m                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 6 from 8
  Normal  ScalingReplicaSet  14m                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 4 from 2
  Normal  ScalingReplicaSet  14m                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 5 from 6
  Normal  ScalingReplicaSet  14m                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 5 from 4
  Normal  ScalingReplicaSet  14m                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 4 from 5
  Normal  ScalingReplicaSet  14m                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 6 from 5
  Normal  ScalingReplicaSet  14m                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 3 from 4
  Normal  ScalingReplicaSet  10m (x6 over 14m)  deployment-controller  (combined from similar events): Scaled down replica set bluelabel-7dc6487b67 to 4 from 8
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl rollout history deploy
deployment.apps/bluelabel
REVISION  CHANGE-CAUSE
1         <none>
2         <none>



*edit and change the label:

raamu@raamu-VirtualBox:~$ kubectl edit deploy bluelabel
deployment.apps/bluelabel edited
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                         READY   STATUS    RESTARTS   AGE
bluelabel-5f5b57465d-89zhg   1/1     Running   0          49s
bluelabel-5f5b57465d-9lbwv   1/1     Running   0          51s
bluelabel-5f5b57465d-qh6qj   1/1     Running   0          29s
bluelabel-5f5b57465d-tm8z5   1/1     Running   0          50s


raamu@raamu-VirtualBox:~$ kubectl rollout history deploy
deployment.apps/bluelabel
REVISION  CHANGE-CAUSE
1         <none>
2         <none>
3         <none>

raamu@raamu-VirtualBox:~$ kubectl rollout history deploy
deployment.apps/bluelabel
REVISION  CHANGE-CAUSE
1         <none>
2         <none>
3         <none>

raamu@raamu-VirtualBox:~$ kubectl describe deploy bluelabel
Name:                   bluelabel
Namespace:              rnamespace
CreationTimestamp:      Thu, 22 Aug 2024 15:20:42 +0530
Labels:                 app=bluelabel
                        state=demo
Annotations:            deployment.kubernetes.io/revision: 3
Selector:               app=bluelabel
Replicas:               4 desired | 4 updated | 4 total | 4 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 50% max surge
Pod Template:
  Labels:  app=bluelabel
  Containers:
   nginx:
    Image:      nginx:1.17
    Port:       <none>
    Host Port:  <none>
    Environment:
      type:        dev
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  bluelabel-64c5d9799b (0/0 replicas created), bluelabel-7dc6487b67 (0/0 replicas created)
NewReplicaSet:   bluelabel-5f5b57465d (4/4 replicas created)
Events:
  Type    Reason             Age                From                   Message
  ----    ------             ----               ----                   -------
  Normal  ScalingReplicaSet  24m                deployment-controller  Scaled up replica set bluelabel-64c5d9799b to 8 from 1
  Normal  ScalingReplicaSet  22m                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 2
  Normal  ScalingReplicaSet  22m                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 6 from 8
  Normal  ScalingReplicaSet  22m                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 4 from 2
  Normal  ScalingReplicaSet  22m                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 5 from 6
  Normal  ScalingReplicaSet  22m                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 5 from 4
  Normal  ScalingReplicaSet  21m                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 4 from 5
  Normal  ScalingReplicaSet  21m                deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 6 from 5
  Normal  ScalingReplicaSet  21m                deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 3 from 4
  Normal  ScalingReplicaSet  17m (x6 over 21m)  deployment-controller  (combined from similar events): Scaled down replica set bluelabel-7dc6487b67 to 4 from 8
  Normal  ScalingReplicaSet  2m23s              deployment-controller  Scaled up replica set bluelabel-5f5b57465d to 2
  Normal  ScalingReplicaSet  2m22s              deployment-controller  Scaled down replica set bluelabel-7dc6487b67 to 3 from 4
  Normal  ScalingReplicaSet  2m21s              deployment-controller  Scaled up replica set bluelabel-5f5b57465d to 3 from 2
  Normal  ScalingReplicaSet  2m1s               deployment-controller  Scaled down replica set bluelabel-7dc6487b67 to 2 from 3
  Normal  ScalingReplicaSet  2m1s               deployment-controller  Scaled up replica set bluelabel-5f5b57465d to 4 from 3
  Normal  ScalingReplicaSet  113s               deployment-controller  Scaled down replica set bluelabel-7dc6487b67 to 1 from 2
  Normal  ScalingReplicaSet  111s               deployment-controller  Scaled down replica set bluelabel-7dc6487b67 to 0 from 1
raamu@raamu-VirtualBox:~$



raamu@raamu-VirtualBox:~$ kubectl rollout history deploy
deployment.apps/bluelabel
REVISION  CHANGE-CAUSE
1         <none>
2         <none>
3         <none>

To check the revisions:

raamu@raamu-VirtualBox:~$ kubectl rollout history deploy bluelabel --revision=1
deployment.apps/bluelabel with revision #1
Pod Template:
  Labels:       app=bluelabel
        pod-template-hash=64c5d9799b
  Containers:
   nginx:
    Image:      nginx
    Port:       <none>
    Host Port:  <none>
    Environment:        <none>
    Mounts:     <none>
  Volumes:      <none>
  Node-Selectors:       <none>
  Tolerations:  <none>

raamu@raamu-VirtualBox:~$ kubectl rollout history deploy bluelabel --revision=2
deployment.apps/bluelabel with revision #2
Pod Template:
  Labels:       app=bluelabel
        pod-template-hash=7dc6487b67
  Containers:
   nginx:
    Image:      nginx
    Port:       <none>
    Host Port:  <none>
    Environment:
      type:     dev
    Mounts:     <none>
  Volumes:      <none>
  Node-Selectors:       <none>
  Tolerations:  <none>

raamu@raamu-VirtualBox:~$ kubectl rollout history deploy bluelabel --revision=3
deployment.apps/bluelabel with revision #3
Pod Template:
  Labels:       app=bluelabel
        pod-template-hash=5f5b57465d
  Containers:
   nginx:
    Image:      nginx:1.17
    Port:       <none>
    Host Port:  <none>
    Environment:
      type:     dev
    Mounts:     <none>
  Volumes:      <none>
  Node-Selectors:       <none>
  Tolerations:  <none>

raamu@raamu-VirtualBox:~$



TO switch/rollback back to the revision:

raamu@raamu-VirtualBox:~$ kubectl rollout undo deploy bluelabel --> it goes to previous version


raamu@raamu-VirtualBox:~$ kubectl rollout undo deploy bluelabel --to-revision=2 -> we can select any version
deployment.apps/bluelabel rolled back


 raamu@raamu-VirtualBox:~$  kubectl describe deploy bluelabel


Name:                   bluelabel
Namespace:              rnamespace
CreationTimestamp:      Thu, 22 Aug 2024 15:20:42 +0530
Labels:                 app=bluelabel
                        state=demo
Annotations:            deployment.kubernetes.io/revision: 4
Selector:               app=bluelabel
Replicas:               4 desired | 4 updated | 4 total | 4 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 50% max surge
Pod Template:
  Labels:  app=bluelabel
  Containers:
   nginx:
    Image:      nginx
    Port:       <none>
    Host Port:  <none>
    Environment:
      type:        dev
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  bluelabel-64c5d9799b (0/0 replicas created), bluelabel-5f5b57465d (0/0 replicas created)
NewReplicaSet:   bluelabel-7dc6487b67 (4/4 replicas created)
Events:
  Type    Reason             Age                 From                   Message
  ----    ------             ----                ----                   -------
  Normal  ScalingReplicaSet  31m                 deployment-controller  Scaled up replica set bluelabel-64c5d9799b to 8 from 1
  Normal  ScalingReplicaSet  29m                 deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 2
  Normal  ScalingReplicaSet  29m                 deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 6 from 8
  Normal  ScalingReplicaSet  29m                 deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 4 from 2
  Normal  ScalingReplicaSet  29m                 deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 5 from 6
  Normal  ScalingReplicaSet  29m                 deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 5 from 4
  Normal  ScalingReplicaSet  28m                 deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 4 from 5
  Normal  ScalingReplicaSet  28m                 deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 6 from 5
  Normal  ScalingReplicaSet  28m                 deployment-controller  Scaled down replica set bluelabel-64c5d9799b to 3 from 4
  Normal  ScalingReplicaSet  9m18s               deployment-controller  Scaled up replica set bluelabel-5f5b57465d to 2
  Normal  ScalingReplicaSet  9m17s               deployment-controller  Scaled down replica set bluelabel-7dc6487b67 to 3 from 4
  Normal  ScalingReplicaSet  9m16s               deployment-controller  Scaled up replica set bluelabel-5f5b57465d to 3 from 2
  Normal  ScalingReplicaSet  8m56s               deployment-controller  Scaled down replica set bluelabel-7dc6487b67 to 2 from 3
  Normal  ScalingReplicaSet  8m56s               deployment-controller  Scaled up replica set bluelabel-5f5b57465d to 4 from 3
  Normal  ScalingReplicaSet  8m48s               deployment-controller  Scaled down replica set bluelabel-7dc6487b67 to 1 from 2
  Normal  ScalingReplicaSet  8m46s               deployment-controller  Scaled down replica set bluelabel-7dc6487b67 to 0 from 1
  Normal  ScalingReplicaSet  98s                 deployment-controller  Scaled up replica set bluelabel-7dc6487b67 to 2 from 0
  Normal  ScalingReplicaSet  97s                 deployment-controller  Scaled down replica set bluelabel-5f5b57465d to 3 from 4
  Normal  ScalingReplicaSet  64s (x11 over 28m)  deployment-controller  (combined from similar events): Scaled down replica set bluelabel-5f5b57465d to 0 from 1
raamu@raamu-VirtualBox:~$

===============================================================================================================

Day14: Daemonset|pod Networking| K8's Networking:


Daemonset setup:

*****Most of the times in real time we see Daemonset in Kube-system namespaces 

raamu@raamu-VirtualBox:~$ kubectl get ns
NAME                   STATUS   AGE
default                Active   110d
kube-node-lease        Active   110d
kube-public            Active   110d
kube-system            Active   110d
kubernetes-dashboard   Active   110d
rnamespace             Active   2d3h
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl describe namespace kube-system
Name:         kube-system
Labels:       kubernetes.io/metadata.name=kube-system
Annotations:  <none>
Status:       Active

No resource quota.

No LimitRange resource.
raamu@raamu-VirtualBox:~$



raamu@raamu-VirtualBox:~$ kubectl get pods -A
NAMESPACE              NAME                                        READY   STATUS    RESTARTS         AGE
kube-system            calico-kube-controllers-ddf655445-gn9gz     1/1     Running   14 (9m45s ago)   110d
kube-system            calico-node-szc9l                           1/1     Running   14 (9m45s ago)   110d
kube-system            coredns-7db6d8ff4d-tw4cj                    1/1     Running   16 (9m40s ago)   110d
kube-system            etcd-minikube                               1/1     Running   14 (9m45s ago)   110d
kube-system            kube-apiserver-minikube                     1/1     Running   15 (9m45s ago)   110d
kube-system            kube-controller-manager-minikube            1/1     Running   16 (9m45s ago)   110d
kube-system            kube-proxy-ztt7n                            1/1     Running   14 (9m45s ago)   110d
kube-system            kube-scheduler-minikube                     1/1     Running   14 (9m45s ago)   110d
kube-system            storage-provisioner                         1/1     Running   28 (8m27s ago)   110d
kubernetes-dashboard   dashboard-metrics-scraper-b5fc48f67-6r4j9   1/1     Running   12 (9m45s ago)   110d
kubernetes-dashboard   kubernetes-dashboard-779776cb65-znsbf       1/1     Running   12 (9m45s ago)   110d
raamu@raamu-VirtualBox:~$


-> It will be used when we use promoteous and ELK(Elastic seardh)			  
                                 ----------------------------------
								 Both are monitoring agents always deployes by Daemonset***********
								 
								 
Since in minkube we have only one node, it not possible to check

For this we need  multi nodes
here we used wiht kind

raamu@raamu-VirtualBox:~$ kind create cluster --config kind-cluster.yml
kubectl get pods
kubectl apply -f daemon.ymlkubectl get ds
kubectl get pods -o wide

==================================
POD Networking:

Basically in pod , the containers in it has same Ip addresses

show the info of IP address like (ip config or ifconfig)
raamu@raamu-VirtualBox:~$ kubectl exec busybox1 -c busybox -- ip a s 

How can we create service:

$kubectl expose <pods>
$kubectl create service	  

exposing the pods with services:

Steps:

raamu@raamu-VirtualBox:~$ kubectl create deploy nginx --image=nginx
deployment.apps/nginx created
raamu@raamu-VirtualBox:~$ kubectl get deploy
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   1/1     1            1           11s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
nginx-bf5d5cf98-7wxk6   1/1     Running   0          17s
raamu@raamu-VirtualBox:~$ kubectl scale deply nginx --replicas=3
error: the server doesn't have a resource type "deply"
raamu@raamu-VirtualBox:~$ kubectl scale deploy nginx --replicas=3
deployment.apps/nginx scaled
raamu@raamu-VirtualBox:~$ kubectl get pods -A
NAMESPACE              NAME                                        READY   STATUS    RESTARTS        AGE
default                nginx-bf5d5cf98-7wxk6                       1/1     Running   0               60s
default                nginx-bf5d5cf98-k8nw4                       1/1     Running   0               8s
default                nginx-bf5d5cf98-mf567                       1/1     Running   0               8s
kube-system            calico-kube-controllers-ddf655445-gn9gz     1/1     Running   14 (101m ago)   110d
kube-system            calico-node-szc9l                           1/1     Running   14 (101m ago)   110d
kube-system            coredns-7db6d8ff4d-tw4cj                    1/1     Running   16 (101m ago)   110d
kube-system            etcd-minikube                               1/1     Running   14 (101m ago)   110d
kube-system            kube-apiserver-minikube                     1/1     Running   15 (101m ago)   110d
kube-system            kube-controller-manager-minikube            1/1     Running   16 (101m ago)   110d
kube-system            kube-proxy-ztt7n                            1/1     Running   14 (101m ago)   110d
kube-system            kube-scheduler-minikube                     1/1     Running   14 (101m ago)   110d
kube-system            storage-provisioner                         1/1     Running   28 (100m ago)   110d
kubernetes-dashboard   dashboard-metrics-scraper-b5fc48f67-6r4j9   1/1     Running   12 (101m ago)   110d
kubernetes-dashboard   kubernetes-dashboard-779776cb65-znsbf       1/1     Running   12 (101m ago)   110d
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
nginx-bf5d5cf98-7wxk6   1/1     Running   0          65s
nginx-bf5d5cf98-k8nw4   1/1     Running   0          13s
nginx-bf5d5cf98-mf567   1/1     Running   0          13s
raamu@raamu-VirtualBox:~$ kubectl describe deploy
Name:                   nginx
Namespace:              default
CreationTimestamp:      Fri, 23 Aug 2024 19:18:30 +0530
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:         nginx
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Progressing    True    NewReplicaSetAvailable
  Available      True    MinimumReplicasAvailable
OldReplicaSets:  <none>
NewReplicaSet:   nginx-bf5d5cf98 (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  86s   deployment-controller  Scaled up replica set nginx-bf5d5cf98 to 1
  Normal  ScalingReplicaSet  34s   deployment-controller  Scaled up replica set nginx-bf5d5cf98 to 3 from 1
raamu@raamu-VirtualBox:~$ kubectl get deploy, pods
error: arguments in resource/name form must have a single resource and name
raamu@raamu-VirtualBox:~$ kubecctl get all
Command 'kubecctl' not found, did you mean:
  command 'kubectl' from snap kubectl (1.30.4)
See 'snap info <snapname>' for additional versions.
raamu@raamu-VirtualBox:~$ kubectl get all
NAME                        READY   STATUS    RESTARTS   AGE
pod/nginx-bf5d5cf98-7wxk6   1/1     Running   0          2m4s
pod/nginx-bf5d5cf98-k8nw4   1/1     Running   0          72s
pod/nginx-bf5d5cf98-mf567   1/1     Running   0          72s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   2m55s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx   3/3     3            3           2m4s

NAME                              DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-bf5d5cf98   3         3         3       2m4s

exposing:

raamu@raamu-VirtualBox:~$ kubectl expose deploy nginx -h |less
raamu@raamu-VirtualBox:~$ kubectl expose deploy nginx --port=80
service/nginx exposed

raamu@raamu-VirtualBox:~$ kubectl get svc
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP   8m2s
nginx        ClusterIP   10.107.220.36   <none>        80/TCP    3m38s
raamu@raamu-VirtualBox:~$


shows the  3 replicas endpoints i.e ip address with exposed port

raamu@raamu-VirtualBox:~$ kubectl get endpoints
NAME         ENDPOINTS                                            AGE
kubernetes   192.168.49.2:8443                                    9m16s
nginx        10.244.120.75:80,10.244.120.76:80,10.244.120.77:80   4m52s
raamu@raamu-VirtualBox:~$


raamu@raamu-VirtualBox:~$ kubectl describe service nginx
Name:              nginx
Namespace:         default
Labels:            app=nginx
Annotations:       <none>
Selector:          app=nginx
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.107.220.36
IPs:               10.107.220.36
Port:              <unset>  80/TCP
TargetPort:        80/TCP
Endpoints:         10.244.120.75:80,10.244.120.76:80,10.244.120.77:80
Session Affinity:  None
Events:            <none>
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl get pods -o wide
NAME                    READY   STATUS    RESTARTS   AGE     IP              NODE       NOMINATED NODE   READINESS GATES
nginx-bf5d5cf98-7wxk6   1/1     Running   0          6m40s   10.244.120.75   minikube   <none>           <none>
nginx-bf5d5cf98-k8nw4   1/1     Running   0          5m48s   10.244.120.77   minikube   <none>           <none>
nginx-bf5d5cf98-mf567   1/1     Running   0          5m48s   10.244.120.76   minikube   <none>           <none>
raamu@raamu-VirtualBox:~$

we can check the exposed port by editing the services:

and from here manually update the nodeport number (whihc ranges from 30000 - 32768)

raamu@raamu-VirtualBox:~$ kubectl edit service
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-08-23T13:47:39Z"
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "84118"
    uid: 77a6f149-6492-4f20-91e5-1f94462a7b38
  spec:
|
|
|
spec:
    clusterIP: 10.107.220.36
    clusterIPs:
    - 10.107.220.36
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - port: 80
      protocol: TCP
      targetPort: 80
	  nodePort: 32000 ----------------------------->> added
    selector:
      app: nginx
    sessionAffinity: None
    type: ClusterIP ---------------------->>> change to NodePort or if we use loadBalancer for micro services applications
  status:
    loadBalancer: {}
kind: List
metadata: {}

Before:
raamu@raamu-VirtualBox:~$ kubectl get svc
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP   8m2s
nginx        ClusterIP   10.107.220.36   <none>        80/TCP    3m38s

After:
raamu@raamu-VirtualBox:~$ kubectl get svc
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        21m
nginx        NodePort    10.107.220.36   <none>        80:32000/TCP   17m
raamu@raamu-VirtualBox:~$

Node IP:

raamu@raamu-VirtualBox:~$ minikube ip
192.168.49.2
raamu@raamu-VirtualBox:~$


and if we want to access the application
node ip:exposed port

raamu@raamu-VirtualBox:~$ curl http://192.168.49.2
curl: (7) Failed to connect to 192.168.49.2 port 80 after 0 ms: Couldn't connect to server
raamu@raamu-VirtualBox:~$ curl http://192.168.49.2:32000
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
raamu@raamu-VirtualBox:~$

==========================================================================

DNS :

-> DNS default location is /et/resolv.conf

raamu@raamu-VirtualBox:~$ kubectl exec -it nginx-bf5d5cf98-7wxk6 -- cat /etc/resolv.conf
nameserver 10.96.0.10
search default.svc.cluster.local svc.cluster.local cluster.local
options ndots:5
raamu@raamu-VirtualBox:~$


communicate applications services from one namespace to other:
--------------------------------------------------------------

created app in default and communicating from rnamespace:

raamu@raamu-VirtualBox:~$ kubectl create deploy nginx --image=nginx
deployment.apps/nginx created
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS              RESTARTS   AGE
nginx-bf5d5cf98-9t444   0/1     ContainerCreating   0          6s
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubens rnamespace
✔ Active namespace is "rnamespace"
raamu@raamu-VirtualBox:~$  kubectl run bb --image=busybox -- sleep 3600
pod/bb created
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME   READY   STATUS              RESTARTS   AGE
bb     0/1     ContainerCreating   0          7s
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl exec -it bb -- nslookup nginx
Server:         10.96.0.10
Address:        10.96.0.10:53

** server can't find nginx.svc.cluster.local: NXDOMAIN

** server can't find nginx.svc.cluster.local: NXDOMAIN

** server can't find nginx.cluster.local: NXDOMAIN

** server can't find nginx.rnamespace.svc.cluster.local: NXDOMAIN

** server can't find nginx.cluster.local: NXDOMAIN

** server can't find nginx.rnamespace.svc.cluster.local: NXDOMAIN

command terminated with exit code 1
raamu@raamu-VirtualBox:~$ kubens default
✔ Active namespace is "default"
raamu@raamu-VirtualBox:~$ kubectl get svc
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   5m10s
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubens
default
kube-node-lease
kube-public
kube-system
kubernetes-dashboard
rnamespace
raamu@raamu-VirtualBox:~$ kubens rnamespace
✔ Active namespace is "rnamespace"
raamu@raamu-VirtualBox:~$ kubectl exec -it bb -- nslookup 10.96.0.1
Server:         10.96.0.10
Address:        10.96.0.10:53

1.0.96.10.in-addr.arpa  name = kubernetes.default.svc.cluster.local ------------------------------------------->>DNS Name

raamu@raamu-VirtualBox:~$ kubectl exec -it bb -- nslookup kubernetes.default.svc.cluster.local
Server:         10.96.0.10
Address:        10.96.0.10:53

Name:   kubernetes.default.svc.cluster.local  
Address: 10.96.0.1


raamu@raamu-VirtualBox:~$

---------------------------------------

raamu@raamu-VirtualBox:~$ kubens rnamespace ->>>>>>>>>>>>>>>>>>>>>..to switch namespace
✔ Active namespace is "rnamespace"
raamu@raamu-VirtualBox:~$ kubens
default
kube-node-lease
kube-public
kube-system
kubernetes-dashboard
rnamespace
raamu@raamu-VirtualBox:~$



==============================================================

Ingress:

to enable the Ingress in minikube:

raamu@raamu-VirtualBox:~$ minikube addons list
|-----------------------------|----------|--------------|--------------------------------|
|         ADDON NAME          | PROFILE  |    STATUS    |           MAINTAINER           |
|-----------------------------|----------|--------------|--------------------------------|
| ambassador                  | minikube | disabled     | 3rd party (Ambassador)         |
| auto-pause                  | minikube | disabled     | minikube                       |
| cloud-spanner               | minikube | disabled     | Google                         |
| csi-hostpath-driver         | minikube | disabled     | Kubernetes                     |
| dashboard                   | minikube | enabled ✅   | Kubernetes                     |
| default-storageclass        | minikube | enabled ✅   | Kubernetes                     |
| efk                         | minikube | disabled     | 3rd party (Elastic)            |
| freshpod                    | minikube | disabled     | Google                         |
| gcp-auth                    | minikube | disabled     | Google                         |
| gvisor                      | minikube | disabled     | minikube                       |
| headlamp                    | minikube | disabled     | 3rd party (kinvolk.io)         |
| helm-tiller                 | minikube | disabled     | 3rd party (Helm)               |
| inaccel                     | minikube | disabled     | 3rd party (InAccel             |
|                             |          |              | [info@inaccel.com])            |
| ingress                     | minikube | disabled     | Kubernetes                     |
| ingress-dns                 | minikube | disabled     | minikube                       |
| inspektor-gadget            | minikube | disabled     | 3rd party                      |
|                             |          |              | (inspektor-gadget.io)          |
| istio                       | minikube | disabled     | 3rd party (Istio)              |
| istio-provisioner           | minikube | disabled     | 3rd party (Istio)              |
| kong                        | minikube | disabled     | 3rd party (Kong HQ)            |
| kubeflow                    | minikube | disabled     | 3rd party                      |
| kubevirt                    | minikube | disabled     | 3rd party (KubeVirt)           |
| logviewer                   | minikube | disabled     | 3rd party (unknown)            |
| metallb                     | minikube | disabled     | 3rd party (MetalLB)            |
| metrics-server              | minikube | disabled     | Kubernetes                     |
| nvidia-device-plugin        | minikube | disabled     | 3rd party (NVIDIA)             |
| nvidia-driver-installer     | minikube | disabled     | 3rd party (Nvidia)             |
| nvidia-gpu-device-plugin    | minikube | disabled     | 3rd party (Nvidia)             |
| olm                         | minikube | disabled     | 3rd party (Operator Framework) |
| pod-security-policy         | minikube | disabled     | 3rd party (unknown)            |
| portainer                   | minikube | disabled     | 3rd party (Portainer.io)       |
| registry                    | minikube | disabled     | minikube                       |
| registry-aliases            | minikube | disabled     | 3rd party (unknown)            |
| registry-creds              | minikube | disabled     | 3rd party (UPMC Enterprises)   |
| storage-provisioner         | minikube | enabled ✅   | minikube                       |
| storage-provisioner-gluster | minikube | disabled     | 3rd party (Gluster)            |
| storage-provisioner-rancher | minikube | disabled     | 3rd party (Rancher)            |
| volumesnapshots             | minikube | disabled     | Kubernetes                     |
| yakd                        | minikube | disabled     | 3rd party (marcnuri.com)       |
|-----------------------------|----------|--------------|--------------------------------|
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ minikube addons enable ingress
* ingress is an addon maintained by Kubernetes. For any concerns contact minikube on GitHub.
You can view the list of minikube maintainers at: https://github.com/kubernetes/minikube/blob/master/OWNERS
  - Using image registry.k8s.io/ingress-nginx/controller:v1.10.0
  - Using image registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.0
  - Using image registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.0
* Verifying ingress addon...

* The 'ingress' addon is enabled
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$


after INgress enabled, we get seperate ns created.

raamu@raamu-VirtualBox:~$ kubectl get ns
NAME                   STATUS   AGE
default                Active   110d
ingress-nginx          Active   2m48s -----------------------> created
kube-node-lease        Active   110d
kube-public            Active   110d
kube-system            Active   110d
kubernetes-dashboard   Active   110d
rnamespace             Active   2d10h
raamu@raamu-VirtualBox:~$

shows the controller pod:

raamu@raamu-VirtualBox:~$ kubectl get deploy -n ingress-nginx
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
ingress-nginx-controller   1/1     1            1           3m43s
raamu@raamu-VirtualBox:~$

to disable:

we ahve access mode as ReadWrite Once
Since we unable to d in minikube we use gcp for persistent volume claim:


=====================================================================================================================
methods:

i.Creating PVC->PV->Storageclass
ii. creating pod->PVC->PV->Storageclass

Access type:

ReadWriteOnce : its for one time
ReadWriteMany : for big data kind of applicartions we use where we need to activities more and where IOPS should is more

i.Creating PVC->PV->Storageclass
==============================

Senario :1

Assiging 1 inernal/loal volume to 2 containers in a pod, which is temporary storage[pvc](If pod goes down volume also)

where we use volumes :

pod.spec.volumes

raamu@raamu-VirtualBox:~$ kubectl explain pod.spec.volumes |less
KIND:       Pod
VERSION:    v1

FIELD: volumes <[]Volume>


DESCRIPTION:
    List of volumes that can be mounted by containers belonging to the pod. More
    info: https://kubernetes.io/docs/concepts/storage/volumes
    Volume represents a named volume in a pod that may be accessed by any
    container in the pod.

FIELDS:
  awsElasticBlockStore  <AWSElasticBlockStoreVolumeSource>
    awsElasticBlockStore represents an AWS Disk resource that is attached to a
    kubelet's host machine and then exposed to the pod. More info:
    https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore

  azureDisk     <AzureDiskVolumeSource>
    azureDisk represents an Azure Data Disk mount on the host and bind mount to
    the pod.

  azureFile     <AzureFileVolumeSource>
    azureFile represents an Azure File Service mount on the host and bind mount
    to the pod.




raamu@raamu-VirtualBox:~$ cat morevolumes.yaml
apiVersion: v1
kind: Pod
metadata:
  name: morevol2
spec:
  containers:
  - name: centos1
    image: centos:7
    command:
      - sleep
      - "3600"
    volumeMounts:
      - mountPath: /centos1
        name: test
  - name: centos2
    image: centos:7
    command:
      - sleep
      - "3600"
    volumeMounts:
      - mountPath: /centos2
        name: test
  volumes:
    - name: test
      emptyDir: {}
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl apply -f morevolumes.yaml
pod/morevol2 created

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME       READY   STATUS    RESTARTS   AGE
morevol2   2/2     Running   0          3m17s
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl describe pods morevol2
Name:             morevol2
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Sat, 24 Aug 2024 17:17:12 +0530
Labels:           <none>
Annotations:      cni.projectcalico.org/containerID: 6a6062ade5c0203bd51421b91425b1756153d4eb2735c9563d4b97be5b1903e7
                  cni.projectcalico.org/podIP: 10.244.120.100/32
                  cni.projectcalico.org/podIPs: 10.244.120.100/32
Status:           Running
IP:               10.244.120.100
IPs:
  IP:  10.244.120.100
Containers:
  centos1: -------------------------------------------------------------------------------------------------------->Container1
    Container ID:  docker://a81834fc8e453aa42ba7ee5fc4a61b3581013646dd964273576a610e5b66d825
    Image:         centos:7
    Image ID:      docker-pullable://centos@sha256:be65f488b7764ad3638f236b7b515b3678369a5124c47b8d32916d6487418ea4
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      3600
    State:          Running
      Started:      Sat, 24 Aug 2024 17:19:54 +0530
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /centos1 from test (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-qxd8g (ro)
  centos2: -------------------------------------------------------------------------------------------------------->Container1
    Container ID:  docker://5dd910a946bb0f837524ac176186bf41fffe1b1544e0e53ab7f76bf84ac0dbcd
    Image:         centos:7
    Image ID:      docker-pullable://centos@sha256:be65f488b7764ad3638f236b7b515b3678369a5124c47b8d32916d6487418ea4
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      3600
    State:          Running
      Started:      Sat, 24 Aug 2024 17:19:57 +0530
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /centos2 from test (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-qxd8g (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       True
  ContainersReady             True
  PodScheduled                True
Volumes:
  test:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime) ---------------------------------->temporary till pod live
    Medium:
    SizeLimit:  <unset>
  kube-api-access-qxd8g:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  3m21s  default-scheduler  Successfully assigned default/morevol2 to minikube
  Normal  Pulling    3m14s  kubelet            Pulling image "centos:7"
  Normal  Pulled     41s    kubelet            Successfully pulled image "centos:7" in 2m32.666s (2m32.666s including waiting). Image size: 203936249 bytes.
  Normal  Created    40s    kubelet            Created container centos1
  Normal  Started    39s    kubelet            Started container centos1
  Normal  Pulled     39s    kubelet            Container image "centos:7" already present on machine
  Normal  Created    38s    kubelet            Created container centos2
  Normal  Started    36s    kubelet            Started container centos2
raamu@raamu-VirtualBox:~$


connect to a particuler container and create a file:

the created file should access from centos2(container2)  since we using the same storage/path

raamu@raamu-VirtualBox:~$ kubectl exec -it morevol2 -c centos1 -- touch /centos1/testrrrr
raamu@raamu-VirtualBox:~$ cd /centos1/
-bash: cd: /centos1/: No such file or directory
raamu@raamu-VirtualBox:~$ kubectl exec -it morevol2 -c centos2 -- bash
[root@morevol2 /]# ls -ltr
total 60
drwxr-xr-x   2 root root  4096 Apr 11  2018 srv
drwxr-xr-x   2 root root  4096 Apr 11  2018 opt
drwxr-xr-x   2 root root  4096 Apr 11  2018 mnt
drwxr-xr-x   2 root root  4096 Apr 11  2018 media
drwxr-xr-x   2 root root  4096 Apr 11  2018 home
drwxr-xr-x  13 root root  4096 Nov 13  2020 usr
lrwxrwxrwx   1 root root     8 Nov 13  2020 sbin -> usr/sbin
lrwxrwxrwx   1 root root     9 Nov 13  2020 lib64 -> usr/lib64
lrwxrwxrwx   1 root root     7 Nov 13  2020 lib -> usr/lib
lrwxrwxrwx   1 root root     7 Nov 13  2020 bin -> usr/bin
drwxr-xr-x  18 root root  4096 Nov 13  2020 var
drwxrwxrwt   7 root root  4096 Nov 13  2020 tmp
dr-xr-x---   2 root root  4096 Nov 13  2020 root
-rw-r--r--   1 root root 12114 Nov 13  2020 anaconda-post.log
dr-xr-xr-x  13 root root     0 Aug 24 11:47 sys
drwxr-xr-x   1 root root  4096 Aug 24 11:49 etc
dr-xr-xr-x 351 root root     0 Aug 24 11:49 proc
drwxr-xr-x   1 root root  4096 Aug 24 11:49 run
drwxr-xr-x   5 root root   360 Aug 24 11:49 dev
drwxrwxrwx   2 root root  4096 Aug 24 11:56 centos2
[root@morevol2 /]# cd centos2
[root@morevol2 centos2]# ls -ltr
total 0
-rw-r--r-- 1 root root 0 Aug 24 11:56 testrrrr
[root@morevol2 centos2]#
[root@morevol2 centos2]# exit
exit

raamu@raamu-VirtualBox:~$ kubectl exec -it morevol2 -c centos1 -- ls -l /centos1
total 0
-rw-r--r-- 1 root root 0 Aug 24 11:56 testrrrr
raamu@raamu-VirtualBox:~$ kubectl exec -it morevol2 -c centos2 -- ls -l /centos2
total 0
-rw-r--r-- 1 root root 0 Aug 24 11:56 testrrrr
raamu@raamu-VirtualBox:~$

==============================================================================
Senario :2

Creating PV manually:

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-volume
  labels:
      type: local
spec:
  capacity:
    storage: 2Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path : "/mydata" ----> because using local not external
raamu@raamu-VirtualBox:~$


raamu@raamu-VirtualBox:~$ kubectl create -f pv.yaml
persistentvolume/pv-volume created

herem, the storage clss and claim is empty since we created in local:

raamu@raamu-VirtualBox:~$ kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv-volume   2Gi        RWO            Retain           Available                          <unset>                          7s


raamu@raamu-VirtualBox:~$ kubectl describe pv pv-volume
Name:            pv-volume
Labels:          type=local
Annotations:     <none>
Finalizers:      [kubernetes.io/pv-protection]
StorageClass:
Status:          Available
Claim:
Reclaim Policy:  Retain
Access Modes:    RWO
VolumeMode:      Filesystem
Capacity:        2Gi
Node Affinity:   <none>
Message:
Source:
    Type:          HostPath (bare host directory volume)
    Path:          /mydata
    HostPathType:
Events:            <none>
raamu@raamu-VirtualBox:~$

when we assign a external storage the default location is in /tmp:
here we just created PVC only not engaged/bond any storage class/PV 
TO connect/bond to the PV and pvc should have the disk and access types should match

raamu@raamu-VirtualBox:~$ kubectl get sc
NAME                 PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
standard (default)   k8s.io/minikube-hostpath   Delete          Immediate           false                  111d

raamu@raamu-VirtualBox:~$ kubectl get storageclass
NAME                 PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
standard (default)   k8s.io/minikube-hostpath   Delete          Immediate           false                  111d
raamu@raamu-VirtualBox:~$


Bonding with PV from PVC::::::::::::


creating storageclass/pv

kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pv-claim
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
	  storage: 1Gi

raamu@raamu-VirtualBox:~$ kubectl create  -f pvc.yaml
persistentvolumeclaim/pv-claim created

PVC status shows available  and storageclass shows standard , where above it shown us empty
PV status shows Bound ---> the name of PV shows as PVC so no confusion
                           volume is bounded to pv and shows the storage name

raamu@raamu-VirtualBox:~$ kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM              STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv-volume                                  2Gi        RWO            Retain           Available                                     <unset>                          25m
pvc-b3da7c95-1acb-42ff-9174-92e6c4641776   1Gi        RWO            Delete           Bound       default/pv-claim   standard       <unset>                          29s

raamu@raamu-VirtualBox:~$ kubectl get pvc
NAME       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
pv-claim   Bound    pvc-b3da7c95-1acb-42ff-9174-92e6c4641776   1Gi        RWO            standard       <unset>                 75s
raamu@raamu-VirtualBox:~$


SO here, the storage class shows as standard (the name will vary in AWS/GCP/AZURE)

raamu@raamu-VirtualBox:~$ kubectl get sc
NAME                 PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
standard (default)   k8s.io/minikube-hostpath   Delete          Immediate           false                  111d
raamu@raamu-VirtualBox:~$

since in minikube the storage enabled in above command it shows the provisioner:k8s.io/minikube-hostpath

raamu@raamu-VirtualBox:~$ minikube addons list

|-----------------------------|----------|--------------|--------------------------------|
|         ADDON NAME          | PROFILE  |    STATUS    |           MAINTAINER           |
|-----------------------------|----------|--------------|--------------------------------|

  	  | storage-provisioner         | minikube | enabled ✅   | minikube                       |

 
To get the pv path: it will created in /tmp of minikube since we using minikube

raamu@raamu-VirtualBox:~$ kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM              STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv-volume                                  2Gi        RWO            Retain           Available                                     <unset>                          35m
pvc-b3da7c95-1acb-42ff-9174-92e6c4641776   1Gi        RWO            Delete           Bound       default/pv-claim   standard       <unset>                          11m
raamu@raamu-VirtualBox:~$ kubectl describe pv pvc-b3da7c95-1acb-42ff-9174-92e6c4641776
Name:            pvc-b3da7c95-1acb-42ff-9174-92e6c4641776
Labels:          <none>
Annotations:     hostPathProvisionerIdentity: be8ce63a-ae43-46e0-89e7-91055d81dfa1
                 pv.kubernetes.io/provisioned-by: k8s.io/minikube-hostpath
Finalizers:      [kubernetes.io/pv-protection]
StorageClass:    standard
Status:          Bound
Claim:           default/pv-claim
Reclaim Policy:  Delete
Access Modes:    RWO
VolumeMode:      Filesystem
Capacity:        1Gi
Node Affinity:   <none>
Message:
Source:
    Type:          HostPath (bare host directory volume)
    Path:          /tmp/hostpath-provisioner/default/pv-claim  ---------------->>>minikube path
    HostPathType:
Events:            <none>
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ minikube ssh
docker@minikube:~$ cd /tmp
docker@minikube:/tmp$ ls -ltr
total 16
drwxr-xr-x 2 root   root   4096 May  5 12:01 hostpath_pv
drwxr-xr-x 2 root   root     40 Aug 24 11:21 gvisor
-rw-r--r-- 1 docker docker  208 Aug 24 11:22 h.1194
-rw-r--r-- 1 docker docker  253 Aug 24 11:22 h.1260
drwxr-xr-x 3 root   root   4096 Aug 24 12:35 hostpath-provisioner ---------------->>created
docker@minikube:/tmp$

==================================================================================================

ii. creating pod->->PVc->PV->Storageclass


By defualt the pvc will asks storage call ans assign the volume to the pvc from pv

kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: nginx-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests: 
	  storage: 2Gi
---
kind: Pod
apiVersion: v1
metadata:
   name: nginx-pvc-pod  -------------> pod name
spec:
  volumes:
    - name: site-storage
	  persistentVolumeClaim:
	    claimName: nginx-pvc ------>pvc name
  containers:
    - name: pv-container
      image: nginx
	  ports:
	    -containerPort: 80
		 name: webserver
	  volumeMounts:
	    - mountPath: "/usr/share/nginx/html"
		  name: site-storage
		  

To delete the  pv, pvc:

raamu@raamu-VirtualBox:~$ kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                  STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pvc-40c61b1c-8e7f-4392-897d-f9de74313c67   2Gi        RWX            Delete           Bound    default/nginx-pvc      standard       <unset>                          36m
pvc-b2a21612-6aca-4f12-9308-7467c88d3226   2Gi        RWX            Delete           Bound    rnamespace/nginx-pvc   standard       <unset>                          19m
pvc-b3da7c95-1acb-42ff-9174-92e6c4641776   1Gi        RWO            Delete           Bound    default/pv-claim       standard       <unset>                          74m
raamu@raamu-VirtualBox:~$ kubectl delete pvc --all
persistentvolumeclaim "nginx-pvc" deleted
persistentvolumeclaim "pv-claim" deleted
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM                  STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pvc-40c61b1c-8e7f-4392-897d-f9de74313c67   2Gi        RWX            Delete           Released   default/nginx-pvc      standard       <unset>                          38m
pvc-b2a21612-6aca-4f12-9308-7467c88d3226   2Gi        RWX            Delete           Bound      rnamespace/nginx-pvc   standard       <unset>                          20m
pvc-b3da7c95-1acb-42ff-9174-92e6c4641776   1Gi        RWO            Delete           Released   default/pv-claim       standard       <unset>                          76m
raamu@raamu-VirtualBox:~$ kubectl delete pv --all
persistentvolume "pvc-40c61b1c-8e7f-4392-897d-f9de74313c67" deleted
persistentvolume "pvc-b2a21612-6aca-4f12-9308-7467c88d3226" deleted
persistentvolume "pvc-b3da7c95-1acb-42ff-9174-92e6c4641776" deleted

		  
	

===============================================================================================================

CongigMap & Secrets:



raamu@raamu-VirtualBox:~$ kubectl create deploy mydb --image=mariadb
deployment.apps/mydb created
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                   READY   STATUS              RESTARTS   AGE
mydb-7d6458794-8rk9t   0/1     ContainerCreating   0          14s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                   READY   STATUS   RESTARTS   AGE
mydb-7d6458794-8rk9t   0/1     Error    0          52s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                   READY   STATUS    RESTARTS     AGE
mydb-7d6458794-8rk9t   1/1     Running   1 (4s ago)   54s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                   READY   STATUS   RESTARTS     AGE
mydb-7d6458794-8rk9t   0/1     Error    1 (7s ago)   57s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                   READY   STATUS   RESTARTS      AGE
mydb-7d6458794-8rk9t   0/1     Error    1 (11s ago)   61s
raamu@raamu-VirtualBox:~$ kubectl logs mydb-7d6458794-8rk9t
2024-08-24 14:24:23+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:11.5.2+maria~ubu2404 started.
2024-08-24 14:24:24+00:00 [Warn] [Entrypoint]: /sys/fs/cgroup///memory.pressure not writable, functionality unavailable to MariaDB
2024-08-24 14:24:24+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'
2024-08-24 14:24:24+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:11.5.2+maria~ubu2404 started.
2024-08-24 14:24:24+00:00 [ERROR] [Entrypoint]: Database is uninitialized and password option is not specified
        You need to specify one of MARIADB_ROOT_PASSWORD, MARIADB_ROOT_PASSWORD_HASH, MARIADB_ALLOW_EMPTY_ROOT_PASSWORD and MARIADB_RANDOM_ROOT_PASSWORD
raamu@raamu-VirtualBox:~$ kubectl set -h |les
Command 'les' not found, but can be installed with:
sudo apt install atm-tools
raamu@raamu-VirtualBox:~$ kubectl set -h |less
raamu@raamu-VirtualBox:~$ kubectl set env deploy mydb MYSQL_ROOT_PASSWORD=password
deployment.apps/mydb env updated
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS              RESTARTS      AGE
mydb-6965bc4cc8-ch5mg   0/1     ContainerCreating   0             5s
mydb-7d6458794-8rk9t    0/1     CrashLoopBackOff    4 (58s ago)   3m29s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
mydb-6965bc4cc8-ch5mg   1/1     Running   0          11s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
mydb-6965bc4cc8-ch5mg   1/1     Running   0          14s
raamu@raamu-VirtualBox:~$ kubectl get deploy
NAME   READY   UP-TO-DATE   AVAILABLE   AGE
mydb   1/1     1            1           4m4s


in this deploy we see the password clearly which shouldn't be shown:


raamu@raamu-VirtualBox:~$ kubectl edit deploy mydb
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "2"
  creationTimestamp: "2024-08-24T14:23:13Z"
  generation: 2
  labels:
    app: mydb
  name: mydb
  namespace: default
  resourceVersion: "103954"
  uid: b9d833d9-9432-4451-8831-ee3bfeae0c49
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: mydb
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: mydb
    spec:
      containers:
      - env:
        - name: MYSQL_ROOT_PASSWORD
          value: password
        image: mariadb
        imagePullPolicy: Always
        name: mariadb
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always


To overcome we mention a seperate file:


In pod -> give env from configmap(where we give env/password/files/varibales) in it.
         i.e application related configuration files 
		 
-> we shouldn't keep passwords in congfigmap , we can give in secrets which it encrypt the passowds


vi varibales

MYSQL_ROOT_PASSWORD=password
MYSQL_USER=raamu

shows confimap related things:

raamu@raamu-VirtualBox:~$ kubectl create configmap -h |less
Create a config map based on a file, directory, or specified literal value.

 A single config map may package one or more key/value pairs.

 When creating a config map based on a file, the key will default to the basename of the file, and the value will default to the file content.  If the basename is an invalid key, you may specify an alternate key.

 When creating a config map based on a directory, each file whose basename is a valid key in the directory will be packaged into the config map.  Any directory entries except regular files are ignored (e.g. subdirectories, symlinks, devices, pipes, etc).

Aliases:
configmap, cm

Examples:
  # Create a new config map named my-config based on folder bar
  kubectl create configmap my-config --from-file=path/to/bar
  
steps:

1:
vi varibales

MYSQL_ROOT_PASSWORD=password
MYSQL_USER=raamu

2:

 raamu@raamu-VirtualBox:~$ ls -ltr
total 39912
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Videos
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Templates
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Public
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Pictures
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Music
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Downloads
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Documents
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Desktop
-rw-rw-r-- 1 raamu raamu 40775680 May  5 17:28 minikube-linux-amd64
drwx------ 5 raamu raamu     4096 Jul 25 12:00 snap
-rw-rw-r-- 1 raamu raamu    10339 Aug 20 01:54 nakednginx.yaml
-rw-rw-r-- 1 raamu raamu      197 Aug 20 13:45 busybox.yaml
-rw-rw-r-- 1 raamu raamu       31 Aug 20 14:34 myniginx.yml
-rw-rw-r-- 1 raamu raamu       31 Aug 20 14:35 mynginx.yml
-rw-rw-r-- 1 raamu raamu      775 Aug 20 17:32 sidecar.yml
-rw-rw-r-- 1 raamu raamu      201 Aug 21 14:42 namespace.yml
-rw-rw-r-- 1 raamu raamu      374 Aug 21 17:49 mynewjob.yml
-rw-rw-r-- 1 raamu raamu      409 Aug 24 17:16 morevolumes.yaml
-rw-rw-r-- 1 raamu raamu      197 Aug 24 17:40 pv.yaml
-rw-rw-r-- 1 raamu raamu      157 Aug 24 18:05 pvc.yaml
-rw-rw-r-- 1 raamu raamu      530 Aug 24 19:05 pvc-pod.yml
-rw-rw-r-- 1 raamu raamu       46 Aug 24 20:08 variables

raamu@raamu-VirtualBox:~$ kubectl create configmap/cm mydbvars --from-env-file=variables
configmap/mydbvars created
raamu@raamu-VirtualBox:~$


3:
 
 raamu@raamu-VirtualBox:~$ kubectl create deploy mydb --image=mariadb --replicas=3
deployment.apps/mydb created
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                   READY   STATUS              RESTARTS   AGE
mydb-7d6458794-7bkff   0/1     ContainerCreating   0          8s
mydb-7d6458794-pdk67   0/1     ContainerCreating   0          8s
mydb-7d6458794-sz84k   0/1     Error               0          8s

4:

 
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                   READY   STATUS             RESTARTS        AGE
mydb-7d6458794-7bkff   0/1     Error              6 (3m1s ago)    6m39s
mydb-7d6458794-pdk67   0/1     Error              6 (2m58s ago)   6m39s
mydb-7d6458794-sz84k   0/1     CrashLoopBackOff   6 (8s ago)      6m39s

raamu@raamu-VirtualBox:~$ kubectl set env deploy mydb --from=configmap/mydbvars
deployment.apps/mydb env updated
raamu@raamu-VirtualBox:~$

5:

so it picks from env and db will up and runs:


raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
mydb-5b568f64b9-8rss8   1/1     Running   0          45s
mydb-5b568f64b9-h6tvn   1/1     Running   0          57s
mydb-5b568f64b9-rrr7n   1/1     Running   0          52s
raamu@raamu-VirtualBox:~$

6:

So instead of using from deployment , we using configmaps:

raamu@raamu-VirtualBox:~$ kubectl get all
NAME                        READY   STATUS    RESTARTS   AGE
pod/mydb-5b568f64b9-8rss8   1/1     Running   0          95s
pod/mydb-5b568f64b9-h6tvn   1/1     Running   0          107s
pod/mydb-5b568f64b9-rrr7n   1/1     Running   0          102s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   83m

NAME                   READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/mydb   3/3     3            3           9m8s

NAME                              DESIRED   CURRENT   READY   AGE
replicaset.apps/mydb-5b568f64b9   3         3         3       107s
replicaset.apps/mydb-7d6458794    0         0         0       9m7s
raamu@raamu-VirtualBox:~$ kubectl get cm
NAME               DATA   AGE
kube-root-ca.crt   1      111d
mydbvars           2      4m40s
raamu@raamu-VirtualBox:~$ kubectl describe cm mydbvars
Name:         mydbvars
Namespace:    default
Labels:       <none>
Annotations:  <none>

Data
====
MYSQL_ROOT_PASSWORD:
----
password
MYSQL_USER:
----
raamu

BinaryData
====

Events:  <none>
raamu@raamu-VirtualBox:~$


7:

raamu@raamu-VirtualBox:~$ kubectl edit deploy mydb
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "2"
  creationTimestamp: "2024-08-24T14:42:21Z"
  generation: 2
  labels:
    app: mydb
  name: mydb
  namespace: default
  resourceVersion: "105438"
  uid: 06b88497-9ab9-4477-920d-887d9d341810
spec:
  progressDeadlineSeconds: 600
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: mydb
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: mydb
    spec:
      containers:
      - env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            configMapKeyRef:
              key: MYSQL_ROOT_PASSWORD
              name: mydbvars --------------------------------------------------->>using this

=========================================================================================================================

Day18: Secrets |K8 node Affinity |Pod Affinity|Pod Anti-Affinity:

raamu@raamu-VirtualBox:~$ kubectl get secrets -A
NAMESPACE              NAME                              TYPE     DATA   AGE
kubernetes-dashboard   kubernetes-dashboard-certs        Opaque   0      111d
kubernetes-dashboard   kubernetes-dashboard-csrf         Opaque   1      111d
kubernetes-dashboard   kubernetes-dashboard-key-holder   Opaque   2      111d
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl create secret generic -h |less
Create a secret based on a file, directory, or specified literal value.

 A single secret may package one or more key/value pairs.

 When creating a secret based on a file, the key will default to the basename of the file, and the value will default to the file content. If the basename is an invalid key or you wish to chose your own, you may specify an alternate key.

 When creating a secret based on a directory, each file whose basename is a valid key in the directory will be packaged into the secret. Any directory entries except regular files are ignored (e.g. subdirectories, symlinks, devices, pipes, etc).

Examples:
  # Create a new secret named my-secret with keys for each file in folder bar
  kubectl create secret generic my-secret --from-file=path/to/bar



raamu@raamu-VirtualBox:~$ kubectl get secrets -A
NAMESPACE              NAME                              TYPE     DATA   AGE
kubernetes-dashboard   kubernetes-dashboard-certs        Opaque   0      111d
kubernetes-dashboard   kubernetes-dashboard-csrf         Opaque   1      111d
kubernetes-dashboard   kubernetes-dashboard-key-holder   Opaque   2      111d
raamu@raamu-VirtualBox:~$ kubectl create secret generic -h |less
raamu@raamu-VirtualBox:~$

To create Secret:


raamu@raamu-VirtualBox:~$ kubectl create secret generic dbpw --from-literal=ROOT_PASSWORD=password
secret/dbpw created
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl get secret
NAME   TYPE     DATA   AGE
dbpw   Opaque   1      8s

To get see the created secret in yaml format

raamu@raamu-VirtualBox:~$ kubectl get secret dbpw -o yaml
apiVersion: v1
data:
  ROOT_PASSWORD: cGFzc3dvcmQ=
kind: Secret
metadata:
  creationTimestamp: "2024-08-24T15:14:18Z"
  name: dbpw
  namespace: default
  resourceVersion: "106745"
  uid: f7dab79b-1a61-4261-ad1c-e10aa2234e9a
type: Opaque
raamu@raamu-VirtualBox:~$

To decode the password:

raamu@raamu-VirtualBox:~$ echo cGFzc3dvcmQ= |base64 -d
passwordraamu@raamu-VirtualBox:~$

TO set the secret env:

raamu@raamu-VirtualBox:~$ kubectl set env deploy mynewdb --from=secret/dbpw
deployment.apps/mynewdb env updated

pods going into crashloop error: for which we need to give prefix is MARIADB_ROOT_PASSWORD. Coz we may use db's like oracle , mysql, cassandra
so for every db has ROOT_PASSWORD updated, if we give key is ROOT_PASSWORD it wont work that's the reason we need to use prefix i.e MARIADB_

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                       READY   STATUS              RESTARTS      AGE
mynewdb-7646df9796-8hdbb   0/1     CrashLoopBackOff    1 (25s ago)   59s
mynewdb-77c98b6b64-frd9r   0/1     ContainerCreating   0             6s

raamu@raamu-VirtualBox:~$ kubectl logs mynewdb-77c98b6b64-frd9r
2024-08-24 15:19:50+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:11.5.2+maria~ubu2404 started.
2024-08-24 15:19:53+00:00 [Warn] [Entrypoint]: /sys/fs/cgroup///memory.pressure not writable, functionality unavailable to MariaDB
2024-08-24 15:19:53+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'
2024-08-24 15:19:54+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:11.5.2+maria~ubu2404 started.
2024-08-24 15:19:59+00:00 [ERROR] [Entrypoint]: Database is uninitialized and password option is not specified
        You need to specify one of MARIADB_ROOT_PASSWORD, MARIADB_ROOT_PASSWORD_HASH, MARIADB_ALLOW_EMPTY_ROOT_PASSWORD and MARIADB_RANDOM_ROOT_PASSWORD


raamu@raamu-VirtualBox:~$ kubectl describe deploy mynewdb
Name:                   mynewdb
Namespace:              default
CreationTimestamp:      Sat, 24 Aug 2024 20:48:40 +0530
Labels:                 app=mynewdb
Annotations:            deployment.kubernetes.io/revision: 2
Selector:               app=mynewdb
Replicas:               1 desired | 1 updated | 1 total | 0 available | 1 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=mynewdb
  Containers:
   mariadb:
    Image:      mariadb
    Port:       <none>
    Host Port:  <none>
    Environment:
      ROOT_PASSWORD:  <set to the key 'ROOT_PASSWORD' in secret 'dbpw'>  Optional: false
    Mounts:           <none>
  Volumes:            <none>
  Node-Selectors:     <none>
  Tolerations:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Progressing    True    NewReplicaSetAvailable
  Available      False   MinimumReplicasUnavailable
OldReplicaSets:  mynewdb-7646df9796 (0/0 replicas created)
NewReplicaSet:   mynewdb-77c98b6b64 (1/1 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  3m9s   deployment-controller  Scaled up replica set mynewdb-7646df9796 to 1
  Normal  ScalingReplicaSet  2m16s  deployment-controller  Scaled up replica set mynewdb-77c98b6b64 to 1
  Normal  ScalingReplicaSet  116s   deployment-controller  Scaled down replica set mynewdb-7646df9796 to 0 from 1
raamu@raamu-VirtualBox:~$


raamu@raamu-VirtualBox:~$ kubectl set env deploy mynewdb --from=secret/dbpw --prefix=MYSQL_
deployment.apps/mynewdb env updated
raamu@raamu-VirtualBox:~$


Now, it is running:

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
mynewdb-54954bddbb-plg7r   1/1     Running   0          23s
raamu@raamu-VirtualBox:~$


If we edit teh pod and see the MYSQL_ROOT_PASSWORD updated

raamu@raamu-VirtualBox:~$ kubectl get pods mynewdb-54954bddbb-plg7r -o yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    cni.projectcalico.org/containerID: 68852c9a92ce77e5242879bed7cb692f43ea0bd3417eb470f352c24e62421ebf
    cni.projectcalico.org/podIP: 10.244.120.111/32
    cni.projectcalico.org/podIPs: 10.244.120.111/32
  creationTimestamp: "2024-08-24T15:28:47Z"
  generateName: mynewdb-54954bddbb-
  labels:
    app: mynewdb
    pod-template-hash: 54954bddbb
  name: mynewdb-54954bddbb-plg7r
  namespace: default
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: ReplicaSet
    name: mynewdb-54954bddbb
    uid: 5e55e60a-3879-4005-b7a8-8156d023aae1
  resourceVersion: "107626"
  uid: 67710d21-12cf-4a63-bad8-6546ebbd9dcd
spec:
  containers:
  - env:
    - name: ROOT_PASSWORD
      valueFrom:
        secretKeyRef:
          key: ROOT_PASSWORD
          name: dbpw
    - name: MYSQL_ROOT_PASSWORD --->>>>>>>>>Added
      valueFrom:
        secretKeyRef:
          key: ROOT_PASSWORD


****From inside of the pod we can check the password , so at kubernetes level only the passoword is encoded:


raamu@raamu-VirtualBox:~$ kubectl exec mynewdb-54954bddbb-plg7r -- env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=mynewdb-54954bddbb-plg7r
ROOT_PASSWORD=password
MYSQL_ROOT_PASSWORD=password
KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
KUBERNETES_SERVICE_HOST=10.96.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT=tcp://10.96.0.1:443
GOSU_VERSION=1.17
LANG=C.UTF-8
MARIADB_VERSION=1:11.5.2+maria~ubu2404
HOME=/root
raamu@raamu-VirtualBox:~$


=========================================================================

Docker-Registry: check the video ************************

kubectl create secret docker-registry mydocker-creds --docekr-usernmae=<dockerusername>
 --docker-password=<docker_pass> --docker-email=dockermail --docker-server=docker.io / myregistry 
                                                                                      (whihc created in docker which runs in 5000 
																					  port if it is our own registry)


Scheduler Options:

where pod need to sit , decision makes on certian criteras like label,selector match and so on..

Need to do this on multip node

-> $kubctl label nodes <nodename> company=deveopsdba

==============================================================

Pulling Image from Private REpository in Kubernetes:

Pull Image from docker:

-> $docker login --> need ot give docker crdentials.
   $docker images (once logged in we see the images)
   $docker pull nginx (like wise we can pull any image)
   
   To move the Images from docer registry to private 
->$docekr tag nginx:latest <username>/private location path
  $docker push <username>/private location path:latest
  
To use the image in k8's:

->$kubectl create deploy nginxpvt --image=<username>/private location path:latest
  
  Go to kubernetes.io and search (docker private image secrets)
  
kubectl create secret docker-registry regcred 
--docker-server=<your-registry-server>
 --docker-username=<your-name> 
 --docker-password=<your-pword> -
 -docker-email=<your-email>
 
 $kubectl get secrets.
 
 Now, we need to use the above created secret in our pods.
 
 apiVersion: v1
kind: Pod
metadata:
  name: private-reg
spec:
  containers:
  - name: private-reg-container
    image: <your-private-image>
  imagePullSecrets:
  - name: regcred

$kubectl create -f secret.yaml

============================================================================

Day19:kubernetes Taint & Tolerations:

$kubctl get nodes
$kubectl taint nodes <node name> example-key=value:NoSchedule
$kubectl create depoy nginx --image=nginx --replicas=4
$kubectl get pods -o wide
  (deploying nginx on the node with 4 pods, then it shows the taint applied node will not accepted
    any niew pods of replicas 4)
	
vi taint-toleration.yml
	

kind: Pod
apiVersion: v1
metadata:
   name: nginx-tolerations  -------------> pod name
   labels:
   env: test
spec:
  containers:
    - name: nginx-tolerations
      image: nginx
	  imagePullPolicy:IfNotPresent
	  tolearions:
       - key: "example-key"
	     operator: "Exits"
		 effect:  "NoSchedule"
		 
To remove Taint and make it normal node:

$kubectl taint nodes <node name> expample-key:NSchedule-
                     (taint created node)		 (minus should be mention to remove the taint)
					 
$kubectl taint nodes <node name> expample-key:NoExecute					 
					 
$kubectl scale deploy nginx --relicas=6


======================================================================

Day20:Kubernetes RBAC | K8's service accounts:

User certificate creation to access the Role:

1. create NS

$kubectl create ns staf
$kubectl create ns student

2. TOget teh users of cluster and Authorization Info.

$kubectl config get-contexts

3. Now create a user

$sudo useradd -G root raamu
$sudo password raamu

4. Generate the keys.

$mkdir raamu
$cd raamu
$openssl genrsa -out raamu.key 2048
$ls -ltr

5.
By using generated key m we create CSR certificate
$openssl req --new --key raamu.key --out raamu.csr --subj  "/CN=raamu/0=staff"
                                                             --
															 company name
$ls -ltr

6. sign the certificate

$openssl x509 -req -in raamu.csr -CA ~/.minikube/ca.crt -CAkey ~/.minikube/ca.key -CAcreateserial -oiu raamu.crt -days 180
                                                               ------------------
															   minikube local certificate, we have sign cluster certificate )raamu.csr)
$ls -ltr
 raamu.key
 raamu.csr
 raamu.crt 
 files should be shown
 
7. shows the list of users with certificates.

$kubectl config view

8. set the credentials

$kubectl config set-credentials raamu --client-certificate=./raamu.crt --client-key=./raamu.key

$kubectl config view

9. By using user --go-->NS-->acces the resources
$kubectl --context=minikube get pods 
                   -------
				   shows the pods which minukube user can acces
$kubectl --contect=raamu-context get pods
                   ------------
				   shows nothing as we need ot set the configuration
				   
$kubectl config set-context raamu-context --cluster=minikube --rnamespace=staff --user =raamu
                                                    --------
													if we have multiple ckuster we need ot mentuon the cluster names
													
now, if we fire below command it through error, since we didn't created RBAC ROLEs and ROle Bindings

$kubectl --context=raamu-context get pods

10. SO , create the ROle & Role Bindings.

Go to role based yaml file and edit and add the roles

vi staff-role.yaml

kind=Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: staff
  name: raamustaff
rules:
- apigroups: ["", "extentions:, "apps"]
  resources: ["deployments", "replicasets", "pods"]
  verbs: ["list", "get", "watch", "create", "update", "patch", "delete"]
  
11. Create a Role:

$kubectl create -f staff-role.yaml
$kubectl get role -n raamu
$kubens
$kubectl describe role raamustaff -n staff  

  
12. create Role bindings to interact.

vi rolebinding.yaml

kind=Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: staff
  name: raamustaff-role-binding
Subjects:
- kind: User
  name: raamu
  apiGroup: ""
roleRef:
  kind:ramustaff
  apiGroup: ""
  
 $kubectl create -f rolebinding.yaml
 $kubectl get rolebinding -n raamu
 $kubectl describe rolebinding -n raamu
 $kubectl --context=raamu-context get pods -> through error as we not created resources

Create resourcesL

 $kubectl create deploy nginx --image=nginx -n raamu -->whihc creates user in staff namespace as raamu only have access to staff
 $kubectl --context=raamu-context get pods
 $kubectl --context=raamu-context get pods -n default -->throughs error whhere for user raamu do nohave access to the default namespace
 
 Service accounts:
 ---------------
 works on tokens
 
 $kubctl get sa -----------------> by default we have one sa
 $kubectl describe sa default
													

================================================

To convert pod to readable format

raamu@raamu-VirtualBox:~$ kubectl create deploy failure1 --image=busybox
deployment.apps/failure1 created
raamu@raamu-VirtualBox:~$


raamu@raamu-VirtualBox:~$ kubectl get pods failure1-54d599b8bc-m2smd -o yaml > fail.yaml
raamu@raamu-VirtualBox:~$ ls -ltr
total 39916
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Videos
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Templates
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Public
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Pictures
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Music
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Downloads
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Documents
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Desktop
-rw-rw-r-- 1 raamu raamu 40775680 May  5 17:28 minikube-linux-amd64
drwx------ 5 raamu raamu     4096 Jul 25 12:00 snap
-rw-rw-r-- 1 raamu raamu    10339 Aug 20 01:54 nakednginx.yaml
-rw-rw-r-- 1 raamu raamu      197 Aug 20 13:45 busybox.yaml
-rw-rw-r-- 1 raamu raamu       31 Aug 20 14:34 myniginx.yml
-rw-rw-r-- 1 raamu raamu       31 Aug 20 14:35 mynginx.yml
-rw-rw-r-- 1 raamu raamu      775 Aug 20 17:32 sidecar.yml
-rw-rw-r-- 1 raamu raamu      201 Aug 21 14:42 namespace.yml
-rw-rw-r-- 1 raamu raamu      374 Aug 21 17:49 mynewjob.yml
-rw-rw-r-- 1 raamu raamu      409 Aug 24 17:16 morevolumes.yaml
-rw-rw-r-- 1 raamu raamu      197 Aug 24 17:40 pv.yaml
-rw-rw-r-- 1 raamu raamu      157 Aug 24 18:05 pvc.yaml
-rw-rw-r-- 1 raamu raamu      530 Aug 24 19:05 pvc-pod.yml
-rw-rw-r-- 1 raamu raamu       46 Aug 24 20:08 variables
-rw-rw-r-- 1 raamu raamu     3777 Aug 28 12:31 fail.yaml
raamu@raamu-VirtualBox:~$


===============================================================================================

Day21: Kubernetes NOde Management | Troubleshooting steps:

Node Reboot:

Pre-requisites:
**If we nor follow the pre-requisites steps, sometimes node will be struck where we cannot do the reboot.

Senatios:1

If one application Spaqning/running on the cluster node with 3  pods or more.

-> During the reboot , we need to ensure no new pods will be created or NoScheduled on teh node.
->we will run below command
  $kubectl cordon <nodename>
                  ----------
				  It will stop scheduling new pods on the node 1 , then it will move on to the node2..
->And then evict or remove everything
  $kubectl drain
           -----
		   -> It will remove everything and no new pods will nbe scheduled as we applied cordon
																						 ------
		   ->these delete pods, will move & sit on the other availabel node.
-> Then we do reboot
              ------
            ->Once this fired, node automatically register/join the cluster
            -> And the registration is a default setting available in k8's.
			-> Default Registration setting will takecare of kubectl service, this kubectl will g and sits on the cluster node.
			                                                 -------               -------
															 
execrsice:

$kubectl create deploy nodes --image=nginx replicas=6
$kubectl get nodes
$kubectl get pods -o wide

cordon & drain:

$kubectl cordon	<node name> ( it will not create any pod on the mentioned node)

$kubectl scale deploy nodes --replicas=3 (extra 3 pods and as we already given cordon , 
                                          so the pods will sit in the node on those cordon not created)

$kubectl drain <cordon node name> --force --ignore-daemonsets
         -----
		 we can apply directly without going to corndon first, if the node is unscheduled & evict
		 -> Drain: it will evicts all pods in the mentioned node.

To revers the changes:

$kubectl uncordon <node name>
         ---------
         (it will stop drain and cordon)
$kubectl get nodes
$kubectl scale deploy nodes --replicas=9
                              (already 6 pods initiatedm so 3 will be appended to the nodes)

**********
If we need to do on AWS, we do it through AWS CLI
If we do on kubeadm, we need to use ($systemctl kubelet status)
        
		$kubeadm reset (which will reboot)
		
********

Afer reboot , make sure kubelet is up and running

How to check this?

$systemctl kubelet status
  
   (to the the status of the node, we need to have access for this AWS admin team will help)
   

Troubeshooting Strategies:
========================

background process of creating the pods:

   $Kubectl run                     ------------> kubectl describe
         |                          |            
		 |                          |              |       |
		\/                          |              |       |
     -----------          1         |              |       |
     |API-server| <------------------              |       |
     ------------                                  |       |
          | 	                                   |       |
          |                                        |       |
         \/                                        |       |
	-------------                                  |       |
	| ETCD      |                                  |       |
    -------------                                  |       |
           |	                                   |       |
           |                                       |       |
          \/                                       |       |
    ------------------          2                  |       |
	| Kube-scheduler  | <--------------------------        |
	------------------                                     |
	      | 	                                           |
	      |	                                               |
         \/                                                |
    ----------                    3                        |
	|kubelet |  <------------------------------------------
	----------
	checks on node whether kubelet service is running and then create teh container/pod
                           --------------	
	

So after creating pod, what to do if we get issue in creating the pod:

step 1:

 $kubectl describe
    first, get teh information from API-serve
    then from the Kube-Scheduler 
    then from  kubelet	


If it is from the application issue:
====================================

$kubectl logs <>pod/container name>
         -----
		 to goes to the running container and fetchs the information.
		 

While deploying , if we get any issues POD will go into different stages:
=======================================================================
This is faiing of pod:

1. Pending stage:
   i. pod will be validated by API server
   ii. pos enters in ETCD
   iii. then looks for pre-requisites conditions.
                       --------------
					   where it fails, then pod goes to pending state.
					   
2. Running stage:
    i. If pre-requisites success, then it goes into running state..
	
3. COmpleted:
  i. If we give some tast to pod, then it goes into completed state,
  
4. Failed:
   i. Pod finished it job but something went wrong like at application or events
      then we need to check 
	      ->describe/events
		  ->logs        
5.Crashloopbackoff:
   i. cluster restarts
   ii.password issue.
   iii.when we donot have required resources.
   
6. Unkonw:
  i. pod state goes to unknown
         ----
		 again checks teh describe/events/logs
		 

Overall:

decribe/events ->cluster/nodelevel
logs ->application/pod level
exit codes
if 0 ->success
if 1 ->some isssues at application end.

and other than 0 is also issue.

Types of issues:
==============

Senario:1 creating deployment without mentioned task (sleep 3600)

Error:Crashloopbackoff error:

raamu@raamu-VirtualBox:~$ kubectl create deploy failure1 --image=busybox
deployment.apps/failure1 created
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS              RESTARTS   AGE
failure1-54d599b8bc-m2smd   0/1     ContainerCreating   0          7s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS              RESTARTS   AGE
failure1-54d599b8bc-m2smd   0/1     ContainerCreating   0          11s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS              RESTARTS   AGE
failure1-54d599b8bc-m2smd   0/1     ContainerCreating   0          15s

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS      RESTARTS   AGE
failure1-54d599b8bc-m2smd   0/1     Completed   1          36s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS             RESTARTS      AGE
failure1-54d599b8bc-m2smd   0/1     CrashLoopBackOff   1 (11s ago)   43s
raamu@raamu-VirtualBox:~$ kubectl describe pod failure1-54d599b8bc-m2smd
Name:             failure1-54d599b8bc-m2smd
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Wed, 28 Aug 2024 12:26:38 +0530
Labels:           app=failure1
                  pod-template-hash=54d599b8bc
Annotations:      cni.projectcalico.org/containerID: ca57ee8f96ba108ac547da57857f8e2d1215f0b4093f088ade797ae70cc084d4
                  cni.projectcalico.org/podIP: 10.244.120.80/32
                  cni.projectcalico.org/podIPs: 10.244.120.80/32
Status:           Running
IP:               10.244.120.80
IPs:
  IP:           10.244.120.80
Controlled By:  ReplicaSet/failure1-54d599b8bc
Containers:
  busybox:
    Container ID:   docker://e5c6080c18adeeea65d27b3a1d1ee9e65333465ed33d6392c4f79baa330aee1a
    Image:          busybox
    Image ID:       docker-pullable://busybox@sha256:9ae97d36d26566ff84e8893c64a6dc4fe8ca6d1144bf5b87b2b85a32def253c7
    Port:           <none>
    Host Port:      <none>
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Wed, 28 Aug 2024 12:27:09 +0530
      Finished:     Wed, 28 Aug 2024 12:27:09 +0530
    Ready:          False
    Restart Count:  1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-nrj65 (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       False
  ContainersReady             False
  PodScheduled                True
Volumes:
  kube-api-access-nrj65:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  51s                default-scheduler  Successfully assigned default/failure1-54d599b8bc-m2smd to minikube
  Normal   Pulled     33s                kubelet            Successfully pulled image "busybox" in 5.733s (5.733s including waiting). Image size: 4261574 bytes.
  Normal   Created    25s (x2 over 32s)  kubelet            Created container busybox
  Normal   Pulled     25s                kubelet            Successfully pulled image "busybox" in 3.75s (3.75s including waiting). Image size: 4261574 bytes.
  Normal   Started    19s (x2 over 30s)  kubelet            Started container busybox
  Warning  BackOff    16s (x2 over 18s)  kubelet            Back-off restarting failed container busybox in pod failure1-54d599b8bc-m2smd_default(2a56efdb-7f29-4f4b-9607-7e3cc2c8dfee)
  Normal   Pulling    2s (x3 over 39s)   kubelet            Pulling image "busybox"
raamu@raamu-VirtualBox:~$


REcreating teh issue with tasks:
===============================


raamu@raamu-VirtualBox:~$ kubectl create deploy failure1 --image=busybox -- sleep 3600
deployment.apps/failure1 created                                            ----------
                                                                            which runs for 1 hour and restarts after 1 hour
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS              RESTARTS   AGE
failure1-8654d49568-httcx   0/1     ContainerCreating   0          4s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS              RESTARTS   AGE
failure1-8654d49568-httcx   0/1     ContainerCreating   0          12s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
failure1-8654d49568-httcx   1/1     Running   0          19s
raamu@raamu-VirtualBox:~$ kubectl describe pod failure1-8654d49568-httcx
Name:             failure1-8654d49568-httcx
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Wed, 28 Aug 2024 12:36:03 +0530
Labels:           app=failure1
                  pod-template-hash=8654d49568
Annotations:      cni.projectcalico.org/containerID: 786402170e7bd811babcd2f92abe3ae7950443ae513985d194996c961a6c8ba3
                  cni.projectcalico.org/podIP: 10.244.120.74/32
                  cni.projectcalico.org/podIPs: 10.244.120.74/32
Status:           Running
IP:               10.244.120.74
IPs:
  IP:           10.244.120.74
Controlled By:  ReplicaSet/failure1-8654d49568
Containers:
  busybox:
    Container ID:  docker://e82d3d6df8eb15a82de226b7aa94cba5f7ffd274cc28fbbc6c1a29ba5c1c836d
    Image:         busybox
    Image ID:      docker-pullable://busybox@sha256:9ae97d36d26566ff84e8893c64a6dc4fe8ca6d1144bf5b87b2b85a32def253c7
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      3600
    State:          Running
      Started:      Wed, 28 Aug 2024 12:36:18 +0530
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6hp4b (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       True
  ContainersReady             True
  PodScheduled                True
Volumes:
  kube-api-access-6hp4b:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason       Age   From               Message
  ----     ------       ----  ----               -------
  Normal   Scheduled    40s   default-scheduler  Successfully assigned default/failure1-8654d49568-httcx to minikube
  Warning  FailedMount  39s   kubelet            MountVolume.SetUp failed for volume "kube-api-access-6hp4b" : failed to sync configmap cache: timed out waiting for the condition
  Normal   Pulling      32s   kubelet            Pulling image "busybox"
  Normal   Pulled       28s   kubelet            Successfully pulled image "busybox" in 3.336s (3.336s including waiting). Image size: 4261574 bytes.
  Normal   Created      28s   kubelet            Created container busybox
  Normal   Started      25s   kubelet            Started container busybox
raamu@raamu-VirtualBox:~$



=======================================================================

Application related issue:

Senario: 2

creating deployment without mentioning the database prefix password for the database pod


raamu@raamu-VirtualBox:~$ kubectl create deploy failure2 --image=mariadb
deployment.apps/failure2 created

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                       READY   STATUS              RESTARTS   AGE
failure2-c95f8fb4b-xwd56   0/1     ContainerCreating   0          9s

raamu@raamu-VirtualBox:~$ kubectl get pods -o wide
NAME                       READY   STATUS    RESTARTS      AGE   IP              NODE       NOMINATED NODE   READINESS GATES
failure2-c95f8fb4b-xwd56   1/1     Running   1 (10s ago)   28s   10.244.120.70   minikube   <none>           <none>
raamu@raamu-VirtualBox:~$ kubectl get pods -o wide
NAME                       READY   STATUS   RESTARTS      AGE   IP              NODE       NOMINATED NODE   READINESS GATES
failure2-c95f8fb4b-xwd56   0/1     Error    1 (21s ago)   39s   10.244.120.70   minikube   <none>           <none>
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl describe pod failure2-c95f8fb4b-xwd56
\Name:             failure2-c95f8fb4b-xwd56
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Wed, 28 Aug 2024 12:40:30 +0530
Labels:           app=failure2
                  pod-template-hash=c95f8fb4b
Annotations:      cni.projectcalico.org/containerID: 02d0322990b363050a2e1f32f17aabc3c8126ee4b664bbe9d338087742b5db47
                  cni.projectcalico.org/podIP: 10.244.120.70/32
                  cni.projectcalico.org/podIPs: 10.244.120.70/32
Status:           Running
IP:               10.244.120.70
IPs:
  IP:           10.244.120.70
Controlled By:  ReplicaSet/failure2-c95f8fb4b
Containers:
  mariadb:
    Container ID:   docker://16714ee9d91e487ce9953ce97fa008e7b9efad27ce50f0d8d5e88680d4ff84ec
    Image:          mariadb
    Image ID:       docker-pullable://mariadb@sha256:4b812bbd9a025569fbe5a7a70e4a3cd3af53aa36621fecb1c2e108af2113450a
    Port:           <none>
    Host Port:      <none>
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
      Exit Code:    1 ------------------------------------------->clearly shows the error
      Started:      Wed, 28 Aug 2024 12:41:21 +0530
      Finished:     Wed, 28 Aug 2024 12:41:25 +0530
    Ready:          False
    Restart Count:  2
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-hxlpg (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       False
  ContainersReady             False
  PodScheduled                True
Volumes:
  kube-api-access-hxlpg:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  78s                default-scheduler  Successfully assigned default/failure2-c95f8fb4b-xwd56 to minikube
  Normal   Pulled     69s                kubelet            Successfully pulled image "mariadb" in 3.965s (3.965s including waiting). Image size: 406905275 bytes.
  Normal   Pulled     55s                kubelet            Successfully pulled image "mariadb" in 3.49s (3.49s including waiting). Image size: 406905275 bytes.
  Normal   Pulling    33s (x3 over 73s)  kubelet            Pulling image "mariadb"
  Normal   Created    29s (x3 over 69s)  kubelet            Created container mariadb
  Normal   Pulled     29s                kubelet            Successfully pulled image "mariadb" in 3.659s (3.659s including waiting). Image size: 406905275 bytes.
  Normal   Started    27s (x3 over 67s)  kubelet            Started container mariadb
  Warning  BackOff    10s (x3 over 44s)  kubelet            Back-off restarting failed container mariadb in pod failure2-c95f8fb4b-xwd56_default(d38170e0-75a6-4023-abfb-4803e702c0d7)


then go to check the logs:
=======================

raamu@raamu-VirtualBox:~$ kubectl logs failure2-c95f8fb4b-xwd56
2024-08-28 07:14:36+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:11.5.2+maria~ubu2404 started.
2024-08-28 07:14:38+00:00 [Warn] [Entrypoint]: /sys/fs/cgroup///memory.pressure not writable, functionality unavailable to MariaDB
2024-08-28 07:14:38+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'
2024-08-28 07:14:39+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:11.5.2+maria~ubu2404 started.
2024-08-28 07:14:40+00:00 [ERROR] [Entrypoint]: Database is uninitialized and password option is not specified
        You need to specify one of MARIADB_ROOT_PASSWORD, MARIADB_ROOT_PASSWORD_HASH, MARIADB_ALLOW_EMPTY_ROOT_PASSWORD and MARIADB_RANDOM_ROOT_PASSWORD
raamu@raamu-VirtualBox:~$

clearly shows the password issue
-----------------------------------

raamu@raamu-VirtualBox:~$ kubectl get all
NAME                           READY   STATUS             RESTARTS      AGE
pod/failure2-c95f8fb4b-xwd56   0/1     CrashLoopBackOff   5 (74s ago)   5m24s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   23h

NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/failure2   0/1     1            0           5m25s

NAME                                 DESIRED   CURRENT   READY   AGE
replicaset.apps/failure2-c95f8fb4b   1         1         0       5m26s  --------------------->shows it not ready
raamu@raamu-VirtualBox:~$

Recreating the issue with passowrd(this can be added manually in the yaml also)
===========================

raamu@raamu-VirtualBox:~$ kubectl set env deploy failure2 MYSQL_ROOT_PASSWORD=password
deployment.apps/failure2 env updated

raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS        RESTARTS   AGE
failure2-5c9fdd4d76-c245q   1/1     Running       0          14s
failure2-898b7b5-wmvb8      0/1     Terminating   4          3m30s --> this one will be deleted.
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
failure2-5c9fdd4d76-c245q   1/1     Running   0          27s
raamu@raamu-VirtualBox:~$


raamu@raamu-VirtualBox:~$ kubectl get all
NAME                            READY   STATUS    RESTARTS   AGE
pod/failure2-5c9fdd4d76-c245q   1/1     Running   0          2m16s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   24h

NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/failure2   1/1     1            1           13m

NAME                                  DESIRED   CURRENT   READY   AGE
replicaset.apps/failure2-5c9fdd4d76   1         1         1       2m16s--------------------->available shows up and running
replicaset.apps/failure2-898b7b5      0         0         0       5m32s---------------------> old deploy
replicaset.apps/failure2-c95f8fb4b    0         0         0       13m---------------------> old deploy
raamu@raamu-VirtualBox:~$

=-====================================-------------------=====================

Senario:3 Pod access Issue( when we expose certin pods to internet or for users)

-> pods are exposed by using Load Balancer.
                             -------------
							 SO first we need ot check LB at services like does it LB,
							 like does it LB went to pending status or still showing the IP add.

-> And also when we need to access the backend pods, the major thing when we trying to access pods through service
  then first thing we need to check the 1. LABLES
                                        2. Selectors
		$kubectl get pods (gives the labels end points whether the endpoints properly matching or not)
		
-> Also check the INGRESS , like n/w policies enabled.

     eg: when we try to connect from one pod to other pod
	 
	 $kubectl get network policy/netpol -ABAC
	 $kubectl create deploy trouble --image=nginx
	 $kubectl get pods
	 
excersice:

raamu@raamu-VirtualBox:~$ kubectl create deploy trouble --image=nginx
deployment.apps/trouble created

expose the pod:

raamu@raamu-VirtualBox:~$ kubectl expose deploy trouble --port=80 --type=NodePort
service/trouble exposed
raamu@raamu-VirtualBox:~$

exposed to NODEPORT

raamu@raamu-VirtualBox:~$ kubectl get pods,svc
NAME                           READY   STATUS    RESTARTS   AGE
pod/trouble-7978bd5f7c-m98jt   1/1     Running   0          2m22s

NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
service/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        5m26s
service/trouble      NodePort    10.109.13.183   <none>        80:32124/TCP   69s------------------------>use this port to curl to expose
raamu@raamu-VirtualBox:~$

check the endpoints: shows trouble is connected to one of the pod

raamu@raamu-VirtualBox:~$ kubectl get ep
NAME         ENDPOINTS           AGE
kubernetes   192.168.49.2:8443   6m7s
trouble      10.244.120.68:80    109s

check the pod with ep: shows the IP add of pod 

raamu@raamu-VirtualBox:~$ kubectl get pod -o wide
NAME                       READY   STATUS    RESTARTS   AGE     IP              NODE       NOMINATED NODE   READINESS GATES
trouble-7978bd5f7c-m98jt   1/1     Running   0          3m12s   10.244.120.68   minikube   <none>           <none>
raamu@raamu-VirtualBox:~$


give the exposed port number: curl which confirms that nginx is able to acces the exposed pod

raamu@raamu-VirtualBox:~$ curl $(minikube ip):32124
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl get service
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        12m
trouble      NodePort    10.109.13.183   <none>        80:32124/TCP   8m3s
raamu@raamu-VirtualBox:~$


Edit the service: to create the troubelshooting the accessing the pod 

raamu@raamu-VirtualBox:~$ kubectl edit svc trouble
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2024-08-28T08:34:33Z"
  labels:
    app: trouble --------------------------------------->change to Trouble
  name: trouble
  namespace: default
  resourceVersion: "119869"
  uid: 5aae7261-1907-4333-afe0-99a9be1575b6
spec:
  clusterIP: 10.109.13.183
  clusterIPs:
  - 10.109.13.183
  externalTrafficPolicy: Cluster
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - nodePort: 32124
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: trouble  --------------------------------------->change to Trouble
  sessionAffinity: None
  type: NodePort
status:
  loadBalancer: {}
~


throughs error of exposed pod since we have changed the selector and labels app:

raamu@raamu-VirtualBox:~$ curl $(minikube ip):32124
curl: (7) Failed to connect to 192.168.49.2 port 32124 after 0 ms: Couldn't connect to server
raamu@raamu-VirtualBox:~$


If we check the endpoints , it shows no Ip

raamu@raamu-VirtualBox:~$ kubectl get ep
NAME         ENDPOINTS           AGE
kubernetes   192.168.49.2:8443   17m
trouble      <none>              13m
raamu@raamu-VirtualBox:~$



=============================================

Senario :4 Cluster level Issues.

shows everything what is going on cluster:

raamu@raamu-VirtualBox:~$ kubectl get events
LAST SEEN   TYPE      REASON              OBJECT                           MESSAGE
25m         Normal    Killing             pod/failure2-5c9fdd4d76-c245q    Stopping container mariadb
25m         Warning   FailedKillPod       pod/failure2-5c9fdd4d76-c245q    error killing pod: failed to "KillPodSandbox" for "7d6b84f4-9cc0-4e03-810f-d36282853eb4" with KillPodSandboxError: "rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"failure2-5c9fdd4d76-c245q_default\" network: plugin type=\"calico\" failed (delete): error getting ClusterInformation: Get \"https://10.96.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default\": dial tcp 10.96.0.1:443: i/o timeout"
25m         Normal    Scheduled           pod/failure2-5c9fdd4d76-nvqcz    Successfully assigned default/failure2-5c9fdd4d76-nvqcz to minikube
25m         Normal    Pulling             pod/failure2-5c9fdd4d76-nvqcz    Pulling image "mariadb"
25m         Normal    Pulled              pod/failure2-5c9fdd4d76-nvqcz    Successfully pulled image "mariadb" in 3.986s (3.986s including waiting). Image size: 406905275 bytes.
25m         Normal    Created             pod/failure2-5c9fdd4d76-nvqcz    Created container mariadb
25m         Normal    Started             pod/failure2-5c9fdd4d76-nvqcz    Started container mariadb
25m         Normal    Killing             pod/failure2-5c9fdd4d76-nvqcz    Stopping container mariadb
25m         Normal    SuccessfulCreate    replicaset/failure2-5c9fdd4d76   Created pod: failure2-5c9fdd4d76-nvqcz
22m         Normal    Scheduled           pod/trouble-7978bd5f7c-m98jt     Successfully assigned default/trouble-7978bd5f7c-m98jt to minikube
22m         Normal    Pulling             pod/trouble-7978bd5f7c-m98jt     Pulling image "nginx"
22m         Normal    Pulled              pod/trouble-7978bd5f7c-m98jt     Successfully pulled image "nginx" in 3.569s (3.569s including waiting). Image size: 187694648 bytes.
22m         Normal    Created             pod/trouble-7978bd5f7c-m98jt     Created container nginx
22m         Normal    Started             pod/trouble-7978bd5f7c-m98jt     Started container nginx
22m         Normal    SuccessfulCreate    replicaset/trouble-7978bd5f7c    Created pod: trouble-7978bd5f7c-m98jt
22m         Normal    ScalingReplicaSet   deployment/trouble               Scaled up replica set trouble-7978bd5f7c to 1
raamu@raamu-VirtualBox:~$

If we want to tchcek the particualr pod events by describe , we can see



raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
trouble-7978bd5f7c-m98jt   1/1     Running   0          24m
raamu@raamu-VirtualBox:~$ kubectl describe pod trouble-7978bd5f7c-m98jt
Name:             trouble-7978bd5f7c-m98jt
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Wed, 28 Aug 2024 14:03:20 +0530
Labels:           app=trouble
                  pod-template-hash=7978bd5f7c
Annotations:      cni.projectcalico.org/containerID: 98e1ca2858b860416ba8c3e1fc26f2704de65c5561d1c05e79ddf30d8a838d47
                  cni.projectcalico.org/podIP: 10.244.120.68/32
                  cni.projectcalico.org/podIPs: 10.244.120.68/32
Status:           Running
IP:               10.244.120.68
IPs:
  IP:           10.244.120.68
Controlled By:  ReplicaSet/trouble-7978bd5f7c
Containers:
  nginx:
    Container ID:   docker://5fff68645de32409185e25c80f88aaf4321513383813be88a8bd94af706bebae
    Image:          nginx
    Image ID:       docker-pullable://nginx@sha256:447a8665cc1dab95b1ca778e162215839ccbb9189104c79d7ec3a81e14577add
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 28 Aug 2024 14:03:33 +0530
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-kqhf9 (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       True
  ContainersReady             True
  PodScheduled                True
Volumes:
  kube-api-access-kqhf9:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  24m   default-scheduler  Successfully assigned default/trouble-7978bd5f7c-m98jt to minikube
  Normal  Pulling    24m   kubelet            Pulling image "nginx"
  Normal  Pulled     24m   kubelet            Successfully pulled image "nginx" in 3.569s (3.569s including waiting). Image size: 187694648 bytes.
  Normal  Created    24m   kubelet            Created container nginx
  Normal  Started    24m   kubelet            Started container nginx
raamu@raamu-VirtualBox:~$


shows particular node object, sub- object , source &  message:
                              -----------
							  If we not understand, then we can also check in describe(which shows the object level envents)
$kubectl get events -o wide

raamu@raamu-VirtualBox:~$ kubectl get events -o wide
LAST SEEN   TYPE      REASON              OBJECT                           SUBOBJECT                  SOURCE                  MESSAGE                                                                                                                                                                                                                                                                                                                                                                                                                                                FIRST SEEN   COUNT   NAME
31m         Normal    Killing             pod/failure2-5c9fdd4d76-c245q    spec.containers{mariadb}   kubelet, minikube       Stopping container mariadb                                                                                                                                                                                                                                                                                                                                                                                                                             31m          1       failure2-5c9fdd4d76-c245q.17efd736b5d442cd
30m         Warning   FailedKillPod       pod/failure2-5c9fdd4d76-c245q                               kubelet, minikube       error killing pod: failed to "KillPodSandbox" for "7d6b84f4-9cc0-4e03-810f-d36282853eb4" with KillPodSandboxError: "rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"failure2-5c9fdd4d76-c245q_default\" network: plugin type=\"calico\" failed (delete): error getting ClusterInformation: Get \"https://10.96.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default\": dial tcp 10.96.0.1:443: i/o timeout"   30m          1       failure2-5c9fdd4d76-c245q.17efd73f4227522b
31m         Normal    Scheduled           pod/failure2-5c9fdd4d76-nvqcz                               default-scheduler       Successfully assigned default/failure2-5c9fdd4d76-nvqcz to minikube                                                                                                                                                                                                                                                                                                                                                                                    31m          1       failure2-5c9fdd4d76-nvqcz.17efd736d8c6d724
30m         Normal    Pulling             pod/failure2-5c9fdd4d76-nvqcz    spec.containers{mariadb}   kubelet, minikube       Pulling image "mariadb"                                                                                                                                                                                                                                                                                                                                                                                                                                30m          1       failure2-5c9fdd4d76-nvqcz.17efd738ac17f3ab
30m         Normal    Pulled              pod/failure2-5c9fdd4d76-nvqcz    spec.containers{mariadb}   kubelet, minikube       Successfully pulled image "mariadb" in 3.986s (3.986s including waiting). Image size: 406905275 bytes.                                                                                                                                                                                                                                                                                                                                                 30m          1       failure2-5c9fdd4d76-nvqcz.17efd73999b5df7d
30m         Normal    Created             pod/failure2-5c9fdd4d76-nvqcz    spec.containers{mariadb}   kubelet, minikube       Created container mariadb                                                                                                                                                                                                                                                                                                                                                                                                                              30m          1       failure2-5c9fdd4d76-nvqcz.17efd739b07a3d8a
30m         Normal    Started             pod/failure2-5c9fdd4d76-nvqcz    spec.containers{mariadb}   kubelet, minikube       Started container mariadb                                                                                                                                                                                                                                                                                                                                                                                                                              30m          1       failure2-5c9fdd4d76-nvqcz.17efd73a4c0f9aec
30m         Normal    Killing             pod/failure2-5c9fdd4d76-nvqcz    spec.containers{mariadb}   kubelet, minikube       Stopping container mariadb                                                                                                                                                                                                                                                                                                                                                                                                                             30m          1       failure2-5c9fdd4d76-nvqcz.17efd73eda5deff7
31m         Normal    SuccessfulCreate    replicaset/failure2-5c9fdd4d76                              replicaset-controller   Created pod: failure2-5c9fdd4d76-nvqcz                                                                                                                                                                                                                                                                                                                                                                                                                 31m          1       failure2-5c9fdd4d76.17efd736cc823e3c
27m         Normal    Scheduled           pod/trouble-7978bd5f7c-m98jt                                default-scheduler       Successfully assigned default/trouble-7978bd5f7c-m98jt to minikube                                                                                                                                                                                                                                                                                                                                                                                     27m          1       trouble-7978bd5f7c-m98jt.17efd76292301ce3
27m         Normal    Pulling             pod/trouble-7978bd5f7c-m98jt     spec.containers{nginx}     kubelet, minikube       Pulling image "nginx"                                                                                                                                                                                                                                                                                                                                                                                                                                  27m          1       trouble-7978bd5f7c-m98jt.17efd76434792e42
27m         Normal    Pulled              pod/trouble-7978bd5f7c-m98jt     spec.containers{nginx}     kubelet, minikube       Successfully pulled image "nginx" in 3.569s (3.569s including waiting). Image size: 187694648 bytes.                                                                                                                                                                                                                                                                                                                                                   27m          1       trouble-7978bd5f7c-m98jt.17efd765093f9b5e
27m         Normal    Created             pod/trouble-7978bd5f7c-m98jt     spec.containers{nginx}     kubelet, minikube       Created container nginx                                                                                                                                                                                                                                                                                                                                                                                                                                27m          1       trouble-7978bd5f7c-m98jt.17efd7652bca8c9c
27m         Normal    Started             pod/trouble-7978bd5f7c-m98jt     spec.containers{nginx}     kubelet, minikube       Started container nginx                                                                                                                                                                                                                                                                                                                                                                                                                                27m          1       trouble-7978bd5f7c-m98jt.17efd7658df472b1
27m         Normal    SuccessfulCreate    replicaset/trouble-7978bd5f7c                               replicaset-controller   Created pod: trouble-7978bd5f7c-m98jt                                                                                                                                                                                                                                                                                                                                                                                                                  27m          1       trouble-7978bd5f7c.17efd7628a7b676b
27m         Normal    ScalingReplicaSet   deployment/trouble                                          deployment-controller   Scaled up replica set trouble-7978bd5f7c to 1                                                                                                                                                                                                                                                                                                                                                                                                          27m          1       trouble.17efd76283542d4a
raamu@raamu-VirtualBox:~$

It shows the deployment events:(object level events)

raamu@raamu-VirtualBox:~$ kubectl describe deploy trouble
Name:                   trouble
Namespace:              default
CreationTimestamp:      Wed, 28 Aug 2024 14:03:20 +0530
Labels:                 app=trouble
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=trouble
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=trouble
  Containers:
   nginx:
    Image:         nginx
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   trouble-7978bd5f7c (1/1 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  31m   deployment-controller  Scaled up replica set trouble-7978bd5f7c to 1
raamu@raamu-VirtualBox:~$


It shows the pod events:

raamu@raamu-VirtualBox:~$ kubectl describe pod  trouble
Name:             trouble-7978bd5f7c-m98jt
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Wed, 28 Aug 2024 14:03:20 +0530
Labels:           app=trouble
                  pod-template-hash=7978bd5f7c
Annotations:      cni.projectcalico.org/containerID: 98e1ca2858b860416ba8c3e1fc26f2704de65c5561d1c05e79ddf30d8a838d47
                  cni.projectcalico.org/podIP: 10.244.120.68/32
                  cni.projectcalico.org/podIPs: 10.244.120.68/32
Status:           Running
IP:               10.244.120.68
IPs:
  IP:           10.244.120.68
Controlled By:  ReplicaSet/trouble-7978bd5f7c
Containers:
  nginx:
    Container ID:   docker://5fff68645de32409185e25c80f88aaf4321513383813be88a8bd94af706bebae
    Image:          nginx
    Image ID:       docker-pullable://nginx@sha256:447a8665cc1dab95b1ca778e162215839ccbb9189104c79d7ec3a81e14577add
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 28 Aug 2024 14:03:33 +0530
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-kqhf9 (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       True
  ContainersReady             True
  PodScheduled                True
Volumes:
  kube-api-access-kqhf9:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  32m   default-scheduler  Successfully assigned default/trouble-7978bd5f7c-m98jt to minikube
  Normal  Pulling    32m   kubelet            Pulling image "nginx"
  Normal  Pulled     32m   kubelet            Successfully pulled image "nginx" in 3.569s (3.569s including waiting). Image size: 187694648 bytes.
  Normal  Created    32m   kubelet            Created container nginx
  Normal  Started    32m   kubelet            Started container nginx

raamu@raamu-VirtualBox:~$

TO check the cluster level events:

raamu@raamu-VirtualBox:~$ kubectl get events | grep error
37m         Warning   FailedKillPod       pod/failure2-5c9fdd4d76-c245q    error killing pod: failed to "KillPodSandbox" for "7d6b84f4-9cc0-4e03-810f-d36282853eb4" with KillPodSandboxError: "rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"failure2-5c9fdd4d76-c245q_default\" network: plugin type=\"calico\" failed (delete): error getting ClusterInformation: Get \"https://10.96.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default\": dial tcp 10.96.0.1:443: i/o timeout"
raamu@raamu-VirtualBox:~$ kubectl get events | grep warning
raamu@raamu-VirtualBox:~$ kubectl get events | grep -i warning
37m         Warning   FailedKillPod       pod/failure2-5c9fdd4d76-c245q    error killing pod: failed to "KillPodSandbox" for "7d6b84f4-9cc0-4e03-810f-d36282853eb4" with KillPodSandboxError: "rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"failure2-5c9fdd4d76-c245q_default\" network: plugin type=\"calico\" failed (delete): error getting ClusterInformation: Get \"https://10.96.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default\": dial tcp 10.96.0.1:443: i/o timeout"
raamu@raamu-Vi


Getting access Issues:


raamu@raamu-VirtualBox:~$ kubectl config view
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /home/raamu/.minikube/ca.crt
    extensions:
    - extension:
        last-update: Wed, 28 Aug 2024 12:24:58 IST
        provider: minikube.sigs.k8s.io
        version: v1.33.0
      name: cluster_info
    server: https://192.168.49.2:8443
  name: minikube
contexts:
- context:
    cluster: minikube
    extensions:
    - extension:
        last-update: Wed, 28 Aug 2024 12:24:58 IST
        provider: minikube.sigs.k8s.io
        version: v1.33.0
      name: context_info
    namespace: default
    user: minikube
  name: minikube
current-context: minikube
kind: Config
preferences: {}
users:
- name: minikube
  user:
    client-certificate: /home/raamu/.minikube/profiles/minikube/client.crt
    client-key: /home/raamu/.minikube/profiles/minikube/client.key
raamu@raamu-VirtualBox:~$

TO check teh access:

raamu@raamu-VirtualBox:~$ kubectl auth can-i create pod
yes
raamu@raamu-VirtualBox:

=======================================================----------------------==============================

Day 22: kubernetes probes |HELM:

Readiness & Liveness

apiVersion: v1
kind: Pod
metadata:
  labels:
    app: busybox
  name: busybox1
  namespace: default
spec:
  containers:
  - name: busy
    image: busybox
    command:
      - sleep
      - "3600"
	readinessProbe:
	  periodSeconds: 10
	  exec:
	    command:
		- cat
		- /tmp/nothing
	resources: {}


raamu@raamu-VirtualBox:~$ vi readiness.yaml
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ vi busybox.yaml
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl apply -f busybox.yaml
pod/busybox1 created
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME       READY   STATUS              RESTARTS   AGE
busybox1   0/1     ContainerCreating   0          16s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME       READY   STATUS    RESTARTS   AGE
busybox1   0/1     Running   0          19s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME       READY   STATUS    RESTARTS   AGE
busybox1   0/1     Running   0          26s
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME       READY   STATUS    RESTARTS   AGE
busybox1   0/1     Running   0          30s
raamu@raamu-VirtualBox:~$ kubectl describe pod busybox1
Name:             busybox1
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Wed, 28 Aug 2024 22:04:54 +0530
Labels:           app=busybox
Annotations:      cni.projectcalico.org/containerID: a8cc7298e75dc11f835b5be3af56a722aac8d05f9b140e8148623c94ee28fe60
                  cni.projectcalico.org/podIP: 10.244.120.100/32
                  cni.projectcalico.org/podIPs: 10.244.120.100/32
Status:           Running
IP:               10.244.120.100
IPs:
  IP:  10.244.120.100
Containers:
  busy:
    Container ID:  docker://90c6807360f28d8339c790f7b02139c8e05fcbdb6f013d1f877bd3d581fe6090
    Image:         busybox
    Image ID:      docker-pullable://busybox@sha256:9ae97d36d26566ff84e8893c64a6dc4fe8ca6d1144bf5b87b2b85a32def253c7
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      3600
    State:          Running
      Started:      Wed, 28 Aug 2024 22:05:09 +0530
    Ready:          False
    Restart Count:  0
    Readiness:      exec [cat /tmp/nothing] delay=0s timeout=1s period=10s #success=1 #failure=3
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-v4n9g (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       False
  ContainersReady             False
  PodScheduled                True
Volumes:
  kube-api-access-v4n9g:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  61s                default-scheduler  Successfully assigned default/busybox1 to minikube
  Normal   Pulling    54s                kubelet            Pulling image "busybox"
  Normal   Pulled     49s                kubelet            Successfully pulled image "busybox" in 5.32s (5.32s including waiting). Image size: 4261574 bytes.
  Normal   Created    48s                kubelet            Created container busy
  Normal   Started    46s                kubelet            Started container busy
  Warning  Unhealthy  43s                kubelet            Readiness probe failed: command "cat /tmp/nothing" timed out
  Warning  Unhealthy  10s (x5 over 41s)  kubelet            Readiness probe failed: cat: can't open '/tmp/nothing': No such file or directory
raamu@raamu-VirtualBox:~$


ITs throughing error , since it does not created the path /tmp/nothing


raamu@raamu-VirtualBox:~$ kubectl exec -it busybox1 -- touch /tmp/nothing


***********Because of the readiness and liveness probes in one file most of the times 
pod will get restat.

raamu@raamu-VirtualBox:~$ kubectl describe pod busybox1
Name:             busybox1
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Wed, 28 Aug 2024 22:04:54 +0530
Labels:           app=busybox
Annotations:      cni.projectcalico.org/containerID: a8cc7298e75dc11f835b5be3af56a722aac8d05f9b140e8148623c94ee28fe60
                  cni.projectcalico.org/podIP: 10.244.120.100/32
                  cni.projectcalico.org/podIPs: 10.244.120.100/32
Status:           Running
IP:               10.244.120.100
IPs:
  IP:  10.244.120.100
Containers:
  busy:
    Container ID:  docker://90c6807360f28d8339c790f7b02139c8e05fcbdb6f013d1f877bd3d581fe6090
    Image:         busybox
    Image ID:      docker-pullable://busybox@sha256:9ae97d36d26566ff84e8893c64a6dc4fe8ca6d1144bf5b87b2b85a32def253c7
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      3600
    State:          Running
      Started:      Wed, 28 Aug 2024 22:05:09 +0530
    Ready:          True
    Restart Count:  0
    Readiness:      exec [cat /tmp/nothing] delay=0s timeout=1s period=10s #success=1 #failure=3
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-v4n9g (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       True
  ContainersReady             True
  PodScheduled                True
Volumes:
  kube-api-access-v4n9g:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                     From               Message
  ----     ------     ----                    ----               -------
  Normal   Scheduled  5m14s                   default-scheduler  Successfully assigned default/busybox1 to minikube
  Normal   Pulling    5m7s                    kubelet            Pulling image "busybox"
  Normal   Pulled     5m2s                    kubelet            Successfully pulled image "busybox" in 5.32s (5.32s including waiting). Image size: 4261574 bytes.
  Normal   Created    5m1s                    kubelet            Created container busy
  Normal   Started    4m59s                   kubelet            Started container busy
  Warning  Unhealthy  2m33s (x17 over 4m54s)  kubelet            Readiness probe failed: cat: can't open '/tmp/nothing': No such file or directory
  Warning  Unhealthy  13s (x3 over 4m56s)     kubelet            Readiness probe failed: command "cat /tmp/nothing" timed out
raamu@raamu-VirtualBox:~$


===========================================


Monitoring:

Generally we have monitoring tool (dashboard)

But, for checking the cpu & RAM utilization
  $kubectl top pod
  
  $kubectl top nodes
  
To check the Disk utilization:
 -> Basically we can check at AWS GUI level
     or  AWSCLI  --> at command level

PCV and PV level Capacity usage:
 
 3rd party app command will be used (need to find)
 
 
 Troubeshooting Stuck in Termination:************
 ------------------------------------------
 -> If anything stucks and we get terminating
      eg: namespace struck terminating
	  
	 -> for this we need to bring the namespace to JSON format

raamu@raamu-VirtualBox:~$ kubectl get namespace rnamespace -o json >tmp.json
raamu@raamu-VirtualBox:~$

remove finalizers and run:

raamu@raamu-VirtualBox:~$ cat tmp.json
{
    "apiVersion": "v1",
    "kind": "Namespace",
    "metadata": {
        "creationTimestamp": "2024-08-21T08:57:46Z",
        "labels": {
            "kubernetes.io/metadata.name": "rnamespace"
        },
        "name": "rnamespace",
        "resourceVersion": "43587",
        "uid": "39669bac-abec-46da-9a77-17991d8dab7a"
    },
    "spec": {
        "finalizers": [               ->>>>>>>>>>>>>>>>>>>>>.remove
            "kubernetes"
        ]
    },
    "status": {
        "phase": "Active"
    }
}
raamu@raamu-VirtualBox:~$

Troubeshooting Client Issues:************
 ------------------------------------------
 
-> Access issues we check through services ->(we check labels)
-> check endpoints
-> check the pod where srv are mapping
-> If access, ask the client to recheck
          like if it is not working then it definitely traffic Issue
		  then ask the n/w team cehck teh packets.
		  still no Issues at n/w, then their may be configuration issue at client end.
		  
============================
HELM:

Its a 3rd party tool which Helm Organization manages.
whenever we install the application , the inatallations and application deployments will be strealined.

what is streamline?
 eg: In linux , if we want to install we use yum ->Redhat
                                             apt-Ubuntu
                                             ----------
											 if any dependencies , these will be managed using yum and apt tools
  Likewise, in k8's if we want to do any installation/manage application and if we want to make
     clear dependencies then HELM will be used.
                             -----
                             works based on charts and so naming convention is HELM Chart or Helm Packages.

HELM Chart or Helm Packages :

It has all description of the package adn also we have templates. 
                                                       ----------
                                                       which are called manifest files
                                                                        ---------
																		where we will bring all dependencies files.
																		
where helm charts/packages will be stored?

we mainly stores locally (/usr/local/bin/heml)

How to install HELM:

go to https://helm.sh/docs/intro/install/ and download zip file or tar file
       if it is linux--->download the file Linuxi386 

once installed in linux, 

raamu@raamu-VirtualBox:~/Downloads$ sudo su
[sudo] password for raamu:
root@raamu-VirtualBox:/home/raamu/Downloads#
root@raamu-VirtualBox:/home/raamu/Downloads#
root@raamu-VirtualBox:/home/raamu/Downloads# chmod 777 /usr/local/bin/
root@raamu-VirtualBox:/home/raamu/Downloads#
root@raamu-VirtualBox:/home/raamu/Downloads# exit
exit
raamu@raamu-VirtualBox:~/Downloads$
raamu@raamu-VirtualBox:~/Downloads$
raamu@raamu-VirtualBox:~/Downloads$ mv linux-386/helm /usr/local/bin/
mv: cannot stat 'linux-386/helm': No such file or directory
raamu@raamu-VirtualBox:~/Downloads$ ls -ltr
total 64152
-rwxr-xr-x 1 raamu raamu 50327704 Jul 11 01:01 helm
-rw-rw-r-- 1 raamu raamu 15351725 Aug 28 23:00 helm-v3.15.3-linux-386.tar.gz
-rw-rw-r-- 1 raamu raamu       96 Aug 28 23:00 helm-v3.15.3-linux-386.tar.gz.sha256sum
drwxr-xr-x 2 raamu raamu     4096 Aug 28 23:06 linux-386
raamu@raamu-VirtualBox:~/Downloads$ mv helm /usr/local/bin/
raamu@raamu-VirtualBox:~/Downloads$ cd /usr/local/bin/
raamu@raamu-VirtualBox:/usr/local/bin$ ls -ltr
total 192804
-rwxrwxr-x 1 raamu raamu 51454104 May  5 17:22 kubectl
-rwxr-xr-x 1 root  root  95637096 May  5 17:23 minikube
-rwxr-xr-x 1 raamu raamu 50327704 Jul 11 01:01 helm
raamu@raamu-VirtualBox:/usr/local/bin$


all charts available from artifacthub.io

https://artifacthub.io/ --> all packages will avaiable

eg: searh here any tool like kafka,jenkins,mariadb and etc.


To deploy anything form helm:

1. first we need to add helm repo first

raamu@raamu-VirtualBox:~$ helm repo list
Error: no repositories to show
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ helm repo add my-repo https://charts.bitnami.com/bitnami
"my-repo" has been added to your repositories
raamu@raamu-VirtualBox:~$ helm repo list
NAME    URL
my-repo https://charts.bitnami.com/bitnami
raamu@raamu-VirtualBox:~$

gives latest udpated files:

raamu@raamu-VirtualBox:~$ helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "my-repo" chart repository
Update Complete. ⎈Happy Helming!⎈


raamu@raamu-VirtualBox:~$ helm search repo bitnami
NAME            CHART VERSION   APP VERSION     DESCRIPTION
my-repo/common  2.22.0          2.22.0          A Library Helm Chart for grouping common logic ...
my-repo/mxnet   3.5.2           1.9.1           DEPRECATED Apache MXNet (Incubating) is a flexi...
my-repo/pytorch 4.2.13          2.4.0           PyTorch is a deep learning platform that accele...
raamu@raamu-VirtualBox:~$

If helm chart not installing go to artifacthub.io and 
https://artifacthub.io/packages/helm/wso2/mysql
-> search mysql ->install ->here we get add repo and install chart links

raamu@raamu-VirtualBox:~$  helm repo add wso2 https://helm.wso2.com
"wso2" has been added to your repositories

raamu@raamu-VirtualBox:~$ helm install my-mysql wso2/mysql --version 1.6.9
NAME: my-mysql
LAST DEPLOYED: Sun Sep  1 17:01:43 2024
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
MySQL can be accessed via port 3306 on the following DNS name from within your cluster:
my-mysql.default.svc.cluster.local

To get your root password run:

    MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default my-mysql -o jsonpath="{.data.mysql-root-password}" | base64 --decode; echo)

To connect to your database:

1. Run an Ubuntu pod that you can use as a client:

    kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il

2. Install the mysql client:

    $ apt-get update && apt-get install mysql-client -y

3. Connect using the mysql cli, then provide your password:
    $ mysql -h my-mysql -p

To connect to your database directly from outside the K8s cluster:
    MYSQL_HOST=127.0.0.1
    MYSQL_PORT=3306

    # Execute the following command to route the connection:
    kubectl port-forward svc/my-mysql 3306

    mysql -h ${MYSQL_HOST} -P${MYSQL_PORT} -u root -p${MYSQL_ROOT_PASSWORD}
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ helm show  all bitnami/mysql
Error: repo bitnami not found
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
my-mysql-7677c5496-72zdd   1/1     Running   0          8m35s


helm install bitnami/mysql
helm show chart bitnami/mysql (show s the deployed)
helm list (shows what we ahve installed)
	   
	raamu@raamu-VirtualBox:/usr/local/bin$ helm list
NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION
my-mysql        default         1               2024-09-01 17:01:43.727637341 +0530 IST deployed        mysql-1.6.9     5.7.30
raamu@raamu-VirtualBox:/usr/local/bin$

raamu@raamu-VirtualBox:/usr/local/bin$ helm status my-mysql
NAME: my-mysql
LAST DEPLOYED: Sun Sep  1 17:01:43 2024
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
MySQL can be accessed via port 3306 on the following DNS name from within your cluster:
my-mysql.default.svc.cluster.local

To get your root password run:

    MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default my-mysql -o jsonpath="{.data.mysql-root-password}" | base64 --decode; echo)

To connect to your database:

1. Run an Ubuntu pod that you can use as a client:

    kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il

2. Install the mysql client:

    $ apt-get update && apt-get install mysql-client -y

3. Connect using the mysql cli, then provide your password:
    $ mysql -h my-mysql -p

To connect to your database directly from outside the K8s cluster:
    MYSQL_HOST=127.0.0.1
    MYSQL_PORT=3306

    # Execute the following command to route the connection:
    kubectl port-forward svc/my-mysql 3306

    mysql -h ${MYSQL_HOST} -P${MYSQL_PORT} -u root -p${MYSQL_ROOT_PASSWORD}
raamu@raamu-VirtualBox:/usr/local/bin$


TO remove the mysql:

raamu@raamu-VirtualBox:~$ helm list
NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION
my-mysql        default         1               2024-09-01 17:01:43.727637341 +0530 IST deployed        mysql-1.6.9     5.7.30
raamu@raamu-VirtualBox:~$ helm delete my-mysql
release "my-mysql" uninstalled
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ helm list
NAME    NAMESPACE       REVISION        UPDATED STATUS  CHART   APP VERSION
raamu@raamu-VirtualBox:~$




=> we can customize the helm manifest files:

to pull the required images:

helm pull bitnami/nginx


********HElm charts need to work on it***********


==========================================================


DAy23: Kubernetes Kustomize | K8's Blue Green Deployment:


=>Kustomozation is rerely used.
=>HElm charts/packages are using 
=>Now-a-days Operators are using  which is a 3rd party which we see in artifacthub.io



Blue/Green Deployment: (Zero Downtime Deployment strategy)

-> If we want to move from Version1[V1] -> version2[v2]
                           -----------
						   IT has its own resource services
-> When we do new deployment V1 & V2 simultaneously runs and during this V1 related services we move gradually to V2.
-> THis moving of services will move in secs or microsecs with the help of LABELS.
-> Then after we can remove teh V1

Blue  - is running application i.e v1 is existing
Green - new application i.e v2 is need to create


Blue:

raamu@raamu-VirtualBox:~$ kubectl create deploy blue-nginx --image=nginx --replicas=3
deployment.apps/blue-nginx created
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$
raamu@raamu-VirtualBox:~$ kubectl get all
NAME                              READY   STATUS    RESTARTS   AGE
pod/blue-nginx-75f5749b4c-gwkk9   1/1     Running   0          33s
pod/blue-nginx-75f5749b4c-klc6w   1/1     Running   0          33s
pod/blue-nginx-75f5749b4c-xhfxr   1/1     Running   0          33s

NAME                         READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/blue-nginx   3/3     3            3           34s

NAME                                    DESIRED   CURRENT   READY   AGE
replicaset.apps/blue-nginx-75f5749b4c   3         3         3       34s
raamu@raamu-VirtualBox:~$


Need to expose:

raamu@raamu-VirtualBox:~$ kubectl expose deploy blue-nginx --port=80 --name=bgnginx
service/bgnginx exposed

raamu@raamu-VirtualBox:~$ kubectl get all
NAME                              READY   STATUS    RESTARTS   AGE
pod/blue-nginx-75f5749b4c-gwkk9   1/1     Running   0          5m12s
pod/blue-nginx-75f5749b4c-klc6w   1/1     Running   0          5m12s
pod/blue-nginx-75f5749b4c-xhfxr   1/1     Running   0          5m12s

NAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/bgnginx   ClusterIP   10.106.76.146   <none>        80/TCP    18s -------------> service creatd

NAME                         READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/blue-nginx   3/3     3            3           5m12s

NAME                                    DESIRED   CURRENT   READY   AGE
replicaset.apps/blue-nginx-75f5749b4c   3         3         3       5m12s
raamu@raamu-VirtualBox:~$

describe:

raamu@raamu-VirtualBox:~$ kubectl describe deploy blue-nginx
Name:                   blue-nginx
Namespace:              rnamespace
CreationTimestamp:      Sun, 01 Sep 2024 18:48:54 +0530
Labels:                 app=blue-nginx
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=blue-nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=blue-nginx
  Containers:
   nginx:
    Image:         nginx
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   blue-nginx-75f5749b4c (3/3 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  6m30s  deployment-controller  Scaled up replica set blue-nginx-75f5749b4c to 3
raamu@raamu-VirtualBox:~$

endpoints:

raamu@raamu-VirtualBox:~$ kubectl get ep
NAME      ENDPOINTS                                              AGE
bgnginx   10.244.120.103:80,10.244.120.107:80,10.244.120.97:80   115s
raamu@raamu-VirtualBox:~$


Green: 
 To create new version, first we copy the blue file and rename to green and edit /update the changes:
 
 (like how we do edit the init.ora file in oracle and  remove unwanted lines)
 
 
raamu@raamu-VirtualBox:~$ kubectl get deploy blue-nginx -o yaml > green-nginx.yaml
raamu@raamu-VirtualBox:~$ ls -ltr
total 39932
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Videos
drwxr-xr-x 2 raamu raamu     4096 May  5 16:03 Templates
-rw-rw-r-- 1 raamu raamu     1594 Sep  1 18:58 green-nginx.yaml
raamu@raamu-VirtualBox:~$

raamu@raamu-VirtualBox:~$ vi green-nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations: ---------------------------------> remove this lines if not required only
    deployment.kubernetes.io/revision: "1"
  creationTimestamp: "2024-09-01T13:18:54Z"
  generation: 1
  labels:
    app: blue-nginx
  name: blue-nginx
  namespace: rnamespace
  resourceVersion: "133558"
  uid: b1b39bbd-bdc0-44ac-985c-a0259af8911a
spec:
  progressDeadlineSeconds: 600
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: blue-nginx
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: blue-nginx
    spec:
      containers:
        - image: nginx:1.17
        imagePullPolicy: Always
        name: nginx
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:                                                 |
  availableReplicas: 3                                  |
  conditions:                                           | 
  - lastTransitionTime: "2024-09-01T13:19:06Z"          |
    lastUpdateTime: "2024-09-01T13:19:06Z"              |
    message: Deployment has minimum availability.       |
    reason: MinimumReplicasAvailable                    |
    status: "True"                                      |  REMOVE ALL LINES
    type: Available                                     |
  - lastTransitionTime: "2024-09-01T13:18:54Z"          |
    lastUpdateTime: "2024-09-01T13:19:06Z"              |
-- INSERT --                                            |
                                                        |
                                                        |



================================================================
Modified:

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: green-nginx
  name: green-nginx
  namespace: rnamespace
spec:
  progressDeadlineSeconds: 600
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: green-nginx
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: green-nginx
    spec:
      containers:
        - image: nginx:1.17
        imagePullPolicy: Always
        name: nginx
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
====================================================

raamu@raamu-VirtualBox:~$ kubectl create -f green-deploy.yaml
deployment.apps/glue-nginx created
raamu@raamu-VirtualBox:~$


One of the disadvantage is , once we create the greeen doployment **************
for sometime both will run sumultanously

TO test we need ot expose  and test in test environment

$kubectl expose deploy glue-nginx --port=80 --name=bgnginx

Coming to prod, we directly delete/create/expose the service and expose the service od updated version glue deployment

raamu@raamu-VirtualBox:~$ kubectl get all
NAME                              READY   STATUS    RESTARTS   AGE
pod/blue-nginx-75f5749b4c-gwkk9   1/1     Running   0          42m
pod/blue-nginx-75f5749b4c-klc6w   1/1     Running   0          42m
pod/blue-nginx-75f5749b4c-xhfxr   1/1     Running   0          42m
pod/glue-nginx-b4485b875-7hjmb    1/1     Running   0          44s
pod/glue-nginx-b4485b875-r7hqh    1/1     Running   0          44s
pod/glue-nginx-b4485b875-wc44b    1/1     Running   0          44s

NAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/bgnginx   ClusterIP   10.106.76.146   <none>        80/TCP    37m

NAME                         READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/blue-nginx   3/3     3            3           42m
deployment.apps/glue-nginx   3/3     3            3           44s

NAME                                    DESIRED   CURRENT   READY   AGE
replicaset.apps/blue-nginx-75f5749b4c   3         3         3       42m
replicaset.apps/glue-nginx-b4485b875    3         3         3       44s
raamu@raamu-VirtualBox:~$ kubectl get all
NAME                              READY   STATUS    RESTARTS   AGE
pod/blue-nginx-75f5749b4c-gwkk9   1/1     Running   0          44m
pod/blue-nginx-75f5749b4c-klc6w   1/1     Running   0          44m
pod/blue-nginx-75f5749b4c-xhfxr   1/1     Running   0          44m
pod/glue-nginx-b4485b875-7hjmb    1/1     Running   0          2m38s
pod/glue-nginx-b4485b875-r7hqh    1/1     Running   0          2m38s
pod/glue-nginx-b4485b875-wc44b    1/1     Running   0          2m38s

NAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/bgnginx   ClusterIP   10.106.76.146   <none>        80/TCP    39m

NAME                         READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/blue-nginx   3/3     3            3           44m
deployment.apps/glue-nginx   3/3     3            3           2m38s

NAME                                    DESIRED   CURRENT   READY   AGE
replicaset.apps/blue-nginx-75f5749b4c   3         3         3       44m
replicaset.apps/glue-nginx-b4485b875    3         3         3       2m38s
raamu@raamu-VirtualBox:~$ kubectl get all
NAME                              READY   STATUS    RESTARTS   AGE
pod/blue-nginx-75f5749b4c-gwkk9   1/1     Running   0          44m
pod/blue-nginx-75f5749b4c-klc6w   1/1     Running   0          44m
pod/blue-nginx-75f5749b4c-xhfxr   1/1     Running   0          44m
pod/glue-nginx-b4485b875-7hjmb    1/1     Running   0          2m41s
pod/glue-nginx-b4485b875-r7hqh    1/1     Running   0          2m41s
pod/glue-nginx-b4485b875-wc44b    1/1     Running   0          2m41s

NAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/bgnginx   ClusterIP   10.106.76.146   <none>        80/TCP    39m

NAME                         READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/blue-nginx   3/3     3            3           44m
deployment.apps/glue-nginx   3/3     3            3           2m41s

NAME                                    DESIRED   CURRENT   READY   AGE
replicaset.apps/blue-nginx-75f5749b4c   3         3         3       44m
replicaset.apps/glue-nginx-b4485b875    3         3         3       2m41s
raamu@raamu-VirtualBox:~$ kubectl delete svc bgniginx; kubectl expose deploy glue-nginx --port=80 --name=bgnginx
Error from server (NotFound): services "bgniginx" not found
Error from server (AlreadyExists): services "bgnginx" already exists
raamu@raamu-VirtualBox:~$ kubectl get ep
NAME      ENDPOINTS                                              AGE
bgnginx   10.244.120.103:80,10.244.120.107:80,10.244.120.97:80   44m
raamu@raamu-VirtualBox:~$ kubectl get pofs -o wide
error: the server doesn't have a resource type "pofs"
raamu@raamu-VirtualBox:~$ kubectl get pods -o wide
NAME                          READY   STATUS    RESTARTS   AGE     IP               NODE       NOMINATED NODE   READINESS GATES
blue-nginx-75f5749b4c-gwkk9   1/1     Running   0          49m     10.244.120.103   minikube   <none>           <none>
blue-nginx-75f5749b4c-klc6w   1/1     Running   0          49m     10.244.120.107   minikube   <none>           <none>
blue-nginx-75f5749b4c-xhfxr   1/1     Running   0          49m     10.244.120.97    minikube   <none>           <none>
glue-nginx-b4485b875-7hjmb    1/1     Running   0          8m22s   10.244.120.116   minikube   <none>           <none>
glue-nginx-b4485b875-r7hqh    1/1     Running   0          8m22s   10.244.120.120   minikube   <none>           <none>
glue-nginx-b4485b875-wc44b    1/1     Running   0          8m22s   10.244.120.106   minikube   <none>           <none>

we are doing with service , its a straigt forward:

raamu@raamu-VirtualBox:~$ kubectl delete svc bgnginx; kubectl expose deploy glue-nginx --port=80 --name=bgnginx
service "bgnginx" deleted
service/bgnginx exposed
raamu@raamu-VirtualBox:~$ kubectl get ep
NAME      ENDPOINTS                                               AGE
bgnginx   10.244.120.106:80,10.244.120.116:80,10.244.120.120:80   14s
raamu@raamu-VirtualBox:~$ kubectl get svc
NAME      TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE
bgnginx   ClusterIP   10.107.8.14   <none>        80/TCP    23s
raamu@raamu-VirtualBox:~$  kubectl get pods -o wide
NAME                          READY   STATUS    RESTARTS   AGE     IP               NODE       NOMINATED NODE   READINESS GATES
blue-nginx-75f5749b4c-gwkk9   1/1     Running   0          50m     10.244.120.103   minikube   <none>           <none>
blue-nginx-75f5749b4c-klc6w   1/1     Running   0          50m     10.244.120.107   minikube   <none>           <none>
blue-nginx-75f5749b4c-xhfxr   1/1     Running   0          50m     10.244.120.97    minikube   <none>           <none>
glue-nginx-b4485b875-7hjmb    1/1     Running   0          9m30s   10.244.120.116   minikube   <none>           <none>
glue-nginx-b4485b875-r7hqh    1/1     Running   0          9m30s   10.244.120.120   minikube   <none>           <none>
glue-nginx-b4485b875-wc44b    1/1     Running   0          9m30s   10.244.120.106   minikube   <none>           <none>
raamu@raamu-VirtualBox:~$ kubectl delete deploy blue-nginx
deployment.apps "blue-nginx" deleted
raamu@raamu-VirtualBox:~$ kubectl get pods -o wide
NAME                         READY   STATUS    RESTARTS   AGE   IP               NODE       NOMINATED NODE   READINESS GATES
glue-nginx-b4485b875-7hjmb   1/1     Running   0          10m   10.244.120.116   minikube   <none>           <none>
glue-nginx-b4485b875-r7hqh   1/1     Running   0          10m   10.244.120.120   minikube   <none>           <none>
glue-nginx-b4485b875-wc44b   1/1     Running   0          10m   10.244.120.106   minikube   <none>           <none>
raamu@raamu-VirtualBox:~$ kubectl get pods
NAME                         READY   STATUS    RESTARTS   AGE
glue-nginx-b4485b875-7hjmb   1/1     Running   0          10m
glue-nginx-b4485b875-r7hqh   1/1     Running   0          10m
glue-nginx-b4485b875-wc44b   1/1     Running   0          10m
raamu@raamu-VirtualBox:~$ kubectl get deploy
NAME         READY   UP-TO-DATE   AVAILABLE   AGE
glue-nginx   3/3     3            3           10m
raamu@raamu-VirtualBox:~$ kubectl describe deploy glue-nginx
Name:                   glue-nginx
Namespace:              rnamespace
CreationTimestamp:      Sun, 01 Sep 2024 19:30:20 +0530
Labels:                 app=glue-nginx
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=glue-nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=glue-nginx
  Containers:
   nginx:
    Image:         nginx:1.17
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   glue-nginx-b4485b875 (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  11m   deployment-controller  Scaled up replica set glue-nginx-b4485b875 to 3
raamu@raamu-VirtualBox:~$


***we can also edit the services  and do the chages but we need to change the label and selector 
thats why we use 

raamu@raamu-VirtualBox:~$ kubectl delete svc bgnginx; kubectl expose deploy glue-nginx --port=80 --name=bgnginx

and why use services: because we already exposed to the client.(best to edit the service)

raamu@raamu-VirtualBox:~$ kubectl edit svc bgnginx
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2024-09-01T14:08:55Z"
  labels:
    app: glue-nginx
  name: bgnginx
  namespace: rnamespace
  resourceVersion: "135992"
  uid: 96370126-930f-46e2-b5d3-443abef3306a
spec:
  clusterIP: 10.107.8.14
  clusterIPs:
  - 10.107.8.14
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: glue-nginx
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}
~
~
~
~
~

STATEFULSETS: (Daemonset, deployment & Statefulset are the same kind of deployments)

 ====================================================================


Day24: Kubernetes CRD's(Custom Resources Definitions):

















